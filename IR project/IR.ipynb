{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8ocxM7tD11c"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hYv050NeqKGl",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f5629cc9-7d47-45fe-cfad-fef858f77d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.12/dist-packages (from numba) (2.0.2)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-3.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
            "Downloading bitarray-3.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (340 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.3/340.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitarray\n",
            "Successfully installed bitarray-3.8.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting ir_measures\n",
            "  Downloading ir_measures-0.4.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pytrec-eval-terrier>=0.5.5 (from ir_measures)\n",
            "  Downloading pytrec_eval_terrier-0.5.10-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from pytrec-eval-terrier>=0.5.5->ir_measures) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from pytrec-eval-terrier>=0.5.5->ir_measures) (1.16.3)\n",
            "Downloading ir_measures-0.4.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytrec_eval_terrier-0.5.10-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.8/304.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytrec-eval-terrier, ir_measures\n",
            "Successfully installed ir_measures-0.4.2 pytrec-eval-terrier-0.5.10\n",
            "Collecting python-terrier\n",
            "  Downloading python_terrier-1.0-py3-none-any.whl.metadata (987 bytes)\n",
            "Collecting pyterrier>=1.0 (from pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading pyterrier-1.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.2.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (10.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.32.4)\n",
            "Collecting ir_datasets>=0.3.2 (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading ir_datasets-0.5.11-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting deprecated (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.16.3)\n",
            "Requirement already satisfied: ir_measures>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.4.2)\n",
            "Requirement already satisfied: pytrec_eval_terrier>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.5.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (3.1.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.14.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (0.3.8)\n",
            "Collecting lz4 (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (4.13.5)\n",
            "Collecting pyjnius>=1.4.2 (from pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading pyjnius-1.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting inscriptis>=2.2.0 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading inscriptis-2.7.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.12/dist-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (6.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (6.0.3)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
            "Collecting warc3-wet>=0.2.3 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading zlib_state-0.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting ijson>=3.1.3 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting unlzw3>=0.2.1 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.12/dist-packages (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (18.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2025.11.12)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (2025.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (25.0)\n",
            "Collecting lxml>=4.5.2 (from ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading lxml-5.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier) (1.17.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir_datasets>=0.3.2->pyterrier>=1.0->pyterrier[all]>=1.0->python-terrier)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading python_terrier-1.0-py3-none-any.whl (1.4 kB)\n",
            "Downloading pyterrier-1.0.0-py3-none-any.whl (205 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.5/205.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_datasets-0.5.11-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.1/866.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyjnius-1.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inscriptis-2.7.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
            "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
            "Downloading zlib_state-0.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Building wheels for collected packages: warc3-wet-clueweb09, cbor\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=c15237e5a85d863d959b0fa594f22235302e488ce2c0ad0d14c3a0e8e919eac5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/85/c2/9f0f621def52a1d5db7d29984f81e45f9fb6dfeb1a4eb6e31c\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp312-cp312-linux_x86_64.whl size=55023 sha256=cb1650059dffaac3600be6c3ab1f5fdb89a87c4e82b2c44f1d2da493a7dbe062\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/3e/21/a739cbcc331a1ab45c326d6edbdac6118de4402f6076e30ff1\n",
            "Successfully built warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: warc3-wet-clueweb09, warc3-wet, pyjnius, cbor, zlib-state, unlzw3, trec-car-tools, lz4, lxml, ijson, deprecated, inscriptis, ir_datasets, pyterrier, python-terrier\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 6.0.2\n",
            "    Uninstalling lxml-6.0.2:\n",
            "      Successfully uninstalled lxml-6.0.2\n",
            "Successfully installed cbor-1.0.0 deprecated-1.3.1 ijson-3.4.0.post0 inscriptis-2.7.0 ir_datasets-0.5.11 lxml-5.4.0 lz4-4.4.5 pyjnius-1.7.0 pyterrier-1.0.0 python-terrier-1.0 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.10\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "!pip install numba\n",
        "!pip install bitarray\n",
        "!pip install numpy\n",
        "!pip install ir_measures\n",
        "!pip install python-terrier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGo6VN_bVMM0"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AngD9OEAVP9K"
      },
      "source": [
        "Importing Dataset, it checks whether it's on the drive and if it isn't then it is downloaded and finally we extract it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUqltGLWWVD_",
        "outputId": "efa133e0-c045-4791-b92f-8082491f0110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-25 07:59:52--  https://msmarco.z22.web.core.windows.net/msmarcoranking/collection.tar.gz\n",
            "Resolving msmarco.z22.web.core.windows.net (msmarco.z22.web.core.windows.net)... 20.150.34.1\n",
            "Connecting to msmarco.z22.web.core.windows.net (msmarco.z22.web.core.windows.net)|20.150.34.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1035009698 (987M) [application/octet-stream]\n",
            "Saving to: ‘collection.tar.gz’\n",
            "\n",
            "collection.tar.gz   100%[===================>] 987.06M  13.9MB/s    in 89s     \n",
            "\n",
            "2025-11-25 08:01:21 (11.1 MB/s) - ‘collection.tar.gz’ saved [1035009698/1035009698]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/collection.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptEC9c7MZ7dT",
        "outputId": "3ff8ebd5-286f-496d-d8e5-4be3aa9291d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "collection.tar.gz:\t 66.2% -- replaced with collection.tar\n"
          ]
        }
      ],
      "source": [
        "!gunzip -v collection.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRmp6p-yvM0Q"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho3MZcNquhoV"
      },
      "source": [
        "This function performs comprehensive text preprocessing on an input string s to prepare it for tasks like information retrieval, natural language processing, or machine learning. It applies a series of transformations to clean, normalize, and tokenize the text, ultimately returning a list of stemmed tokens. Here's a breakdown of each step:\n",
        "\n",
        "- Converts all characters in the string to lowercase using s.lower().\n",
        "Ensures uniformity and case-insensitive matching.\n",
        "\n",
        "- Uses a __translation table__ (map with single character keys) to replace symbols with their written forms. This improves semantic clarity and indexing.\n",
        "\n",
        "- Replaces visually similar or typographically styled characters with standard equivalents. Ensures consistent tokenization and avoids fragmentation.\n",
        "\n",
        "- Uses a regular expression to remove periods (.) unless they are part of acronyms (e.g., Ph.D, U.S.A).\n",
        "\n",
        "- Uses the contractions library to expand common English contractions. Improves semantic clarity and matching.\n",
        "\n",
        "- Builds a translation table from string.punctuation that replaces each punctuation character with a space to maintain word boundaries. Prevents punctuation from interfering with token matching.\n",
        "\n",
        "- Strips leading/trailing spaces. Replaces multiple consecutive spaces with a single space. Ensures clean token separation.\n",
        "\n",
        "- Splits the cleaned string into a list of tokens using s.split(). Basic whitespace-based tokenization.\n",
        "\n",
        "- Removes common English stopwords using NLTK's stopword list. Reduces noise and improves relevance in retrieval tasks.\n",
        "\n",
        "- Applies the Porter Stemmer from NLTK to each token. Reduces words to their root form (e.g., \"running\"  \"run\"). Improves generalization and matching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4Q9pJEqfz-F"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import contractions\n",
        "\n",
        "\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "def preprocess(\n",
        "  s: str\n",
        ") -> str:\n",
        "  \"\"\"\n",
        "    Preprocessing Function\n",
        "\n",
        "    Arguments:\n",
        "      s: String to be preprocessed\n",
        "\n",
        "    Returns:\n",
        "      Preprocessed string\n",
        "  \"\"\"\n",
        "\n",
        "  # Case Folding into lowercase using python built-in method\n",
        "  # of the string class\n",
        "  s = s.lower()\n",
        "\n",
        "  # Replacing some special characters with their written form\n",
        "  # using a translation table object for speed purposes\n",
        "  spec_chars_to_text = {\n",
        "    \"&\": \" and \",\n",
        "    \"|\": \" or \",\n",
        "    \"°\": \" degree\",\n",
        "  }\n",
        "  trans_table = str.maketrans(spec_chars_to_text)\n",
        "  s = s.translate(trans_table)\n",
        "\n",
        "  # Replacing some special character with a standard equivalent\n",
        "  # using a translation table for speed purposes\n",
        "  spec_chars_to_standard = {\n",
        "      \"‘\": \"'\",\n",
        "      \"’\": \"'\",\n",
        "      \"´\": \"'\",\n",
        "      \"“\": \"\\\"\",\n",
        "      \"”\": \"\\\"\",\n",
        "      \"–\": \"-\",\n",
        "      \"-\": \"-\"\n",
        "  }\n",
        "  trans_table = str.maketrans(spec_chars_to_standard)\n",
        "  s = s.translate(trans_table)\n",
        "\n",
        "  # Remove periods \".\" in acronyms (e.g., Ph.D, U.S.A) but not in decimals (e.g., 3.14)\n",
        "  # Regex breakdown:\n",
        "  # \\.           -> match a literal period\n",
        "  # (?!)         -> negative lookahead: only match if the following pattern does NOT occur\n",
        "  # (\\S[^. ])    -> a non-whitespace character followed by something that's NOT a period or space\n",
        "  # | \\d         -> OR a digit (preserve decimal points like \"3.14\")\n",
        "  s = re.sub(r\"\\.(?!(\\S[^. ])|\\d)\", \"\", s)\n",
        "\n",
        "  # Expanding contractions using a reliable python library\n",
        "  s = contractions.fix(s)\n",
        "\n",
        "  # Removing punctuation, done with the usual translation\n",
        "  # tables but starting from a built-in string with every symbol\n",
        "  table = str.maketrans(string.punctuation, ' ' * len(string.punctuation))  # the two strings must have the same length\n",
        "  s = s.translate(table)\n",
        "\n",
        "  # removes any leading, and trailing whitespaces\n",
        "  s = s.strip()\n",
        "  # removes any double whitespaces inside the string\n",
        "  while \"  \" in s:\n",
        "    s = s.replace(\"  \", \" \")\n",
        "\n",
        "  # Tokenizing using python string built-in method split\n",
        "  s_list = s.split()\n",
        "\n",
        "  # Removing Stopwords using the nltk library and list comprehension\n",
        "  stopwords = nltk.corpus.stopwords.words('english')\n",
        "  s_list = [token for token in s_list if token not in stopwords]\n",
        "\n",
        "  # Stemming using Porter\n",
        "  stemmer = nltk.stem.PorterStemmer().stem\n",
        "  s_list = [stemmer(t) for t in s_list]\n",
        "\n",
        "  return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3LAA19xhUVe"
      },
      "source": [
        "The preprocess() function is slow due to several inefficiencies that compound during repeated execution:\n",
        "1. it reloads the NLTK stopwords list every time the function runs, which is unnecessary and costly.\n",
        "2. it re-instantiates the Porter stemmer on each call instead of initializing it once globally.\n",
        "3. the function rebuilds translation tables for character replacements repeatedly, even though they remain constant.\n",
        "4. the regex are re-compiled every time the function is called\n",
        "5. while checking for double spaces \"  \"\n",
        "\n",
        "Thus we proceed improving those points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zIWP5dWffDq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import contractions\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Load once\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "STEM = PorterStemmer().stem\n",
        "\n",
        "# Precompile regex\n",
        "MULTISPACE_RE = re.compile(r\"\\s+\")\n",
        "ACRONYM_RE = re.compile(r\"\\.(?!(\\S[^. ])|\\d)\")\n",
        "\n",
        "# Translation tables\n",
        "TEXT_TRANS = str.maketrans({\"&\": \" and \", \"|\": \" or \", \"°\": \" degree\"})\n",
        "STANDARD_TRANS = str.maketrans({\n",
        "    \"‘\": \"'\", \"’\": \"'\", \"´\": \"'\", \"“\": \"\\\"\", \"”\": \"\\\"\", \"–\": \"-\", \"-\": \"-\"\n",
        "})\n",
        "PUNCT_TRANS = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "\n",
        "def preprocess(s: str) -> list:\n",
        "    s = s.lower()\n",
        "    s = s.translate(TEXT_TRANS)\n",
        "    s = s.translate(STANDARD_TRANS)\n",
        "    s = ACRONYM_RE.sub(\"\", s)\n",
        "    s = contractions.fix(s)\n",
        "    s = s.translate(PUNCT_TRANS)\n",
        "    s = MULTISPACE_RE.sub(\" \", s).strip()\n",
        "    tokens = s.split()\n",
        "    tokens = [STEM(t) for t in tokens if t not in STOPWORDS]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hytXywN0mdr"
      },
      "source": [
        "## Inverted Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soZ1hiJ4L8se"
      },
      "source": [
        "### Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5zulrVd-FXy"
      },
      "source": [
        "Defining a decorator to measure and print the execution time of a function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kUSdVIL01tE"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import Callable, Any\n",
        "\n",
        "def profile(\n",
        "  f: Callable[..., Any]\n",
        ") -> Callable[..., Any]:\n",
        "  \"\"\"\n",
        "    Decorator to measure and print the execution time of a function.\n",
        "\n",
        "    Args:\n",
        "        func (callable): The function to be timed.\n",
        "\n",
        "    Returns:\n",
        "        callable: Wrapped function with timing logic.\n",
        "    \"\"\"\n",
        "\n",
        "  # A general signature for a python function\n",
        "  def f_timer(*args, **kwargs):\n",
        "\n",
        "    # Measuring start and end time\n",
        "    start = time.time()\n",
        "    result = f(*args, **kwargs)\n",
        "    end = time.time()\n",
        "\n",
        "    # Actually computing and printing time execution in ms\n",
        "    ms = (end - start) * 1000\n",
        "    print(f\"{f.__name__} ({ms:.3f} ms)\")\n",
        "    return result\n",
        "\n",
        "  return f_timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCL6i9AeMAvu"
      },
      "source": [
        "### Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Xm-ArP_MO-"
      },
      "source": [
        "This function preprocesses a dataset and returns a list of tuples, where each tuple corresponds to a single document and contains two elements:\n",
        "- the document identifier (docno)\n",
        "- a list of preprocessed tokens extracted from the document's content.\n",
        "\n",
        "The output list preserves the original order of the dataset. This structure is useful for downstream tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIb8byoL095a"
      },
      "outputs": [],
      "source": [
        "@profile\n",
        "def load_and_preprocess_dataset(\n",
        "    filename: str,\n",
        "    max_docs: int = -1,\n",
        "    granularity: int = 10000\n",
        ") -> list:\n",
        "  \"\"\"\n",
        "    Loads and preprocesses a dataset from a tab-separated file.\n",
        "    Each line is expected to contain: docno, document_text.\n",
        "    Returns a list of tuples: (docno, list_of_tokens).\n",
        "\n",
        "    Arguments:\n",
        "      filename: filename of the dataset\n",
        "      maxdocs: maximum number of documents to process\n",
        "\n",
        "    Returns:\n",
        "      Preprocessed Dataset\n",
        "  \"\"\"\n",
        "\n",
        "  dataset = []\n",
        "\n",
        "  # Iterating over file line by line\n",
        "  with open(filename, 'r') as file:\n",
        "    for doc_ind, line in enumerate(file):\n",
        "\n",
        "      # First line is not a document, but an header (docno  document_text)\n",
        "      if doc_ind == 0:\n",
        "        continue\n",
        "\n",
        "      # Skipping malformed lines (not in the format docno<\\tab>document_text)\n",
        "      try:\n",
        "        docno, doc = line.strip().split('\\t')\n",
        "      except ValueError:\n",
        "        print(f\"Skipping malformed line {doc_ind}: {line.strip()}\")\n",
        "        continue\n",
        "\n",
        "      # Print checkpoints every granularity times\n",
        "      if doc_ind % granularity == 0:\n",
        "        print(f\"Processed {doc_ind} documents\")\n",
        "\n",
        "      # Preprocess document text and append structured entity\n",
        "      preprocessed_doc = preprocess(doc)\n",
        "      dataset.append((docno, preprocessed_doc))\n",
        "\n",
        "      # Early stopping for debugging (never actually used)\n",
        "      if max_docs > 0 and doc_ind + 1 >= max_docs:\n",
        "          break\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQxd5IacME_Y"
      },
      "source": [
        "### Index builder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goZYLPd3EOPZ"
      },
      "source": [
        "This function processes a tokenized document dataset to construct the core indexing structures required for an information retrieval system. For each document, it computes term frequencies and updates a lexicon that maps each unique term to a tuple containing its term ID, document frequency, and global term frequency. It also builds an inverted index composed of two dictionaries: one mapping each term ID to the list of document IDs where the term appears, and another mapping each term ID to the corresponding term frequencies in those documents. Additionally, it maintains a document index that records metadata for each document, including its identifier and length. Throughout the process, the function tracks collection-wide statistics such as the total number of documents, unique terms, and overall token count, which are essential for retrieval models and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuQEVloYEW2u"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "@profile\n",
        "def build_index(\n",
        "  dataset: list\n",
        ") -> tuple:\n",
        "  \"\"\"\n",
        "    Processes a tokenized document dataset to build core indexing structures\n",
        "    for an information retrieval system.\n",
        "\n",
        "    Returns four components:\n",
        "    1. lexicon: a dictionary mapping each unique term to a tuple (term_id,\n",
        "      document_frequency, collection frequency).\n",
        "    2. inverted index: two dictionaries mapping each term_id to:\n",
        "      - a list of document IDs where the term appears (`docids`)\n",
        "      - a list of corresponding term frequencies (`freqs`)\n",
        "    3. document index: a list mapping each document ID to its metadata (docno,\n",
        "      document length, URL, title).\n",
        "    4. collection statistics: a dictionary containing total number of documents,\n",
        "      unique terms, and total tokens.\n",
        "\n",
        "    This function iterates through each document, computes term frequencies,\n",
        "    updates the lexicon and posting lists, and tracks collection-wide\n",
        "    statistics for use in retrieval models or evaluation.\n",
        "\n",
        "    Arguments:\n",
        "      dataset: preprocessed dataset list(docno, list_tokens)\n",
        "\n",
        "    Returns:\n",
        "      lexicon, inverted_index, document_index, collection_statistics\n",
        "  \"\"\"\n",
        "\n",
        "  # Declaring some useful Data Structures:\n",
        "  lexicon = {}            # term : (termid, df, cf)\n",
        "  doc_index = []          # docid = (docno, doc_len)\n",
        "  inv_d, inv_f = {}, {}   # termid : docid | termid : tf\n",
        "\n",
        "  # Declaring some counter that will be used to compute Collection Statistics\n",
        "  # (num_tokens, num_docs, num_terms)\n",
        "  max_term_id = 0  # used as current id of the last added term in the vocabulary creation\n",
        "  num_docs = 0\n",
        "  num_tokens = 0\n",
        "  stats = {}\n",
        "\n",
        "  for docid, doc_info in enumerate(dataset):\n",
        "\n",
        "    docno, tokens = doc_info\n",
        "    token_tf = Counter(tokens) # iterable with (term, tf)\n",
        "\n",
        "    # For each (token, tf) checks if the token is not in the lexicon\n",
        "    # and then either add a new entry to the lexicon and a posting list\n",
        "    # or update the entry of the lexicon and append to the posting list\n",
        "    for token, tf in token_tf.items():\n",
        "\n",
        "      if token not in lexicon:\n",
        "        lexicon[token] = [max_term_id, 0, 0]  # [termid, df, cf]\n",
        "        inv_d[max_term_id], inv_f[max_term_id] = [], []\n",
        "        max_term_id += 1\n",
        "\n",
        "      lexicon[token][1] += 1    # df\n",
        "      lexicon[token][2] += tf   # cf\n",
        "      term_id = lexicon[token][0]\n",
        "      inv_d[term_id].append(docid)\n",
        "      inv_f[term_id].append(tf)\n",
        "\n",
        "    # Updating Document Index\n",
        "    doc_index.append((docno, len(tokens)))\n",
        "\n",
        "    # Updating collection statistics\n",
        "    num_docs += 1\n",
        "    num_tokens += len(tokens)\n",
        "\n",
        "  # Computing Statistics Collection\n",
        "  stats = {\n",
        "      'num_docs': num_docs,       # used in IDF\n",
        "      'num_terms': len(lexicon),  # never used\n",
        "      'num_tokens': num_tokens,   # never used\n",
        "      'average_document_length': num_tokens / num_docs # used in BM25 / BM11\n",
        "  }\n",
        "\n",
        "  return lexicon, {'docids': inv_d, 'freqs': inv_f}, doc_index, stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJLTkpTjMNwI"
      },
      "source": [
        "### Computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjtiStObx3ul"
      },
      "source": [
        "Both the preprocessing and index building phases are computationally intensive, resulting in long execution times. If an error or disconnection occurs during execution, the entire process would normally need to be repeated from the beginning.\n",
        "\n",
        "To address this, we will designed the preprocessing phase to operate in chunks as well as the indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IKyKX2my16Qy",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5615ac6d-c4b1-4b53-b862-43dfb1a182a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 10000 documents\n",
            "Processed 20000 documents\n",
            "Processed 30000 documents\n",
            "Processed 40000 documents\n",
            "Processed 50000 documents\n",
            "Processed 60000 documents\n",
            "Processed 70000 documents\n",
            "Processed 80000 documents\n",
            "Processed 90000 documents\n",
            "Processed 100000 documents\n",
            "Processed 110000 documents\n",
            "Processed 120000 documents\n",
            "Processed 130000 documents\n",
            "Processed 140000 documents\n",
            "Processed 150000 documents\n",
            "Processed 160000 documents\n",
            "Processed 170000 documents\n",
            "Processed 180000 documents\n",
            "Processed 190000 documents\n",
            "Processed 200000 documents\n",
            "Processed 210000 documents\n",
            "Processed 220000 documents\n",
            "Processed 230000 documents\n",
            "Processed 240000 documents\n",
            "Processed 250000 documents\n",
            "Processed 260000 documents\n",
            "Processed 270000 documents\n",
            "Processed 280000 documents\n",
            "Processed 290000 documents\n",
            "Processed 300000 documents\n",
            "Processed 310000 documents\n",
            "Processed 320000 documents\n",
            "Processed 330000 documents\n",
            "Processed 340000 documents\n",
            "Processed 350000 documents\n",
            "Processed 360000 documents\n",
            "Processed 370000 documents\n",
            "Processed 380000 documents\n",
            "Processed 390000 documents\n",
            "Processed 400000 documents\n",
            "Processed 410000 documents\n",
            "Processed 420000 documents\n",
            "Processed 430000 documents\n",
            "Processed 440000 documents\n",
            "Processed 450000 documents\n",
            "Processed 460000 documents\n",
            "Processed 470000 documents\n",
            "Processed 480000 documents\n",
            "Processed 490000 documents\n",
            "Processed 500000 documents\n",
            "Processed 510000 documents\n",
            "Processed 520000 documents\n",
            "Processed 530000 documents\n",
            "Processed 540000 documents\n",
            "Processed 550000 documents\n",
            "Processed 560000 documents\n",
            "Processed 570000 documents\n",
            "Processed 580000 documents\n",
            "Processed 590000 documents\n",
            "Processed 600000 documents\n",
            "Processed 610000 documents\n",
            "Processed 620000 documents\n",
            "Processed 630000 documents\n",
            "Processed 640000 documents\n",
            "Processed 650000 documents\n",
            "Processed 660000 documents\n",
            "Processed 670000 documents\n",
            "Processed 680000 documents\n",
            "Processed 690000 documents\n",
            "Processed 700000 documents\n",
            "Processed 710000 documents\n",
            "Processed 720000 documents\n",
            "Processed 730000 documents\n",
            "Processed 740000 documents\n",
            "Processed 750000 documents\n",
            "Processed 760000 documents\n",
            "Processed 770000 documents\n",
            "Processed 780000 documents\n",
            "Processed 790000 documents\n",
            "Processed 800000 documents\n",
            "Processed 810000 documents\n",
            "Processed 820000 documents\n",
            "Processed 830000 documents\n",
            "Processed 840000 documents\n",
            "Processed 850000 documents\n",
            "Processed 860000 documents\n",
            "Processed 870000 documents\n",
            "Processed 880000 documents\n",
            "Processed 890000 documents\n",
            "Processed 900000 documents\n",
            "Processed 910000 documents\n",
            "Processed 920000 documents\n",
            "Processed 930000 documents\n",
            "Processed 940000 documents\n",
            "Processed 950000 documents\n",
            "Processed 960000 documents\n",
            "Processed 970000 documents\n",
            "Processed 980000 documents\n",
            "Processed 990000 documents\n",
            "Processed 1000000 documents\n",
            "Processed 1010000 documents\n",
            "Processed 1020000 documents\n",
            "Processed 1030000 documents\n",
            "Processed 1040000 documents\n",
            "Processed 1050000 documents\n",
            "Processed 1060000 documents\n",
            "Processed 1070000 documents\n",
            "Processed 1080000 documents\n",
            "Processed 1090000 documents\n",
            "Processed 1100000 documents\n",
            "Processed 1110000 documents\n",
            "Processed 1120000 documents\n",
            "Processed 1130000 documents\n",
            "Processed 1140000 documents\n",
            "Processed 1150000 documents\n",
            "Processed 1160000 documents\n",
            "Processed 1170000 documents\n",
            "Processed 1180000 documents\n",
            "Processed 1190000 documents\n",
            "Processed 1200000 documents\n",
            "Processed 1210000 documents\n",
            "Processed 1220000 documents\n",
            "Processed 1230000 documents\n",
            "Processed 1240000 documents\n",
            "Processed 1250000 documents\n",
            "Processed 1260000 documents\n",
            "Processed 1270000 documents\n",
            "Processed 1280000 documents\n",
            "Processed 1290000 documents\n",
            "Processed 1300000 documents\n",
            "Processed 1310000 documents\n",
            "Processed 1320000 documents\n",
            "Processed 1330000 documents\n",
            "Processed 1340000 documents\n",
            "Processed 1350000 documents\n",
            "Processed 1360000 documents\n",
            "Processed 1370000 documents\n",
            "Processed 1380000 documents\n",
            "Processed 1390000 documents\n",
            "Processed 1400000 documents\n",
            "Processed 1410000 documents\n",
            "Processed 1420000 documents\n",
            "Processed 1430000 documents\n",
            "Processed 1440000 documents\n",
            "Processed 1450000 documents\n",
            "Processed 1460000 documents\n",
            "Processed 1470000 documents\n",
            "Processed 1480000 documents\n",
            "Processed 1490000 documents\n",
            "Processed 1500000 documents\n",
            "Processed 1510000 documents\n",
            "Processed 1520000 documents\n",
            "Processed 1530000 documents\n",
            "Processed 1540000 documents\n",
            "Processed 1550000 documents\n",
            "Processed 1560000 documents\n",
            "Processed 1570000 documents\n",
            "Processed 1580000 documents\n",
            "Processed 1590000 documents\n",
            "Processed 1600000 documents\n",
            "Processed 1610000 documents\n",
            "Processed 1620000 documents\n",
            "Processed 1630000 documents\n",
            "Processed 1640000 documents\n",
            "Processed 1650000 documents\n",
            "Processed 1660000 documents\n",
            "Processed 1670000 documents\n",
            "Processed 1680000 documents\n",
            "Processed 1690000 documents\n",
            "Processed 1700000 documents\n",
            "Processed 1710000 documents\n",
            "Processed 1720000 documents\n",
            "Processed 1730000 documents\n",
            "Processed 1740000 documents\n",
            "Processed 1750000 documents\n",
            "Processed 1760000 documents\n",
            "Processed 1770000 documents\n",
            "Processed 1780000 documents\n",
            "Processed 1790000 documents\n",
            "Processed 1800000 documents\n",
            "Processed 1810000 documents\n",
            "Processed 1820000 documents\n",
            "Processed 1830000 documents\n",
            "Processed 1840000 documents\n",
            "Processed 1850000 documents\n",
            "Processed 1860000 documents\n",
            "Processed 1870000 documents\n",
            "Processed 1880000 documents\n",
            "Processed 1890000 documents\n",
            "Processed 1900000 documents\n",
            "Processed 1910000 documents\n",
            "Processed 1920000 documents\n",
            "Processed 1930000 documents\n",
            "Processed 1940000 documents\n",
            "Processed 1950000 documents\n",
            "Processed 1960000 documents\n",
            "Processed 1970000 documents\n",
            "Processed 1980000 documents\n",
            "Processed 1990000 documents\n",
            "Processed 2000000 documents\n",
            "Processed 2010000 documents\n",
            "Processed 2020000 documents\n",
            "Processed 2030000 documents\n",
            "Processed 2040000 documents\n",
            "Processed 2050000 documents\n",
            "Processed 2060000 documents\n",
            "Processed 2070000 documents\n",
            "Processed 2080000 documents\n",
            "Processed 2090000 documents\n",
            "Processed 2100000 documents\n",
            "Processed 2110000 documents\n",
            "Processed 2120000 documents\n",
            "Processed 2130000 documents\n",
            "Processed 2140000 documents\n",
            "Processed 2150000 documents\n",
            "Processed 2160000 documents\n",
            "Processed 2170000 documents\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3036564280.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m a = load_and_preprocess_dataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m'/content/collection.tar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-785085702.py\u001b[0m in \u001b[0;36mf_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Measuring start and end time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3341886777.py\u001b[0m in \u001b[0;36mload_and_preprocess_dataset\u001b[0;34m(filename, max_docs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0;31m# Preprocess document text and append structured entity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mpreprocessed_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m       \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-955771780.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;31m# Stemming using Porter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/stem/porter.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word, to_lowercase)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step5a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step5b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/stem/porter.py\u001b[0m in \u001b[0;36m_step4\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mmeasure_gt_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         return self._apply_rule_list(\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             [\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/stem/porter.py\u001b[0m in \u001b[0;36m_apply_rule_list\u001b[0;34m(self, word, rules)\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;31m# Don't try any further rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "preprocessed_dataset = load_and_preprocess_dataset(\n",
        "  '/content/collection.tar'\n",
        ")\n",
        "\n",
        "lexicon, inverted_index, document_index, collection_statistics = build_index(preprocessed_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TP0Eyln0YZI"
      },
      "source": [
        "### Loading and Preprocessing 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6C-4fP8l0V2"
      },
      "source": [
        "We define a function that loads and preprocesses a specific subset of the dataset. This approach allows us to handle the dataset in manageable chunks: each subset is independently preprocessed and saved to disk. By doing so, we can later load each preprocessed subset individually and incrementally construct the inverted index, optimizing both memory usage and processing efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obw27AjY0b05"
      },
      "outputs": [],
      "source": [
        "@profile\n",
        "def load_and_preprocess_dataset_batch(\n",
        "  filename: str,\n",
        "  line_start: int,\n",
        "  line_end: int\n",
        "):\n",
        "  \"\"\"\n",
        "  Loads and preprocesses a dataset from a tab-separated file.\n",
        "  Each line is expected to contain: docno, document_text.\n",
        "  Returns a list of tuples: (docno, list_of_tokens).\n",
        "\n",
        "  Arguments:\n",
        "    filename: filename of the dataset\n",
        "    line_start: first line to load\n",
        "    line_end: last line to load\n",
        "\n",
        "  Returns:\n",
        "    Preprocessed Dataset\n",
        "  \"\"\"\n",
        "  assert line_end >= line_start\n",
        "  dataset = []\n",
        "\n",
        "  # Iterating over file line by line\n",
        "  with open(filename, 'r') as file:\n",
        "    for line_ind, line in enumerate(file):\n",
        "\n",
        "      # Finding the right batch\n",
        "      # This operation could be optimized but when operating with chunks\n",
        "      # of 10^5 lines this cost is negligible\n",
        "      if line_ind < line_start:\n",
        "        continue\n",
        "      if line_ind >= line_end:\n",
        "        break\n",
        "\n",
        "      # First line is not a document, but the header (docno  document_text)\n",
        "      if line_ind == 0:\n",
        "        continue\n",
        "\n",
        "      # Skipping malformed lines\n",
        "      try:\n",
        "        docno, doc = line.strip().split('\\t')\n",
        "      except ValueError:\n",
        "        print(f\"Skipping malformed line {line_ind}: {line.strip()}\")\n",
        "        continue\n",
        "\n",
        "      # Preprocess document text and append structured entity\n",
        "      preprocessed_doc = preprocess(doc)\n",
        "      dataset.append((docno, preprocessed_doc))\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ6l-C3wms4n"
      },
      "source": [
        "We use helper functions to store and retrieve Python objects from disk. This is achieved using the pickle library, which handles serialization (converting a Python object into a byte stream for storage) and deserialization (reconstructing the object from the stored byte stream). This allows us to efficiently save intermediate data and reload it when needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQLbHmb13Zgy"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def save_object(obj, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_object(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAt6YeujnJoh"
      },
      "source": [
        "This loop processes a large dataset in fixed-size chunks to optimize memory usage and enable incremental indexing. Each iteration loads and preprocesses a subset of the dataset defined by the granularity parameter, starting from a calculated line range based on chunk_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIXAv5_vnRaI",
        "outputId": "e4931372-1388-4771-df4a-138f887039ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8841824\n",
            "load_and_preprocess_dataset_batch (290531.407 ms)\n",
            "Chunk 0 stored as 'n_preprocessed_chunks_0'\n",
            "load_and_preprocess_dataset_batch (300421.321 ms)\n",
            "Chunk 1 stored as 'n_preprocessed_chunks_1'\n",
            "load_and_preprocess_dataset_batch (284955.432 ms)\n",
            "Chunk 2 stored as 'n_preprocessed_chunks_2'\n",
            "load_and_preprocess_dataset_batch (290458.543 ms)\n",
            "Chunk 3 stored as 'n_preprocessed_chunks_3'\n",
            "load_and_preprocess_dataset_batch (278484.198 ms)\n",
            "Chunk 4 stored as 'n_preprocessed_chunks_4'\n",
            "load_and_preprocess_dataset_batch (310484.432 ms)\n",
            "Chunk 5 stored as 'n_preprocessed_chunks_5'\n",
            "load_and_preprocess_dataset_batch (299484.111 ms)\n",
            "Chunk 6 stored as 'n_preprocessed_chunks_6'\n",
            "load_and_preprocess_dataset_batch (265330.990 ms)\n",
            "Chunk 7 stored as 'n_preprocessed_chunks_7'\n",
            "load_and_preprocess_dataset_batch (193740.198 ms)\n",
            "Chunk 8 stored as 'n_preprocessed_chunks_8'\n",
            "All chunks processed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the number of lines per chunk, the chunk from which we should\n",
        "# start and the path to the dataset\n",
        "granularity = 1000000\n",
        "chunk_id = 0\n",
        "dataset_path = '/content/collection.tar'\n",
        "\n",
        "# Counting the number of total lines to estimate the time needed for the work\n",
        "with open(dataset_path, 'r') as file:\n",
        "  num_lines = sum(1 for _line in file)\n",
        "print(num_lines)\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "  # Compute chunk delimiters and output filename\n",
        "  start_line = chunk_id * granularity\n",
        "  end_line = (chunk_id + 1) * granularity\n",
        "  filename = f\"n_preprocessed_chunks_{chunk_id}\"\n",
        "\n",
        "  # reach the end of file?\n",
        "  if start_line >= num_lines:\n",
        "    print(\"All chunks processed.\")\n",
        "    break\n",
        "\n",
        "  # Load and preprocess the current chunk\n",
        "  data_chunk = load_and_preprocess_dataset_batch(\n",
        "    dataset_path,\n",
        "    start_line,\n",
        "    end_line\n",
        "  )\n",
        "\n",
        "  # Save the preprocessed chunk to disk\n",
        "  save_object(data_chunk, filename)\n",
        "  print(f\"Chunk {chunk_id} stored as '{filename}'\")\n",
        "\n",
        "  # Move to the next chunk\n",
        "  chunk_id += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKScVf2ghNxt"
      },
      "source": [
        "### Index Builder 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfrBlx2dr-i3"
      },
      "source": [
        "Processes a tokenized batched document dataset to incrementally update core indexing structures (that are passed as parameters to the function) for an information retrieval system.\n",
        "An additional parameter is needed to allow this incremental update:\n",
        "- 'max_term_id'  that represent the current max term id of the data structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8cU7nyl3ZKS"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "@profile\n",
        "def build_index_batch(\n",
        "  dataset: list,   # batch dataset list(docno, list(tokens))\n",
        "  # -- partially built data structures --\n",
        "  lexicon: dict,\n",
        "  doc_index: list,\n",
        "  inv_d: dict,\n",
        "  inv_f: dict,\n",
        "  max_term_id: int,  # current max token id\n",
        "  num_docs: int,\n",
        "  num_tokens: int,\n",
        "  docid: int\n",
        ") -> tuple[int, int, int, int]:\n",
        "  \"\"\"\n",
        "    Processes a tokenized document dataset to build core indexing structures\n",
        "    for an information retrieval system.\n",
        "\n",
        "    Returns four components:\n",
        "    1. lexicon: a dictionary mapping each unique term to a tuple (term_id,\n",
        "      document_frequency, global_term_frequency).\n",
        "    2. inverted index: two dictionaries mapping each term_id to:\n",
        "      - a list of document IDs where the term appears (`docids`)\n",
        "      - a list of corresponding term frequencies (`freqs`)\n",
        "    3. document index: a list mapping each document ID to its metadata (docno,\n",
        "      document length, URL, title).\n",
        "    4. collection statistics: a dictionary containing total number of documents,\n",
        "      unique terms, and total tokens.\n",
        "\n",
        "    This function iterates through each document, computes term frequencies,\n",
        "    updates the lexicon and posting lists, and tracks collection-wide\n",
        "    statistics for use in retrieval models or evaluation.\n",
        "\n",
        "    Arguments:\n",
        "      dataset: preprocessed dataset\n",
        "\n",
        "    Returns:\n",
        "      lexicon, inverted_index, document_index, collection_statistics\n",
        "  \"\"\"\n",
        "\n",
        "  for doc_info in dataset:\n",
        "\n",
        "    # Extracting doc_info and building an iterable with (term, tf)\n",
        "    docid += 1\n",
        "    docno, tokens = doc_info\n",
        "    token_tf = Counter(tokens)\n",
        "\n",
        "    # For each (token, tf) checks if the token is not in the lexicon\n",
        "    # and then either add a new entry to the lexicon and a posting list\n",
        "    # or update the entry of the lexicon and append to the posting list\n",
        "    for token, tf in token_tf.items():\n",
        "\n",
        "      if token not in lexicon:\n",
        "        lexicon[token] = [max_term_id, 0, 0]  # [term_id, dc, cf]\n",
        "        inv_d[max_term_id], inv_f[max_term_id] = [], []\n",
        "        max_term_id += 1\n",
        "\n",
        "      lexicon[token][1] += 1\n",
        "      lexicon[token][2] += tf\n",
        "      term_id = lexicon[token][0]\n",
        "      inv_d[term_id].append(docid)\n",
        "      inv_f[term_id].append(tf)\n",
        "\n",
        "    # Updating Document Index\n",
        "    doc_index.append((docno, len(tokens)))\n",
        "    num_docs += 1\n",
        "    num_tokens += len(tokens)\n",
        "\n",
        "  return (\n",
        "    max_term_id,\n",
        "    num_docs,\n",
        "    num_tokens,\n",
        "    docid\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OetMa_VJpUPQ"
      },
      "source": [
        "Build the index structures in batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uptk3vUi_CUF"
      },
      "outputs": [],
      "source": [
        "lexicon = {}\n",
        "doc_index = []\n",
        "inv_d = {}\n",
        "inv_f = {}\n",
        "max_term_id = 0\n",
        "num_docs = 0\n",
        "num_tokens = 0\n",
        "docid = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q3kEiDjN_IuD",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d826b832-75b0-4dae-acc1-f312b0856cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build_index_batch (52174.121 ms)\n",
            "build_index_batch (56044.636 ms)\n",
            "build_index_batch (62034.245 ms)\n",
            "build_index_batch (64838.223 ms)\n",
            "build_index_batch (67483.323 ms)\n",
            "build_index_batch (70138.324 ms)\n",
            "build_index_batch (74204.421 ms)\n",
            "build_index_batch (90362.424 ms)\n",
            "build_index_batch (50494.332 ms)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "chunk_ids = [i for i in range(9)]\n",
        "\n",
        "for chunk_id in chunk_ids:\n",
        "\n",
        "  # Load the preprocessed data chunk from disk\n",
        "  filename = f\"n_preprocessed_chunks_{chunk_id}\"\n",
        "  chunk = load_object(filename)\n",
        "\n",
        "  # Update the inverted index and related metadata using the current chunk\n",
        "  max_term_id, num_docs, num_tokens, docid = build_index_batch(\n",
        "    chunk,\n",
        "    lexicon,\n",
        "    doc_index,\n",
        "    inv_d,\n",
        "    inv_f,\n",
        "    max_term_id,\n",
        "    num_docs,\n",
        "    num_tokens,\n",
        "    docid\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQj-HTjrmF0r"
      },
      "source": [
        "We are now generating statistics based on predefined variables, along with additional information computed dynamically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8VMIqU8XNWc"
      },
      "outputs": [],
      "source": [
        "stats = {\n",
        "    'num_docs': num_docs,\n",
        "    'num_terms': len(lexicon),\n",
        "    'num_tokens': num_tokens,\n",
        "    'average_document_length': num_tokens / num_docs\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wexp75-Yr-i5"
      },
      "source": [
        "Save data structures to .pkl file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgfRt6tSYjEh"
      },
      "outputs": [],
      "source": [
        "save_object(lexicon, 'lexicon')\n",
        "save_object(doc_index, 'doc_index')\n",
        "save_object(inv_d, 'inv_d')\n",
        "save_object(inv_f, 'inv_f')\n",
        "save_object(stats, 'stats')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1hKXWkVcfo9"
      },
      "source": [
        "The data are stored as list but loaded as np.arrays to take advantage of their computational efficiency and reduced memory footprint compared to standard Python structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f2IXtwnEDg6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "inv_f = load_object('inv_f')\n",
        "for term_id in inv_f:\n",
        "  inv_f[term_id] = np.array(inv_f[term_id], dtype=np.int32)\n",
        "\n",
        "inv_d = load_object('inv_d')\n",
        "for term_id in inv_d:\n",
        "  inv_d[term_id] = np.array(inv_d[term_id], dtype=np.int32)\n",
        "\n",
        "\n",
        "lexicon = load_object('lexicon')\n",
        "doc_index = load_object('doc_index')\n",
        "stats = load_object('stats')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQdWNNmn8TAz"
      },
      "source": [
        "## Disk Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ywuRlMT1Rpr"
      },
      "source": [
        "We now examine compression algorithms for storing posting lists on disk, focusing on both memory savings and the overhead introduced by compression and decompression times. This constitutes a preliminary study; in later sections of the notebook, we will extend the analysis to posting lists held in memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw9nTeEgdeoZ"
      },
      "source": [
        "### Delta Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSqiw1Ez9VZe"
      },
      "outputs": [],
      "source": [
        "def delta_encode(numbers):\n",
        "    \"\"\"\n",
        "    Applies delta compression to a sorted list of integers.\n",
        "    \"\"\"\n",
        "    if len(numbers) == 0:\n",
        "        return []\n",
        "\n",
        "    deltas = [numbers[0]]\n",
        "    for i in range(1, len(numbers)):\n",
        "        deltas.append(numbers[i] - numbers[i - 1])\n",
        "    return deltas\n",
        "\n",
        "def delta_decode(deltas):\n",
        "    \"\"\"\n",
        "    Reconstructs original list from delta-compressed integers.\n",
        "    \"\"\"\n",
        "    if len(deltas) == 0:\n",
        "        return []\n",
        "    numbers = [deltas[0]]\n",
        "    for i in range(1, len(deltas)):\n",
        "        numbers.append(numbers[-1] + deltas[i])\n",
        "    return numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfuS0kSTd2eD"
      },
      "source": [
        "### Variable Byte Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkJ4c4y2f_VY"
      },
      "source": [
        "We implement a set of helper functions to handle variable-byte (VB) encoding, which are responsible for efficiently converting integer values into a compact byte representation. In addition to these utilities, we develop a main function that takes as input the posting lists along with their docids and performs the actual encoding process. This function applies delta compression followed by VB encoding to reduce storage requirements and improve data retrieval efficiency.\n",
        "\n",
        "Once the encoding logic is implemented, we conduct a series of experiments to evaluate its performance. Specifically, we measure both the execution time and the memory usage during the encoding process. These tests aim to assess how well the approach optimizes resource consumption while maintaining correctness and scalability for larger datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff4uFgUpkek8"
      },
      "source": [
        "#### Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgJ5mSVzd5MQ"
      },
      "outputs": [],
      "source": [
        "def vb_encode_number(n):\n",
        "    \"\"\"\n",
        "    Encodes a single integer using variable-byte encoding.\n",
        "    \"\"\"\n",
        "    assert n >= 0  # negative numbers not supported\n",
        "\n",
        "    bytes_ = []\n",
        "    while True:\n",
        "        bytes_.insert(0, n % 128)  # prepend\n",
        "        if n < 128: # fits entirely in this byte (7 bits)\n",
        "            break\n",
        "        n = n // 128\n",
        "    bytes_[-1] += 128  # set continuation (end) bit on last byte to 1 (MSB = 1)\n",
        "    return bytes_\n",
        "\n",
        "def vb_encode_list(numbers):\n",
        "    \"\"\"\n",
        "    Encodes a list of integers using VB encoding.\n",
        "    Returns a bytearray.\n",
        "    \"\"\"\n",
        "    encoded_bytes = []\n",
        "    for number in numbers:\n",
        "        byte_list = vb_encode_number(number)\n",
        "        encoded_bytes.extend(byte_list) # extend the current list adding the byte list (VB is self-delimiting)\n",
        "    return bytearray(encoded_bytes) # effectively uses one byte for element, contrary to a python list\n",
        "\n",
        "def vb_decode(byte_stream):\n",
        "    \"\"\"\n",
        "    Decodes a byte stream using variable-byte decoding.\n",
        "    Returns a list of integers.\n",
        "    \"\"\"\n",
        "    numbers = []\n",
        "    n = 0\n",
        "    for byte in byte_stream:\n",
        "        if byte < 128:\n",
        "            n = 128 * n + byte\n",
        "        else:   # last byte\n",
        "            n = 128 * n + (byte - 128)\n",
        "            numbers.append(n)\n",
        "            n = 0  # reset local aggregator\n",
        "    return numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xFgsygr-i8"
      },
      "source": [
        "Delta encoding for inv_d is used to reduce the magnitude of the numbers by storing differences between consecutive values. This results in smaller, still positive integers, which improves the efficiency of Variable Byte (VB) encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ5_9mwReJTU"
      },
      "outputs": [],
      "source": [
        "@profile\n",
        "def delta_vb_encode_inv_d(\n",
        "  inv_d: dict,\n",
        ") -> None:\n",
        "\n",
        "  \"\"\"\n",
        "    It takes the posting lists along with their document ids\n",
        "    and directly applies delta compression and variable-byte\n",
        "    (VB) encoding to reduce RAM usage.\n",
        "\n",
        "    Arguments:\n",
        "      inv_d: inverted index with growing document ids\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  for term_id in inv_d:\n",
        "    inv_d[term_id] = delta_encode(inv_d[term_id])\n",
        "    inv_d[term_id] = vb_encode_list(inv_d[term_id])\n",
        "\n",
        "@profile\n",
        "def delta_vb_decode_inv_d(\n",
        "  inv_d: dict\n",
        ") -> None:\n",
        "\n",
        "  \"\"\"\n",
        "    It takes the posting lists along with their document ids\n",
        "    and directly applies delta compression and variable-byte\n",
        "    (VB) encoding to reduce RAM usage.\n",
        "\n",
        "    Arguments:\n",
        "      inv_d: inverted index with growing document ids\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  for term_id in inv_d:\n",
        "    inv_d[term_id] = vb_decode(inv_d[term_id])\n",
        "    inv_d[term_id] = delta_decode(inv_d[term_id])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or1DiPSPh85S"
      },
      "outputs": [],
      "source": [
        "@profile\n",
        "def vb_encode_inv_f(\n",
        "  inv_f: dict,\n",
        ") -> None:\n",
        "  \"\"\"\n",
        "    It takes the posting lists along with their term\n",
        "    frequencies and directly applies variable-byte (VB)\n",
        "    encoding to reduce RAM usage.\n",
        "\n",
        "    Arguments:\n",
        "      inv_f: inverted index with term frequencies\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  for term_id in inv_f:\n",
        "    inv_f[term_id] = vb_encode_list(inv_f[term_id])\n",
        "\n",
        "@profile\n",
        "def vb_decode_inv_f(\n",
        "  inv_f: dict\n",
        ") -> None:\n",
        "  \"\"\"\n",
        "    It takes the posting lists along with their term\n",
        "    frequencies and directly applies variable-byte (VB)\n",
        "    decoding to reduce RAM usage.\n",
        "\n",
        "    Arguments:\n",
        "      inv_f: inverted index with term frequencies\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  for term_id in inv_f:\n",
        "    inv_f[term_id] = vb_decode(inv_f[term_id])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A3XXN9uge6t"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MwdVeuRknRJ"
      },
      "source": [
        "In evaluating the performance and memory efficiency of posting list encoding and decoding, we report the overhead introduced by compression and decompression, quantify the memory savings achieved, and compare these results against a general-purpose ZIP algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0ZH1unefuWU",
        "outputId": "1b38b743-4130-41e4-d503-0e91d8f4d1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "delta_vb_encode_inv_d (110736.371 ms)\n",
            "delta_vb_decode_inv_d (98064.552 ms)\n"
          ]
        }
      ],
      "source": [
        "# Loading inv_d from disk\n",
        "inv_d = load_object('inv_d')\n",
        "\n",
        "# Encoding using Delta + Variabile-Byte Encoding\n",
        "delta_vb_encode_inv_d(inv_d)\n",
        "\n",
        "# Saving the encoded inv_d on disk\n",
        "save_object(inv_d, 'comp_inv_d')\n",
        "\n",
        "# Decoding using Variable-Byte + Delta Decoding\n",
        "delta_vb_decode_inv_d(inv_d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YUco4V32h4y"
      },
      "source": [
        "These are the compression results obtained with a general purpose compression algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx1ClXI8hE5d",
        "outputId": "776198ef-df0d-4743-ad17-4da46b1aee3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1G\tinv_d\n",
            "  adding: inv_d (deflated 58%)\n",
            "471M\ttest_inv_d.zip\n"
          ]
        }
      ],
      "source": [
        "!du -sh inv_d\n",
        "!zip test_inv_d.zip inv_d\n",
        "!du -sh test_inv_d.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7Z1jpc2nr9"
      },
      "source": [
        "These are the compression results obtained using Delta + Variable-Byte Encoding, which are slightly better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHSrkJDZfx_c",
        "outputId": "37c053d8-156c-4f5e-a9ee-d23e2ba815ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1G\tinv_d\n",
            "332M\tcomp_inv_d\n"
          ]
        }
      ],
      "source": [
        "!du -sh inv_d\n",
        "!du -sh comp_inv_d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx4HoLk-ilN6"
      },
      "source": [
        "Same procedure applied to inv_f (of course without Delta Encoding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wQzd9oeit_k",
        "outputId": "7ded9af4-8fd8-41cc-c1c0-d49d0e9de14d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vb_encode_inv_f (69061.333 ms)\n",
            "vb_decode_inv_f (36405.070 ms)\n"
          ]
        }
      ],
      "source": [
        "# Loading inv_f from disk\n",
        "inv_f = load_object('inv_f')\n",
        "\n",
        "# Encoding inv_f using Variably-Byte Encoding\n",
        "vb_encode_inv_f(inv_f)\n",
        "\n",
        "# Storing compressed inv_f on disk\n",
        "save_object(inv_f, 'comp_inv_f')\n",
        "\n",
        "# Decoding inv_f using Variably-Byte Decoding\n",
        "vb_decode_inv_f(inv_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4nH487nuot9",
        "outputId": "b4d60866-3c35-49ec-9cc0-91d5f8ccf9ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: inv_f (deflated 89%)\n",
            "52M\tinv_f.zip\n"
          ]
        }
      ],
      "source": [
        "!zip inv_f.zip inv_f\n",
        "!du -sh inv_f.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EIWaSSDiwHR",
        "outputId": "0f7294c5-0df1-48dc-cbe5-eb698f0232f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "455M\tinv_f\n",
            "244M\tcomp_inv_f\n"
          ]
        }
      ],
      "source": [
        "!du -sh inv_f\n",
        "!du -sh comp_inv_f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWqXO0KNeBu6"
      },
      "source": [
        "### Gamma Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5yqiqC-AjpV"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGARPiV2eD3w"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def gamma_encode_number(n):\n",
        "    \"\"\"\n",
        "    Encodes a single positive integer using Elias gamma encoding.\n",
        "    \"\"\"\n",
        "    if n <= 0:\n",
        "        raise ValueError(\"Gamma encoding only supports positive integers.\")\n",
        "\n",
        "    binary = bin(n)[2:]  # get the str binary representation of n and remove '0b' prefix\n",
        "    offset = binary[1:]  # remove leading '1' always present in bin() representation\n",
        "    length = len(offset)\n",
        "    unary = '0' * length + '1' # write the unary representation of bin(n)\n",
        "    return unary + offset  # concatenate the two strings\n",
        "\n",
        "def gamma_encode_list(numbers):\n",
        "    \"\"\"\n",
        "    Encodes a list of positive integers using Elias gamma encoding.\n",
        "    Returns a string of bits.\n",
        "    Padding is made of 0s because when decoding the padding won't\n",
        "    make a decodable number\n",
        "    \"\"\"\n",
        "    encoded_list = ''.join(gamma_encode_number(n) for n in numbers)\n",
        "    return encoded_list\n",
        "\n",
        "def gamma_decode(bitstream):\n",
        "    \"\"\"\n",
        "    Decodes a bitstream encoded with Elias gamma encoding.\n",
        "    Returns a list of integers.\n",
        "    \"\"\"\n",
        "    numbers = []\n",
        "    i = 0\n",
        "    while i < len(bitstream):\n",
        "        # Read unary prefix (length of offset)\n",
        "        length = 0\n",
        "        decodable = False\n",
        "        while i < len(bitstream) and bitstream[i] == '0':\n",
        "            decodable = True\n",
        "            length += 1\n",
        "            i += 1\n",
        "        i += 1  # add the skipped '1' delimiter at the end of the length\n",
        "\n",
        "        if not decodable:  # TODO: a che serve?\n",
        "          continue\n",
        "\n",
        "        # Read offset bits\n",
        "        offset = bitstream[i:i + length]\n",
        "        i += length\n",
        "\n",
        "        binary = '1' + offset  # add the 1 that was redundant in encoding\n",
        "        numbers.append(int(binary, 2))\n",
        "    return numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da9r3nyzkNm8"
      },
      "outputs": [],
      "source": [
        "@profile\n",
        "def delta_gamma_encode_inv_d(\n",
        "  inv_d: dict\n",
        ") -> None:\n",
        "\n",
        "  \"\"\"\n",
        "    It takes the posting lists along with their document ids\n",
        "    and directly applies delta compression and gamma encoding\n",
        "    to reduce RAM usage.\n",
        "\n",
        "    Arguments:\n",
        "      inv_d: inverted index with growing document ids\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  for term_id in inv_d:\n",
        "    inv_d[term_id] = delta_encode(inv_d[term_id])\n",
        "    inv_d[term_id] = gamma_encode_list(inv_d[term_id])\n",
        "\n",
        "@profile\n",
        "def delta_gamma_decode_inv_d(\n",
        "  inv_d: dict\n",
        ") -> None:\n",
        "\n",
        "  \"\"\"\n",
        "    It takes the posting lists along with their document ids\n",
        "    and directly applies delta compression and gamma decoding\n",
        "    to reduce RAM usage.\n",
        "\n",
        "    Arguments:\n",
        "      inv_d: inverted index with growing document ids\n",
        "\n",
        "    Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  for term_id in inv_d:\n",
        "    inv_d[term_id] = gamma_decode(inv_d[term_id])\n",
        "    inv_d[term_id] = delta_decode(inv_d[term_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It6u3-c2AmUH"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z17M1YVM3WIF"
      },
      "source": [
        "We are also experimenting with Gamma Encoding.\n",
        "However, because Python lacks efficient native methods for bit manipulation, the algorithm is expected to run slowly and is unlikely to deliver significant memory improvements compared to variable-byte encoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4K6IMQcr-jB",
        "outputId": "4f91665d-2c3c-4b26-f04f-2e2ad1f6d09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "delta_gamma_encode_inv_d (172095.841 ms)\n",
            "321223005.0\n",
            "delta_gamma_decode_inv_d (381073.575 ms)\n"
          ]
        }
      ],
      "source": [
        "# Load the inverted index object from disk\n",
        "inv_d = load_object('inv_d')\n",
        "\n",
        "# Apply delta + gamma encoding to the inverted index\n",
        "# This will compress the posting lists associated with each term\n",
        "delta_gamma_encode_inv_d(inv_d)\n",
        "\n",
        "# Initialize a counter for the total number of bits used\n",
        "bits_used = 0\n",
        "\n",
        "# Iterate over each term in the inverted index\n",
        "for term_id in inv_d:\n",
        "    # Add the length (in bits) of the encoded posting list for this term (characters as bits)\n",
        "    bits_used += len(inv_d[term_id])\n",
        "\n",
        "# Convert the total bit count into bytes (divide by 8) and print the result\n",
        "print(bits_used / 8)\n",
        "\n",
        "# Decode the inverted index back to its original form\n",
        "# This ensures that the encoding/decoding process is reversible and correct\n",
        "decoded_inv_d = delta_gamma_decode_inv_d(inv_d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb3YQF6Zr-jC"
      },
      "source": [
        "VB Encoding\n",
        "\n",
        "| Dataset | Original Size | Compressed Size | Encode Time (ms) | Decode Time (ms) |\n",
        "| ------- | ------------- | --------------- | ---------------- | ---------------- |\n",
        "| inv_d   | 1.1 G         | 332 M           | 110,736.371      | 98,064.552       |\n",
        "| inv_f   | 455 M         | 244 M           | 69,061.333       | 36,405.070       |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOg4FHjXr-jC"
      },
      "source": [
        "Gamma Encoding\n",
        "\n",
        "| Dataset | Original Size | Compressed Size | Encode Time (ms) | Decode Time (ms) |\n",
        "| ------- | ------------- | --------------- | ---------------- | ---------------- |\n",
        "| inv_d   | 1.1 G         | 321 M           | 172,095.841      | 381,073.575      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhgcRwd2KfBT"
      },
      "source": [
        "The compression for gamma encoding is slightly better than byte-variable encoding, but the improvement doesn't justify the additional encoding/decoding cost. I also won't apply it to the posting lists with frequencies, since it would not compress efficiently as we cannot use of delta compression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyMSmclmAsGr"
      },
      "source": [
        "## Boolean Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgZGxTliAxoN"
      },
      "source": [
        "To validate the implementation, we develop a set of simple Boolean retrieval algorithms (AND & OR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q05ADB5jfSsi"
      },
      "source": [
        "### Inverted Index Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSARpdSCfWZ2"
      },
      "source": [
        "A simple class for the Inverted Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoSN5nTTdv5H"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "\n",
        "class InvertedIndex:\n",
        "\n",
        "    class PostingListIterator:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Iterator over a posting list for a single term in the inverted index.\n",
        "        Arguments:\n",
        "            docids (np.ndarray): Array of document IDs containing the term.\n",
        "            freqs (np.ndarray): Array of term frequencies corresponding to docids.\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, docids: np.ndarray, freqs: np.ndarray):\n",
        "            self.docids = docids\n",
        "            self.freqs = freqs\n",
        "            self.pos = 0\n",
        "\n",
        "        def docid(self) -> int | float:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the current document ID.\n",
        "            Returns:\n",
        "                int: Current document ID, or math.inf if iterator is at the end.\n",
        "            \"\"\"\n",
        "            return math.inf if self._is_end_list() else self.docids[self.pos]\n",
        "\n",
        "        def score(self):\n",
        "            pass\n",
        "\n",
        "        def next(self, target: Optional[int] = None):\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Advances the iterator. If target is provided, jump to the first document\n",
        "                with ID >= target.\n",
        "            Arguments:\n",
        "                target (Optional[int]): Target document ID to skip to. Default is None.\n",
        "            \"\"\"\n",
        "            if target is None:\n",
        "                if not self._is_end_list():\n",
        "                    self.pos += 1\n",
        "            elif target > self.docid():\n",
        "                # first document with ID >= target\n",
        "                self.pos = np.searchsorted(self.docids, target, side='left')\n",
        "\n",
        "        def len(self) -> int:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the number of documents in the posting list.\n",
        "            Returns:\n",
        "                int: Length of the posting list.\n",
        "            \"\"\"\n",
        "            return len(self.docids)\n",
        "\n",
        "        def _is_end_list(self) -> bool:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Checks whether the iterator has reached the end of the posting list.\n",
        "            Returns:\n",
        "                bool: True if at end, False otherwise.\n",
        "            \"\"\"\n",
        "            return self.pos >= len(self.docids)\n",
        "\n",
        "    # ----------------- InvertedIndex main ----------------- #\n",
        "\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Inverted index storing the mapping from terms to posting lists, along with\n",
        "        document statistics.\n",
        "    Arguments:\n",
        "        lexicon (Dict[str, Tuple[int, ...]]): Maps token to (termid, df, cf) .\n",
        "        inv_d (List[np.ndarray]): List of arrays of document IDs per term.\n",
        "        inv_f (List[np.ndarray]): List of arrays of term frequencies per term.\n",
        "        stats (Dict[str, int]): Global statistics (num_docs, num_terms, num_tokens, average_document_length)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        lexicon: Dict[str, Tuple[int, ...]],\n",
        "        inv_d: List[np.ndarray],\n",
        "        inv_f: List[np.ndarray],\n",
        "        stats: Dict[str, int],\n",
        "    ):\n",
        "        self.lexicon = lexicon\n",
        "        self.inv_d = inv_d\n",
        "        self.inv_f = inv_f\n",
        "        self.stats = stats\n",
        "\n",
        "    def num_docs(self) -> int:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns the total number of documents in the index.\n",
        "        Returns:\n",
        "            int: Number of documents.\n",
        "        \"\"\"\n",
        "        return self.stats['num_docs']\n",
        "\n",
        "    def get_posting(self, termid: int) -> PostingListIterator:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a PostingListIterator for a given term ID.\n",
        "        Arguments:\n",
        "            termid (int): The term ID to retrieve the posting list for.\n",
        "        Returns:\n",
        "            PostingListIterator: Iterator over the posting list.\n",
        "        \"\"\"\n",
        "        return InvertedIndex.PostingListIterator(\n",
        "            self.inv_d[termid],\n",
        "            self.inv_f[termid],\n",
        "        )\n",
        "\n",
        "    def get_termids(self, tokens: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of term IDs for the tokens that exist in the lexicon.\n",
        "        Arguments:\n",
        "            tokens (List[str]): List of tokens to look up.\n",
        "        Returns:\n",
        "            List[int]: List of corresponding term IDs.\n",
        "        \"\"\"\n",
        "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
        "\n",
        "    def get_postings(self, termids: List[int]) -> List['PostingListIterator']:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of PostingListIterators for a list of term IDs.\n",
        "        Arguments:\n",
        "            termids (List[int]): List of term IDs.\n",
        "        Returns:\n",
        "            List[PostingListIterator]: List of posting list iterators.\n",
        "        \"\"\"\n",
        "        return [self.get_posting(termid) for termid in termids]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbqOrFOgfdz-"
      },
      "source": [
        "### Boolean And"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilities functions for boolean AND retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CyxE9ElfGNC"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Set\n",
        "\n",
        "@profile\n",
        "def boolean_and(\n",
        "    postings: List['InvertedIndex.PostingListIterator']\n",
        ") -> Set[int]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Computes the intersection of multiple posting lists (Boolean AND).\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "    Returns:\n",
        "        Set[int]: Set of document IDs present in all postings.\n",
        "    \"\"\"\n",
        "\n",
        "    if not postings:\n",
        "        return set()\n",
        "\n",
        "    # Sort postings by length (shortest first for efficiency)\n",
        "    # and creating result set (set of document ids)\n",
        "    postings = sorted(postings, key=lambda p: p.len())\n",
        "    results = set()\n",
        "\n",
        "    # 1) Initialize results with the first posting (docids that contains the query term with shortest posting)\n",
        "    #    keeping min and max docids to search faster subsequent postings\n",
        "    min_docid, max_docid = postings[0].docid(), postings[0].docid()\n",
        "    first_posting = postings[0]\n",
        "    while first_posting.docid() != math.inf:  # math.inf returned as last docid\n",
        "        results.add(first_posting.docid())\n",
        "        max_docid = first_posting.docid()\n",
        "        first_posting.next()\n",
        "\n",
        "    # 2) Intersect with remaining postings\n",
        "    for posting in postings[1:]:\n",
        "\n",
        "        # Jumping to the first possible match\n",
        "        posting.next(target=min_docid)\n",
        "        current_results = set()\n",
        "\n",
        "        # Iterating over posting while finding new min and max\n",
        "        # docids and also creating the new result set\n",
        "        n_min_docid, n_max_docid = -1, -1\n",
        "        while posting.docid() != math.inf:\n",
        "            doc_id = posting.docid()\n",
        "            if doc_id in results:\n",
        "                current_results.add(doc_id)   # implements the AND logic, adding only terms present in the prev postings and in the current\n",
        "                if n_min_docid == -1:\n",
        "                    n_min_docid = doc_id\n",
        "                n_max_docid = doc_id\n",
        "            elif doc_id > max_docid:  # previous founded max doc id\n",
        "                break\n",
        "            posting.next()\n",
        "\n",
        "        # Updating result set and max min indices and if result\n",
        "        # set is empty we can stop the execution\n",
        "        results = current_results\n",
        "        min_docid = n_min_docid\n",
        "        max_docid = n_max_docid\n",
        "        if not results:\n",
        "            return set()\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NefVE6cXhK90"
      },
      "outputs": [],
      "source": [
        "from typing import Set\n",
        "\n",
        "def query_process_and(\n",
        "    query: str,\n",
        "    index: InvertedIndex\n",
        ") -> Set[int]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Processes a query using Boolean AND retrieval on an inverted index.\n",
        "    Arguments:\n",
        "        query (str): Input query string.\n",
        "        index (InvertedIndex): Inverted index containing terms and posting lists.\n",
        "    Returns:\n",
        "        Set[int]: Set of document IDs that contain all query terms.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess query (e.g., tokenization, lowercasing, stemming)\n",
        "    qtokens: List[str] = preprocess(query)\n",
        "\n",
        "    # Map tokens to term IDs present in the index\n",
        "    qtermids: list[int] = index.get_termids(qtokens)\n",
        "\n",
        "    # Retrieve posting lists for the term IDs\n",
        "    postings: list['InvertedIndex.PostingListIterator'] = index.get_postings(qtermids)\n",
        "\n",
        "    # Perform Boolean AND on posting lists\n",
        "    return boolean_and(postings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4eU_POKihrj"
      },
      "source": [
        "We tested the code with the query: \"USA\". The result retrieved is correct (checked using Ctrl+F) in a reasonable time interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolean_and (397.352 ms)\n",
            "{np.int32(8363778), np.int32(8363779), np.int32(1339852), np.int32(1297), np.int32(707704), np.int32(4184601)}\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the InvertedIndex using the provided components:\n",
        "# - lexicon: mapping of terms to IDs\n",
        "# - inv_d: dictionary of posting lists (documents per term)\n",
        "# - inv_f: frequency information for terms\n",
        "# - stats: global statistics about the collection\n",
        "inv_ind = InvertedIndex(\n",
        "    lexicon,\n",
        "    inv_d,\n",
        "    inv_f,\n",
        "    stats\n",
        ")\n",
        "\n",
        "# Define the query string we want to search for\n",
        "query = \"USA mouse cat\"\n",
        "\n",
        "# Process the query using the AND operator.\n",
        "# This means we retrieve all documents that contain at least one of the query terms.\n",
        "result_docs = query_process_and(query, inv_ind)\n",
        "\n",
        "# Print the number of documents returned by the query\n",
        "print(result_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBaooHKui7zG"
      },
      "source": [
        "### Boolean Or"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set of helper functions for boolean OR retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvlg213-jBor"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List, Set\n",
        "\n",
        "@profile\n",
        "def boolean_or(\n",
        "    postings: List['InvertedIndex.PostingListIterator']\n",
        ") -> Set[int]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Computes the union of multiple posting lists (Boolean OR).\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "    Returns:\n",
        "        Set[int]: Set of document IDs present in any of the postings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Creating result sets and adding docids of each posting to the set\n",
        "    result = set()\n",
        "    for posting in postings:\n",
        "        while posting.docid() != math.inf:\n",
        "            result.add(posting.docid())\n",
        "            posting.next()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-NpMOiSk7Lv"
      },
      "outputs": [],
      "source": [
        "from typing import Set\n",
        "\n",
        "def query_process_or(\n",
        "    query: str,\n",
        "    index: InvertedIndex\n",
        ") -> Set[int]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Processes a query using Boolean OR retrieval on an inverted index.\n",
        "    Arguments:\n",
        "        query (str): Input query string.\n",
        "        index (InvertedIndex): Inverted index containing terms and posting lists.\n",
        "    Returns:\n",
        "        Set[int]: Set of document IDs that contain all query terms.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess query (e.g., tokenization, lowercasing, stemming)\n",
        "    qtokens: List[str] = preprocess(query)\n",
        "\n",
        "    # Map tokens to term IDs present in the index\n",
        "    qtermids: list[int] = index.get_termids(qtokens)\n",
        "\n",
        "    # Retrieve posting lists for the term IDs\n",
        "    postings: list['InvertedIndex.PostingListIterator'] = index.get_postings(qtermids)\n",
        "\n",
        "    # Perform Boolean AND on posting lists\n",
        "    return boolean_or(postings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa_1ovQilQeB"
      },
      "source": [
        "We tested the code with the query: \"USA\". The result is retrieved in a reasonable time interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolean_or (392.299 ms)\n",
            "77855\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the InvertedIndex using the provided components:\n",
        "# - lexicon: mapping of terms to IDs\n",
        "# - inv_d: dictionary of posting lists (docids per term)\n",
        "# - inv_f: dictionary of posting lists (term frequencies per term)\n",
        "# - stats: global statistics about the collection\n",
        "inv_ind = InvertedIndex(\n",
        "    lexicon,\n",
        "    inv_d,\n",
        "    inv_f,\n",
        "    stats\n",
        ")\n",
        "\n",
        "# Define the query string we want to search for\n",
        "query = \"USA cat\"\n",
        "\n",
        "# Process the query using the OR operator.\n",
        "# This means we retrieve all documents that contain at least one of the query terms.\n",
        "result_docs = query_process_or(query, inv_ind)\n",
        "\n",
        "# Print the number of documents returned by the query\n",
        "print(len(result_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDgs-J5ht-bB"
      },
      "source": [
        "## Ranked-Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBd6W2iquBMY"
      },
      "source": [
        "We implemented a range of scoring algorithms to explore different approaches to document ranking and retrieval effectiveness. We started with the simplest models, namely Term Frequency (TF) and Inverse Document Frequency (IDF), to establish a baseline understanding of how individual term occurrence and term rarity influence relevance scoring. Building upon these foundations, we combined the two into the well-known TF-IDF weighting scheme, which balances term importance within a document against its commonness across the entire collection. Finally, we implemented several members of the BM family of models, including BM11, BM15, and BM25, to examine how variations in term saturation and document length normalization affected retrieval performance and ranking accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS9pvevyTf9f"
      },
      "source": [
        "### Inverted Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnbqAPy6elmV"
      },
      "source": [
        "We extended the InvertedIndex class implemented above, by passing a scorer Callable object to easily implement the different scoring function (tf, idf, tf-idf, BM11, BM15, BM25)\n",
        "- **Flexible**: easy to swap scoring models\n",
        "- **Extensible**: supports experimentation with ranking functions\n",
        "\n",
        "The scorer function takes as input the PostingListIterator object in order to compute correctly the float score for the current term.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo5vSBg3Ou5n"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Callable, Optional\n",
        "\n",
        "\n",
        "class InvertedIndex:\n",
        "\n",
        "    class PostingListIterator:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Iterator over a posting list for a single term in the inverted index.\n",
        "        Arguments:\n",
        "            docids (np.ndarray): Array of document IDs containing the term.\n",
        "            freqs (np.ndarray): Array of term frequencies corresponding to docids.\n",
        "            doc (List[Tuple]): Dictionary storing document statistics (docid, length) \n",
        "            stats (Dict[str, int]): Global statistics (num_docs, num_terms, num_tokens, average_document_length)\n",
        "            scorer (Callable[['InvertedIndex.PostingListIterator'], float]): Callback scoring function \n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(\n",
        "            self,\n",
        "            docids: np.ndarray,\n",
        "            freqs: np.ndarray,\n",
        "            termid: int,\n",
        "            token: str,\n",
        "            lexicon: Dict[str, Tuple],\n",
        "            doc: List[Tuple],\n",
        "            stats: Dict[str, int],\n",
        "            scorer: Callable[['InvertedIndex.PostingListIterator'], float]\n",
        "        ):\n",
        "            self.docids = docids\n",
        "            self.freqs = freqs\n",
        "            self.pos = 0\n",
        "            self.termid = termid\n",
        "            self.token = token\n",
        "            self.lexicon = lexicon\n",
        "            self.doc = doc\n",
        "            self.stats = stats\n",
        "            self._scorer = scorer\n",
        "\n",
        "        def docid(self) -> int | float:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the current document ID.\n",
        "            Returns:\n",
        "                int: Current document ID, or math.inf if iterator is at the end.\n",
        "            \"\"\"\n",
        "            return math.inf if self._is_end_list() else self.docids[self.pos]\n",
        "\n",
        "        def score(self) -> float:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Computes the score for the current document, which is constant\n",
        "                for every document in the same posting\n",
        "            Returns:\n",
        "                float: Score for the current document, or math.inf if iterator is at the end.\n",
        "            \"\"\"\n",
        "            if self._is_end_list():\n",
        "                return math.inf\n",
        "            return self._scorer(self)\n",
        "\n",
        "        def next(self, target: Optional[int] = None):\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Advances the iterator. If target is provided, jump to the first document\n",
        "                with ID >= target.\n",
        "            Arguments:\n",
        "                target (Optional[int]): Target document ID to skip to. Default is None.\n",
        "            \"\"\"\n",
        "            if target is None:\n",
        "                if not self._is_end_list():\n",
        "                    self.pos += 1\n",
        "            elif target > self.docid():\n",
        "                self.pos = np.searchsorted(self.docids, target, side='left')\n",
        "\n",
        "        def len(self) -> int:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the number of documents in the posting list.\n",
        "            Returns:\n",
        "                int: Length of the posting list.\n",
        "            \"\"\"\n",
        "            return len(self.docids)\n",
        "\n",
        "        def _is_end_list(self) -> bool:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Checks whether the iterator has reached the end of the posting list.\n",
        "            Returns:\n",
        "                bool: True if at end, False otherwise.\n",
        "            \"\"\"\n",
        "            return self.pos >= len(self.docids)\n",
        "\n",
        "    # ----------------- InvertedIndex main ----------------- #\n",
        "\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Inverted index storing the mapping from terms to posting lists, along with\n",
        "        document statistics.\n",
        "    Arguments:\n",
        "        lexicon (Dict[str, Tuple[int, ...]]): Maps token to (termid, df, cf)\n",
        "        inv_d (List[np.ndarray]): List of arrays of document IDs per term.\n",
        "        inv_f (List[np.ndarray]): List of arrays of term frequencies per term.\n",
        "        doc (List[Tuple]): Document statistics list(docid, length)\n",
        "        stats (Dict[str, int]): Global statistics (num_docs, num_terms, num_tokens, average_document_length)\n",
        "        scorer (Callable[['InvertedIndex.PostingListIterator'], float]): Callback scoring function \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        lexicon: Dict[str, Tuple[int, ...]],\n",
        "        inv_d: List[np.ndarray],\n",
        "        inv_f: List[np.ndarray],\n",
        "        doc: List[Tuple],\n",
        "        stats: Dict[str, int],\n",
        "        scorer: Callable[['InvertedIndex.PostingListIterator'], float]\n",
        "    ):\n",
        "        self.lexicon = lexicon\n",
        "        self.inv_d = inv_d\n",
        "        self.inv_f = inv_f\n",
        "        self.doc = doc\n",
        "        self.stats = stats\n",
        "        self.scorer = scorer\n",
        "\n",
        "    def num_docs(self) -> int:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns the total number of documents in the index.\n",
        "        Returns:\n",
        "            int: Number of documents.\n",
        "        \"\"\"\n",
        "        return self.stats['num_docs']\n",
        "\n",
        "    def get_posting(self, termid: int, term: str) -> 'PostingListIterator':\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a PostingListIterator for a given term ID.\n",
        "        Arguments:\n",
        "            termid (int): The term ID to retrieve the posting list for.\n",
        "        Returns:\n",
        "            PostingListIterator: Iterator over the posting list.\n",
        "        \"\"\"\n",
        "        return InvertedIndex.PostingListIterator(\n",
        "            self.inv_d[termid],\n",
        "            self.inv_f[termid],\n",
        "            termid,\n",
        "            term,\n",
        "            self.lexicon,\n",
        "            self.doc,\n",
        "            self.stats,\n",
        "            self.scorer\n",
        "        )\n",
        "\n",
        "    def get_termids(self, tokens: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of term IDs for the tokens that exist in the lexicon.\n",
        "        Arguments:\n",
        "            tokens (List[str]): List of tokens to look up.\n",
        "        Returns:\n",
        "            List[int]: List of corresponding term IDs.\n",
        "        \"\"\"\n",
        "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
        "\n",
        "    def get_postings(\n",
        "        self,\n",
        "        termids: List[int],\n",
        "        terms: List[str]\n",
        "    ) -> List['PostingListIterator']:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of PostingListIterators for a list of term IDs.\n",
        "        Arguments:\n",
        "            termids (List[int]): List of term IDs.\n",
        "        Returns:\n",
        "            List[PostingListIterator]: List of posting list iterators.\n",
        "        \"\"\"\n",
        "        return [self.get_posting(termid, term) for termid, term in zip(termids, terms)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_FoJf6NW2mm"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jKXeP78fLb0"
      },
      "source": [
        "The functions and classes in this code collectively implement the core logic for ranked retrieval in an information retrieval (IR) system using two fundamental query evaluation strategies Term-at-a-Time (TAAT) and Document-at-a-Time (DAAT) along with a priority queue mechanism (TopQueue) for efficient ranking and top-k result management.\n",
        "\n",
        "At the foundation of this setup is the TopQueue class, which maintains the top-k highest-scoring documents encountered during retrieval. It uses a min-heap data structure (via Python's heapq module) to store document-score pairs, ensuring that insertion and removal are efficient (O(log k)). The queue dynamically updates its threshold the minimum score required for a document to remain in the top k as new results are inserted. This allows the system to discard low-scoring documents early, optimizing both time and memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9twYvvEASXIN"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "class TopQueue:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Maintains the top-k scored items in a min-heap with a dynamic threshold.\n",
        "    Arguments:\n",
        "        k (int): Maximum number of items to keep. Default is 10.\n",
        "        threshold (float): Minimum score required for an item to enter. Default is 0.0.\n",
        "    \"\"\"\n",
        "    def __init__(self, k: int = 10, threshold: float = 0.0):\n",
        "        self.queue: List[Tuple[float, int]] = []  # heap of (score, docid)\n",
        "        self.k: int = k\n",
        "        self.threshold: float = threshold\n",
        "\n",
        "    def size(self) -> int:\n",
        "        \"\"\"Returns the number of items currently in the queue.\"\"\"\n",
        "        return len(self.queue)\n",
        "\n",
        "    def would_enter(self, score: float) -> bool:\n",
        "        \"\"\"\n",
        "        Checks if a given score is high enough to enter the queue.\n",
        "        Arguments:\n",
        "            score (float): Score to test.\n",
        "        Returns:\n",
        "            bool: True if score exceeds current threshold.\n",
        "        \"\"\"\n",
        "        return score > self.threshold\n",
        "\n",
        "    def clear(self, new_threshold: float = -1):  # NOTE changed to -1 for types\n",
        "        \"\"\"\n",
        "        Clears the queue.\n",
        "        Arguments:\n",
        "            new_threshold (float, optional): If provided, updates the threshold.\n",
        "        \"\"\"\n",
        "        self.queue = []\n",
        "        if new_threshold >= 0.0:\n",
        "            self.threshold = new_threshold\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f'<TopQueue: {self.size()} items, th={self.threshold}, {self.queue}>'\n",
        "\n",
        "    def insert(self, docid: int, score: float) -> bool:\n",
        "        \"\"\"\n",
        "        Inserts a document with its score into the top-k queue if it exceeds the threshold.\n",
        "        Arguments:\n",
        "            docid (int): Document ID.\n",
        "            score (float): Score of the document.\n",
        "        Returns:\n",
        "            bool: True if the item was inserted, False otherwise.\n",
        "        \"\"\"\n",
        "        if score > self.threshold:\n",
        "            if self.size() >= self.k:\n",
        "                # Replace the smallest element if heap is full\n",
        "                heapq.heapreplace(self.queue, (score, docid))   # log(k)\n",
        "            else:\n",
        "                heapq.heappush(self.queue, (score, docid))      # log(k)\n",
        "\n",
        "            # Update threshold to the smallest score in the heap if full\n",
        "            if self.size() >= self.k:\n",
        "                self.threshold = max(self.threshold, self.queue[0][0])\n",
        "            return True\n",
        "\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The taat() function implements the Term-at-a-Time retrieval model. In this approach, the system processes one posting list (i.e., one term's document list) at a time. For each term, it iterates through all documents containing that term and accumulates their scores in a dictionary (doc_scores). Once all terms have been processed, the TopQueue selects and maintains the top-k highest-scoring documents. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxxvcbiCSjfA"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List, Set, Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "@profile\n",
        "def taat(\n",
        "    postings: List['InvertedIndex.PostingListIterator'],\n",
        "    k: int = 1000\n",
        ") -> List[Tuple[float, int]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Computes term-at-a-time (TAAT) scoring for a list of posting lists.\n",
        "        Accumulates scores for each document across all postings and returns\n",
        "        the top-k documents.\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "        k (int): Number of top-scoring documents to return. Default is 1000.\n",
        "    Returns:\n",
        "        List[Tuple[float, int]]: List of (score, docid) tuples, sorted in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    # Accumulate scores for each document\n",
        "    # Default dict is used since it allows automatic score initialization to 0.0 and then the += posting.score()\n",
        "    doc_scores: defaultdict[int, float] = defaultdict(float)\n",
        "    for posting in postings:\n",
        "        current_docid = posting.docid()\n",
        "        while current_docid != math.inf:\n",
        "            doc_scores[current_docid] += posting.score() # type: ignore since current_docid is not math.inf, thus int\n",
        "            posting.next()\n",
        "            current_docid = posting.docid()\n",
        "\n",
        "    # Use TopQueue to maintain top-k scores\n",
        "    top = TopQueue(k)\n",
        "    for docid, score in doc_scores.items():\n",
        "        top.insert(docid, score)\n",
        "\n",
        "    # Return top-k results sorted by score descending\n",
        "    return sorted(top.queue, reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The daat() function implements the Document-at-a-Time retrieval model. Instead of iterating term by term, DAAT traverses all posting lists simultaneously, aligning documents across terms by their IDs. The helper function min_docid() identifies the smallest document ID currently being pointed to across all posting lists, effectively synchronizing the iteration. For each document ID, the algorithm aggregates contributions (term scores) from all posting lists that include that document, computes a total score, and then inserts it into the TopQueue. Once processed, the posting lists advance to the next relevant document, and the loop continues until all lists are exhausted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHzg5FX_Sp46"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List, Set, Tuple\n",
        "\n",
        "\n",
        "def min_docid(\n",
        "    postings: List['InvertedIndex.PostingListIterator']\n",
        ") -> int | float:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Returns the smallest current docid among all posting list iterators.\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "    Returns:\n",
        "        int: Minimum current docid, or math.inf if all postings are exhausted.\n",
        "    \"\"\"\n",
        "    # iterating over the heads of the postings and returning the min\n",
        "    min_docid_value = math.inf\n",
        "    for p in postings:\n",
        "        if not p._is_end_list():\n",
        "            min_docid_value = min(p.docid(), min_docid_value)\n",
        "    return min_docid_value\n",
        "\n",
        "\n",
        "\n",
        "@profile\n",
        "def daat(\n",
        "    postings: List['InvertedIndex.PostingListIterator'],\n",
        "    k: int = 1000\n",
        ") -> List[Tuple[float, int]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Computes document-at-a-time (DAAT) scoring for a list of posting lists.\n",
        "        Scores each document across all postings simultaneously and returns\n",
        "        the top-k documents.\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "        k (int): Number of top-scoring documents to return. Default is 1000.\n",
        "    Returns:\n",
        "        List[Tuple[float, int]]: List of (score, docid) tuples, sorted in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    top = TopQueue(k)\n",
        "\n",
        "    # Initialize current_docid as the smallest docid among all postings\n",
        "    current_docid = min_docid(postings)\n",
        "\n",
        "    while current_docid != math.inf:\n",
        "        score = 0.0\n",
        "        next_docid = math.inf\n",
        "\n",
        "        for posting in postings:\n",
        "            if posting.docid() == current_docid:\n",
        "                score += posting.score()\n",
        "                posting.next()\n",
        "            if not posting._is_end_list():\n",
        "                next_docid = min(next_docid, posting.docid())\n",
        "\n",
        "        top.insert(current_docid, score) # type: ignore since current_docid != math.inf\n",
        "        current_docid = next_docid\n",
        "\n",
        "    # Return top-k results sorted by score descending\n",
        "    return sorted(top.queue, reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The query_process() function takes a raw query string, preprocesses it into tokens (using a preprocessing function such as stemming or stop-word removal), retrieves the corresponding term IDs from the inverted index, and obtains their posting list iterators. Depending on the specified retrieval mode (method parameter), it then calls either the TAAT or DAAT function to compute and return the top-k ranked results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waSE_1fWSvKC"
      },
      "outputs": [],
      "source": [
        "def query_process(\n",
        "    query: str,\n",
        "    index: InvertedIndex,\n",
        "    k: int = 1000,\n",
        "    method: str = \"D\"\n",
        ") -> List[Tuple[float, int]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Processes a query using TAAT or DAAT retrieval on an inverted index.\n",
        "    Arguments:\n",
        "        query (str): Input query string.\n",
        "        index (InvertedIndex): Inverted index containing terms and postings.\n",
        "        k (int): Number of top-scoring documents to return. Default is 1000.\n",
        "        method (str): Scoring method to use ('D' for DAAT, 'T' for TAAT). Default is 'D'.\n",
        "    Returns:\n",
        "        List[Tuple[float, int]]: List of top-k (score, docid) results.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess query into tokens\n",
        "    qtokens: List[str] = preprocess(query)\n",
        "\n",
        "    # Map tokens to term IDs\n",
        "    qtermids: List[int] = index.get_termids(qtokens)\n",
        "\n",
        "    # Retrieve posting lists for the term IDs\n",
        "    postings: List['InvertedIndex.PostingListIterator'] = index.get_postings(\n",
        "        qtermids,\n",
        "        qtokens\n",
        "    )\n",
        "\n",
        "    # Compute TAAT or DAAT top-k results\n",
        "    if method == \"D\":\n",
        "        return daat(postings, k)\n",
        "    else:\n",
        "        return taat(postings, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J6rluh0wSYz"
      },
      "source": [
        "### TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewTq01PIXAJX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TFScorer:\n",
        "    \"\"\"\n",
        "    TF scoring function.\n",
        "    Arguments:\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        posting: 'InvertedIndex.PostingListIterator'\n",
        "    ) -> float:\n",
        "\n",
        "        # Extracting term frequency and computing\n",
        "        tf: int = posting.freqs[posting.pos]\n",
        "        tf_w: float = np.log(1 + tf)\n",
        "\n",
        "        return tf_w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkP3357xbqz"
      },
      "source": [
        "The execution time is acceptable, and the test runs successfully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHeV9IY4xLCJ",
        "outputId": "4932c9a3-29d6-4cac-d85c-c7cc1e82fb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taat (534.696 ms)\n",
            "[(np.float64(3.6635616461296463), np.int32(1484875)), (np.float64(3.5553480614894135), np.int32(5733950)), (np.float64(3.401197381662155), np.int32(8363778)), (np.float64(3.401197381662155), np.int32(3874864)), (np.float64(3.295836866004329), np.int32(5733949)), (np.float64(3.295836866004329), np.int32(527509)), (np.float64(3.2188758248682006), np.int32(611370)), (np.float64(3.1780538303479453), np.int32(8363779)), (np.float64(3.1780538303479453), np.int32(3368134)), (np.float64(3.1780538303479453), np.int32(2397556))]\n",
            "daat (880.180 ms)\n",
            "[(np.float64(3.6635616461296463), np.int32(1484875)), (np.float64(3.5553480614894135), np.int32(5733950)), (np.float64(3.401197381662155), np.int32(8363778)), (np.float64(3.401197381662155), np.int32(3874864)), (np.float64(3.295836866004329), np.int32(5733949)), (np.float64(3.295836866004329), np.int32(527509)), (np.float64(3.2188758248682006), np.int32(611370)), (np.float64(3.1780538303479453), np.int32(8363779)), (np.float64(3.1780538303479453), np.int32(3368134)), (np.float64(3.1780538303479453), np.int32(2397556))]\n"
          ]
        }
      ],
      "source": [
        "scorer = TFScorer()\n",
        "inv_ind = InvertedIndex(\n",
        "  lexicon,\n",
        "  inv_d,\n",
        "  inv_f,\n",
        "  doc_index,\n",
        "  stats,\n",
        "  scorer = scorer\n",
        ")\n",
        "\n",
        "query = \"mouse cat USA\"\n",
        "print(query_process(query, inv_ind, 10, \"T\"))\n",
        "print(query_process(query, inv_ind, 10, \"D\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRUyB_omy0uf"
      },
      "source": [
        "### IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdICPRX1YDfn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class IDFScorer:\n",
        "    \"\"\"\n",
        "    IDF scoring function.\n",
        "    Arguments:\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        posting: 'InvertedIndex.PostingListIterator'\n",
        "    ) -> float:\n",
        "        # Extracting doc frequency, number of docs and computing idf weight\n",
        "        df: int = posting.lexicon[posting.token][1]\n",
        "        N: int = posting.stats['num_docs']\n",
        "        idf_w: float = np.log(N / df)\n",
        "\n",
        "        return idf_w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLvGyR_k1oCH"
      },
      "source": [
        "Time is acceptable and tests run successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiXjQ9sK1NQn",
        "outputId": "35c51aee-3107-4745-88da-834beae24ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taat (435.251 ms)\n",
            "[(np.float64(17.47011581576931), np.int32(8363779)), (np.float64(17.47011581576931), np.int32(8363778)), (np.float64(17.47011581576931), np.int32(4184601)), (np.float64(17.47011581576931), np.int32(1339852)), (np.float64(17.47011581576931), np.int32(707704)), (np.float64(17.47011581576931), np.int32(1297)), (np.float64(12.083379111121442), np.int32(232930)), (np.float64(12.083379111121442), np.int32(158694)), (np.float64(12.083379111121442), np.int32(130458)), (np.float64(12.083379111121442), np.int32(1298))]\n",
            "daat (796.148 ms)\n",
            "[(np.float64(17.47011581576931), np.int32(8363779)), (np.float64(17.47011581576931), np.int32(8363778)), (np.float64(17.47011581576931), np.int32(4184601)), (np.float64(17.47011581576931), np.int32(1339852)), (np.float64(17.47011581576931), np.int32(707704)), (np.float64(17.47011581576931), np.int32(1297)), (np.float64(12.083379111121442), np.int32(387050)), (np.float64(12.083379111121442), np.int32(343339)), (np.float64(12.083379111121442), np.int32(285045)), (np.float64(12.083379111121442), np.int32(257579))]\n"
          ]
        }
      ],
      "source": [
        "scorer = IDFScorer()\n",
        "inv_ind = InvertedIndex(\n",
        "  lexicon,\n",
        "  inv_d,\n",
        "  inv_f,\n",
        "  doc_index,\n",
        "  stats,\n",
        "  scorer\n",
        ")\n",
        "\n",
        "query = \"mouse cat USA\"\n",
        "print(query_process(query, inv_ind, 10, \"T\"))\n",
        "print(query_process(query, inv_ind, 10, \"D\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRrcF4bg2UeA"
      },
      "source": [
        "### TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO-60eHfRF0W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TFIDFScorer:\n",
        "    \"\"\"\n",
        "    TF-IDF scoring function.\n",
        "    Arguments:\n",
        "    \"\"\"\n",
        "    def __call__(\n",
        "        self,\n",
        "        posting: 'InvertedIndex.PostingListIterator'\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Computes the TF-IDF score for a given posting.\n",
        "        \"\"\"\n",
        "        # Extracting term frequency, doc frequency and number of docs\n",
        "        tf = posting.freqs[posting.pos]\n",
        "        df = posting.lexicon[posting.token][1]\n",
        "        N = posting.stats['num_docs']\n",
        "\n",
        "        # Computing tf-idf weight\n",
        "        tf_w = np.log(1 + tf)\n",
        "        idf_w = np.log(N / df)\n",
        "        tf_idf_w = tf_w * idf_w\n",
        "\n",
        "        return tf_idf_w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWFuoyNd4sgy"
      },
      "source": [
        "Time is acceptable and tests run successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKIW6UVW4rbb",
        "outputId": "36679c1c-b4d4-4f43-923a-62fdc4fefc93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taat (638.263 ms)\n",
            "[(np.float64(22.900067434274966), np.int32(1484875)), (np.float64(21.675178999018136), np.int32(5733950)), (np.float64(20.54869052963537), np.int32(5733949)), (np.float64(20.44338616312423), np.int32(3874864)), (np.float64(20.39084744942713), np.int32(8363778)), (np.float64(19.447448451753104), np.int32(611370)), (np.float64(18.913448568973624), np.int32(8363779)), (np.float64(18.35688035827288), np.int32(4430168)), (np.float64(18.003621091775226), np.int32(527509)), (np.float64(17.970049571299597), np.int32(7150429))]\n",
            "daat (1006.136 ms)\n",
            "[(np.float64(22.900067434274966), np.int32(1484875)), (np.float64(21.675178999018136), np.int32(5733950)), (np.float64(20.54869052963537), np.int32(5733949)), (np.float64(20.44338616312423), np.int32(3874864)), (np.float64(20.39084744942713), np.int32(8363778)), (np.float64(19.447448451753104), np.int32(611370)), (np.float64(18.913448568973624), np.int32(8363779)), (np.float64(18.35688035827288), np.int32(4430168)), (np.float64(18.003621091775226), np.int32(527509)), (np.float64(17.970049571299597), np.int32(7150429))]\n"
          ]
        }
      ],
      "source": [
        "scorer = TFIDFScorer()\n",
        "inv_ind = InvertedIndex(\n",
        "  lexicon,\n",
        "  inv_d,\n",
        "  inv_f,\n",
        "  doc_index,\n",
        "  stats,\n",
        "  scorer\n",
        ")\n",
        "\n",
        "query = \"mouse cat USA\"\n",
        "print(query_process(query, inv_ind, 10, \"T\"))\n",
        "print(query_process(query, inv_ind, 10, \"D\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mr18ilKYceV"
      },
      "source": [
        "### BM15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAL9b5e3Ssyk"
      },
      "outputs": [],
      "source": [
        "class BM15Scorer:\n",
        "    \"\"\"\n",
        "    BM15 scoring function.\n",
        "    Arguments:\n",
        "        k1 (float): Term frequency saturation parameter.\n",
        "    \"\"\"\n",
        "    def __init__(self, k1: float = 1.2):\n",
        "        self.k1: float = k1\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        posting: 'InvertedIndex.PostingListIterator'\n",
        "    ) -> float:\n",
        "        # Extracting term frequency, number of documents and doc frequency\n",
        "        tf: int = posting.freqs[posting.pos]\n",
        "        N: int = posting.stats['num_docs']\n",
        "        df: int = posting.lexicon[posting.token][1]\n",
        "\n",
        "        # Computing bm1 weight with the actual formula\n",
        "        bm1: float = np.log((N - df + 0.5) / (df + 0.5))\n",
        "\n",
        "        # Computing the Bounded TF weight approximation\n",
        "        # and BM15 = BM1 * (tf) / (k_1 + tf)\n",
        "        tf_approx: float = tf / (self.k1 + tf)\n",
        "        bm15: float = bm1 * tf_approx\n",
        "\n",
        "        return bm15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-UjJGsraXIq"
      },
      "source": [
        "Time is almost acceptable and tests run successfully (we will worry about making it faster later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiyK2PAWY4kq",
        "outputId": "e5ae7d7c-ae3d-4559-8066-3993b442067d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taat (672.266 ms)\n",
            "[(np.float64(10.949743618358667), np.int32(8363778)), (np.float64(10.586036503821358), np.int32(8363779)), (np.float64(9.71489299972576), np.int32(5733950)), (np.float64(9.65394411103718), np.int32(1339852)), (np.float64(9.493729408374108), np.int32(3874864)), (np.float64(9.381535166040274), np.int32(1484875)), (np.float64(9.290568032765567), np.int32(611370)), (np.float64(9.167478520133201), np.int32(5733949)), (np.float64(8.926860918228257), np.int32(7150429)), (np.float64(8.926860918228257), np.int32(7150428))]\n",
            "daat (1043.604 ms)\n",
            "[(np.float64(10.949743618358667), np.int32(8363778)), (np.float64(10.586036503821358), np.int32(8363779)), (np.float64(9.71489299972576), np.int32(5733950)), (np.float64(9.65394411103718), np.int32(1339852)), (np.float64(9.493729408374108), np.int32(3874864)), (np.float64(9.381535166040274), np.int32(1484875)), (np.float64(9.290568032765567), np.int32(611370)), (np.float64(9.167478520133201), np.int32(5733949)), (np.float64(8.926860918228257), np.int32(7150429)), (np.float64(8.926860918228257), np.int32(7150428))]\n"
          ]
        }
      ],
      "source": [
        "scorer = BM15Scorer()\n",
        "inv_ind = InvertedIndex(\n",
        "  lexicon,\n",
        "  inv_d,\n",
        "  inv_f,\n",
        "  doc_index,\n",
        "  stats,\n",
        "  scorer\n",
        ")\n",
        "\n",
        "query = \"mouse cat USA\"\n",
        "print(query_process(query, inv_ind, 10, \"T\"))\n",
        "print(query_process(query, inv_ind, 10, \"D\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndrn_el7SR-1"
      },
      "source": [
        "### BM11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-nJj-GSWW64"
      },
      "outputs": [],
      "source": [
        "class BM11Scorer:\n",
        "    \"\"\"\n",
        "    BM11 scoring function.\n",
        "    Arguments:\n",
        "        k1 (float): Term frequency saturation parameter.\n",
        "    \"\"\"\n",
        "    def __init__(self, k1: float = 1.2):\n",
        "        self.k1: float = k1\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        posting: 'InvertedIndex.PostingListIterator'\n",
        "    ) -> float:\n",
        "        # Extracting term frequency, number of documents and doc frequency\n",
        "        tf: int = posting.freqs[posting.pos]\n",
        "        N: int = posting.stats['num_docs']\n",
        "        df: int = posting.lexicon[posting.token][1]\n",
        "\n",
        "        # Computing bm1 weight with the actual formula\n",
        "        bm1: float = np.log((N - df + 0.5) / (df + 0.5))\n",
        "\n",
        "        # Computing tilde tf, then the Bounded TF weight approximation\n",
        "        # and finally BM11 = BM1 * (tf') / (k_1 + tf')  \n",
        "        dl: int = posting.doc[posting.docid() - 1][1] # type: ignore\n",
        "        avg_dl: int = posting.stats['average_document_length']\n",
        "        tf_tilde: float = tf * avg_dl / dl\n",
        "        tf_approx: float = tf_tilde / (self.k1 + tf_tilde)\n",
        "        bm11: float = bm1 * tf_approx  \n",
        "\n",
        "        return bm11\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UezMHis-ahNn"
      },
      "source": [
        "Time is almost acceptable and tests run successfully (we will worry about making it faster later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XOkRr4rY-l7",
        "outputId": "8e46ba14-502c-43ab-f470-074604266307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taat (999.479 ms)\n",
            "[(np.float64(10.949743618358667), np.int32(8363778)), (np.float64(10.586036503821358), np.int32(8363779)), (np.float64(9.71489299972576), np.int32(5733950)), (np.float64(9.65394411103718), np.int32(1339852)), (np.float64(9.493729408374108), np.int32(3874864)), (np.float64(9.381535166040274), np.int32(1484875)), (np.float64(9.290568032765567), np.int32(611370)), (np.float64(9.167478520133201), np.int32(5733949)), (np.float64(8.926860918228257), np.int32(7150429)), (np.float64(8.926860918228257), np.int32(7150428))]\n",
            "daat (1386.923 ms)\n",
            "[(np.float64(10.949743618358667), np.int32(8363778)), (np.float64(10.586036503821358), np.int32(8363779)), (np.float64(9.71489299972576), np.int32(5733950)), (np.float64(9.65394411103718), np.int32(1339852)), (np.float64(9.493729408374108), np.int32(3874864)), (np.float64(9.381535166040274), np.int32(1484875)), (np.float64(9.290568032765567), np.int32(611370)), (np.float64(9.167478520133201), np.int32(5733949)), (np.float64(8.926860918228257), np.int32(7150429)), (np.float64(8.926860918228257), np.int32(7150428))]\n"
          ]
        }
      ],
      "source": [
        "scorer = BM11Scorer()\n",
        "inv_ind = InvertedIndex(\n",
        "  lexicon,\n",
        "  inv_d,\n",
        "  inv_f,\n",
        "  doc_index,\n",
        "  stats,\n",
        "  scorer\n",
        ")\n",
        "\n",
        "query = \"mouse cat USA\"\n",
        "print(query_process(query, inv_ind, 10, \"T\"))\n",
        "print(query_process(query, inv_ind, 10, \"D\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1HSsYpVam4X"
      },
      "source": [
        "### BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o088nyxGZFzu"
      },
      "outputs": [],
      "source": [
        "class BM25Scorer:\n",
        "    \"\"\"\n",
        "    BM25 scoring function.\n",
        "    Arguments:\n",
        "        k1 (float): Term frequency saturation parameter.\n",
        "        b (float): Document length normalization parameter.\n",
        "    \"\"\"\n",
        "    def __init__(self, k1: float = 1.2, b: float = 0.75):\n",
        "        self.k1: float = k1\n",
        "        self.b: float = b\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        posting: 'InvertedIndex.PostingListIterator'\n",
        "    ) -> float:\n",
        "        # Extracting term frequency, number of documents and doc frequency\n",
        "        tf: int = posting.freqs[posting.pos]\n",
        "        N: int = posting.stats['num_docs']\n",
        "        df: int = posting.lexicon[posting.token][1]\n",
        "\n",
        "        # Computing bm1 weight with the actual formula\n",
        "        bm1: float = np.log((N - df + 0.5) / (df + 0.5))\n",
        "\n",
        "        # Computing the tilde tf, then the Bounded TF weight approximation\n",
        "        # and finally BM25 = BM1 * (tf) / (k_1 + tf_tilde)  \n",
        "        # tf_tilde = tf / (1 - b) + b * (dl / avg_dl)\n",
        "        dl: int = posting.doc[posting.docid() - 1][1] # type: ignore\n",
        "        avg_dl: int = posting.stats['average_document_length']\n",
        "        norm_factor: float = (1 - self.b) + self.b * (dl / avg_dl)  # convex combination\n",
        "        tf_tilde: float = tf / norm_factor\n",
        "        tf_approx: float = tf_tilde / (self.k1 + tf_tilde)\n",
        "        bm25: float = bm1 * tf_approx\n",
        "\n",
        "        return bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKOTbQUIakCj"
      },
      "source": [
        "Time is not acceptable and tests run successfully (we will worry about making it faster later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taat (1138.629 ms)\n",
            "[(np.float64(10.949743618358667), np.int32(8363778)), (np.float64(10.586036503821358), np.int32(8363779)), (np.float64(9.71489299972576), np.int32(5733950)), (np.float64(9.65394411103718), np.int32(1339852)), (np.float64(9.493729408374108), np.int32(3874864)), (np.float64(9.381535166040274), np.int32(1484875)), (np.float64(9.290568032765567), np.int32(611370)), (np.float64(9.167478520133201), np.int32(5733949)), (np.float64(8.926860918228257), np.int32(7150429)), (np.float64(8.926860918228257), np.int32(7150428))]\n",
            "daat (1629.016 ms)\n",
            "[(np.float64(10.949743618358667), np.int32(8363778)), (np.float64(10.586036503821358), np.int32(8363779)), (np.float64(9.71489299972576), np.int32(5733950)), (np.float64(9.65394411103718), np.int32(1339852)), (np.float64(9.493729408374108), np.int32(3874864)), (np.float64(9.381535166040274), np.int32(1484875)), (np.float64(9.290568032765567), np.int32(611370)), (np.float64(9.167478520133201), np.int32(5733949)), (np.float64(8.926860918228257), np.int32(7150429)), (np.float64(8.926860918228257), np.int32(7150428))]\n"
          ]
        }
      ],
      "source": [
        "scorer = BM25Scorer()\n",
        "inv_ind = InvertedIndex(\n",
        "  lexicon,\n",
        "  inv_d,\n",
        "  inv_f,\n",
        "  doc_index,\n",
        "  stats,\n",
        "  scorer\n",
        ")\n",
        "\n",
        "query = \"mouse cat USA\"\n",
        "print(query_process(query, inv_ind, 10, \"T\"))\n",
        "print(query_process(query, inv_ind, 10, \"D\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVDTz1WPapwM"
      },
      "source": [
        "## Experimental Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRGkUEAEfhAg"
      },
      "source": [
        "An experimental evaluation framework in information retrieval (IR) provides a systematic and reproducible approach for assessing the performance of retrieval models, ranking algorithms, and indexing techniques. Its primary goal is to measure how effectively a retrieval system satisfies users' information needs, by comparing the system's ranked outputs against a set of relevance judgments (qrels) provided by human assessors. Such a framework generally consists of several key components: a document collection (e.g., web pages, news articles, or academic papers), a set of queries or topics, corresponding ground-truth relevance assessments, and a suite of evaluation metrics such as Mean Average Precision (MAP), Normalized Discounted Cumulative Gain (nDCG), or Mean Reciprocal Rank (MRR)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neNqHc5wfdzN"
      },
      "source": [
        "### Download Queries and QRels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dlI1YVNfz48"
      },
      "source": [
        "Downloading queries, qrels and unzipping queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GE7GJNoiepAJ",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "9365b93c-a9b7-4437-e12f-2441d0489f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-25 07:30:15--  https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz\n",
            "Resolving msmarco.z22.web.core.windows.net (msmarco.z22.web.core.windows.net)... 20.150.34.1\n",
            "Connecting to msmarco.z22.web.core.windows.net (msmarco.z22.web.core.windows.net)|20.150.34.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4276 (4.2K) [application/x-gzip]\n",
            "Saving to: ‘msmarco-test2019-queries.tsv.gz’\n",
            "\n",
            "msmarco-test2019-qu 100%[===================>]   4.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-25 07:30:16 (1.03 GB/s) - ‘msmarco-test2019-queries.tsv.gz’ saved [4276/4276]\n",
            "\n",
            "--2025-11-25 07:30:16--  https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2020-queries.tsv.gz\n",
            "Resolving msmarco.z22.web.core.windows.net (msmarco.z22.web.core.windows.net)... 20.150.34.1\n",
            "Connecting to msmarco.z22.web.core.windows.net (msmarco.z22.web.core.windows.net)|20.150.34.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4131 (4.0K) [application/x-gzip]\n",
            "Saving to: ‘msmarco-test2020-queries.tsv.gz’\n",
            "\n",
            "msmarco-test2020-qu 100%[===================>]   4.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-25 07:30:16 (1.37 GB/s) - ‘msmarco-test2020-queries.tsv.gz’ saved [4131/4131]\n",
            "\n",
            "--2025-11-25 07:30:16--  https://trec.nist.gov/data/deep/2019qrels-pass.txt\n",
            "Resolving trec.nist.gov (trec.nist.gov)... 172.65.90.27, 172.65.90.25, 172.65.90.24, ...\n",
            "Connecting to trec.nist.gov (trec.nist.gov)|172.65.90.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘2019qrels-pass.txt’\n",
            "\n",
            "2019qrels-pass.txt      [ <=>                ] 182.71K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-11-25 07:30:17 (5.75 MB/s) - ‘2019qrels-pass.txt’ saved [187092]\n",
            "\n",
            "--2025-11-25 07:30:17--  https://trec.nist.gov/data/deep/2020qrels-pass.txt\n",
            "Resolving trec.nist.gov (trec.nist.gov)... 172.65.90.27, 172.65.90.25, 172.65.90.24, ...\n",
            "Connecting to trec.nist.gov (trec.nist.gov)|172.65.90.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘2020qrels-pass.txt’\n",
            "\n",
            "2020qrels-pass.txt      [ <=>                ] 213.49K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-11-25 07:30:17 (6.23 MB/s) - ‘2020qrels-pass.txt’ saved [218617]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download queries for MS MARCO\n",
        "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2019-queries.tsv.gz\n",
        "!wget https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco-test2020-queries.tsv.gz\n",
        "\n",
        "# Downlaod relevance judgements for MS MARCO queries\n",
        "# example:   23849 0 1034183 3  (topic_id, fix, docno, relevance)\n",
        "!wget https://trec.nist.gov/data/deep/2019qrels-pass.txt\n",
        "!wget https://trec.nist.gov/data/deep/2020qrels-pass.txt\n",
        "\n",
        "# Uncompress the queries\n",
        "!gunzip msmarco-test2019-queries.tsv.gz\n",
        "!gunzip msmarco-test2020-queries.tsv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09j5BVPT9_qk"
      },
      "source": [
        "### Evaluation-Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbT48HVY-hb8"
      },
      "source": [
        "We have chosen MSMARCO 2019 as our evaluation set and MSMARCO 2020 as our test set. The evaluation set will be used to tune the parameters of various scoring functions and to identify the best-performing function. The test set will then serve to compare our selected scoring function implementation against the PyTerrier implementation and to compute performance statistics.\n",
        "\n",
        "However, it is clear that our initial plan for the evaluation set is not entirely valid: we cannot both tune a model and compare it with other models using the same evaluation data. To address this, we split the evaluation set into two distinct subsets with a 70-30 ratio. The larger portion is reserved for model comparison, while the smaller portion is used for parameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tviUhBdlD0S3"
      },
      "source": [
        "\n",
        "To divide MSMARCO 2019 into two evaluation sets, we split the dataset by query IDs. Out of the 200 available queries, the first 140 are assigned to the primary evaluation set, while the remaining 60 form the secondary set. Splitting the qrels is straightforward: for each entry, we simply check the query ID and assign the relevance judgment to the corresponding evaluation subset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Query example:    1030303 who is aziz hashim  (topicid, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ayi7eJrfDLSS"
      },
      "outputs": [],
      "source": [
        "# Filenames for queries and qrels\n",
        "query_file = \"msmarco-test2019-queries.tsv\"\n",
        "qrel_file = \"2019qrels-pass.txt\"\n",
        "\n",
        "# Output filenames for the two evaluation splits\n",
        "eval_filename_1 = \"eval-set-1.tsv\"\n",
        "eval_filename_2 = \"eval-set-2.tsv\"\n",
        "eval_qrels_filename_1 = \"eval-qrels-1.txt\"\n",
        "eval_qrels_filename_2 = \"eval-qrels-2.txt\"\n",
        "\n",
        "# Sets to store query IDs belonging to each evaluation split\n",
        "query_ids_eval_1 = set()\n",
        "query_ids_eval_2 = set()\n",
        "\n",
        "# Ratio for splitting queries (70% in set 1, 30% in set 2)\n",
        "eval_split = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKwePHTcKUin"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Step 1: Read queries and split them\n",
        "# -------------------------------\n",
        "with open(query_file, \"r\") as f:\n",
        "    lines = f.readlines()              # Read all query lines\n",
        "    num_lines = len(lines)             # Total number of queries\n",
        "    split_index = int(num_lines * eval_split)  # Index at which to split\n",
        "\n",
        "# Assign query IDs to the appropriate sets\n",
        "for line in lines[:split_index]:\n",
        "    query_id = line.split(\"\\t\")[0]     # Extract query ID (first column)\n",
        "    query_ids_eval_1.add(query_id)\n",
        "\n",
        "for line in lines[split_index:]:\n",
        "    query_id = line.split(\"\\t\")[0]\n",
        "    query_ids_eval_2.add(query_id)\n",
        "\n",
        "# Save the split queries into separate files\n",
        "with open(eval_filename_1, \"w\") as f:\n",
        "    f.writelines(lines[:split_index])\n",
        "\n",
        "with open(eval_filename_2, \"w\") as f:\n",
        "    f.writelines(lines[split_index:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRyjBJx8KYMH"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Step 2: Read qrels and split them according to query IDs\n",
        "# -------------------------------\n",
        "with open(qrel_file, \"r\") as f:\n",
        "    qrel_lines = f.readlines()\n",
        "\n",
        "# Write qrels into the corresponding evaluation files\n",
        "with open(eval_qrels_filename_1, \"w\") as f1, open(eval_qrels_filename_2, \"w\") as f2:\n",
        "    for line in qrel_lines:\n",
        "        query_id = line.split()[0]     # Extract query ID (first column in qrels)\n",
        "        if query_id in query_ids_eval_1:\n",
        "            f1.write(line)\n",
        "        elif query_id in query_ids_eval_2:\n",
        "            f2.write(line)\n",
        "        else:\n",
        "            # This should not happen if queries and qrels are consistent\n",
        "            print(f\"Warning: Query ID {query_id} not found in either evaluation set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0f8Bw14K6rr"
      },
      "source": [
        "### BM25 Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwgqUcefK6rs"
      },
      "source": [
        "I'm conducting a grid search over various combinations of the parameters (b,k). For each configuration, I compute performance scores using TREC evaluation metrics. To identify the best parameter pair, I apply a statistical test to determine whether the observed differences in performance are statistically significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDqXKTnULi24"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuCNFlh2Li27"
      },
      "source": [
        "\n",
        "The two functions, extract_queries() and write_run_file(), together form a crucial part of the retrieval and evaluation pipeline in an information retrieval (IR) system — specifically handling the preparation of input queries and the generation of output run files for evaluation.\n",
        "\n",
        "The extract_queries() function is responsible for reading a tab-separated values (TSV) file that contains pairs of query identifiers and their corresponding query texts. Each line in the file is expected to follow the format query_id<TAB>query_text. The function parses this file line by line, splitting each entry into a tuple of (query_id, query) and appending it to a list. It also includes a safeguard to skip malformed lines that don’t match the expected format, ensuring robustness against minor formatting errors. The resulting list of tuples provides a structured and standardized way to store multiple queries, which can then be processed in bulk by the retrieval system.\n",
        "\n",
        "The write_run_file() function, on the other hand, takes these extracted queries and runs them through the retrieval engine using a provided inverted index. For each query, it calls the query_process() function to obtain a ranked list of documents, represented as pairs of (score, docid) values. These results are then formatted according to the TREC standard, a widely used evaluation format in IR research, which includes columns for the query ID, document number, rank position, score, and run name (an identifier for the retrieval experiment). Before writing to the file, document identifiers are cleaned and standardized by removing prefixes (e.g., “DOC”) to match the TREC conventions. The final run file, saved to the specified output path, serves as an input for evaluation tools like trec_eval or ir_measures, enabling performance comparison across different retrieval models. Together, these functions automate the process of preparing queries, retrieving ranked results, and producing evaluation-ready outputs — ensuring reproducibility, consistency, and compatibility with standard IR benchmarking frameworks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thn59IUHLi2-"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def extract_queries(\n",
        "    filename: str\n",
        ") -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Reads a TSV file containing query IDs and query texts,\n",
        "        and returns them as a list of (query_id, query) tuples.\n",
        "\n",
        "    Arguments:\n",
        "        filename (str): Path to the TSV file.\n",
        "          Each line should contain 'query_id<TAB>query_text'.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list where each element is a tuple\n",
        "          containing (query_id, query_text).\n",
        "    \"\"\"\n",
        "    queries: List[Tuple[str, str]] = []\n",
        "\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "\n",
        "            # Skipping malformed lines\n",
        "            try:\n",
        "                query_id, query = line.strip().split(\"\\t\")\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            # Appending query_id and query text\n",
        "            queries.append((query_id, query))\n",
        "\n",
        "    return queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5VwUaBNLi2_"
      },
      "outputs": [],
      "source": [
        "def write_run_file(\n",
        "    queries: list[tuple[str, str]],\n",
        "    index: InvertedIndex,\n",
        "    output_path: str,\n",
        "    run_name: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Generates a TREC-formatted run file from a set of queries and the inverted index.\n",
        "\n",
        "    Arguments:\n",
        "        queries (Dict[int, str]): Mapping from query IDs to query strings.\n",
        "        index (InvertedIndex): The inverted index used for retrieval.\n",
        "        output_path (str): Path to save the output run file.\n",
        "        run_name (str): Identifier for the run (appears in the last column).\n",
        "    \"\"\"\n",
        "\n",
        "    with open(output_path, \"w\") as f:\n",
        "        for qid, query in queries:\n",
        "\n",
        "            # List of scores and docids ordered by score using DAAT\n",
        "            results: list[tuple[np.float64, np.int32]] = query_process(query, index)\n",
        "            # TODO: problema: il tipo np.float64 / int32 non è quello che ritora il query_process. E altra cosa, prima venivano definite float int immagino\n",
        "\n",
        "            # Iterating over results, converting docid into docno while\n",
        "            # removing DOC and storing the line in the run file\n",
        "            for rank, (score, docid) in enumerate(results, start=1):\n",
        "                docno: str = doc_index[docid - 1][0]  #  NOTE: -1 since docid starts from 1\n",
        "                docno: str = docno.replace(\"DOC\", \"\")\n",
        "                f.write(f\"{qid} Q0 {docno} {rank} {score:.6f} {run_name}\\n\")\n",
        "\n",
        "    print(f\"Run file saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjc73h2PK6rt"
      },
      "source": [
        "#### Creating Run Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daekZRbAK6rt"
      },
      "source": [
        "This script automates the generation of TREC-formatted run files for a series of BM25 retrieval configurations. It begins by specifying the input query file, containing query IDs and text and associates them with unique suffixes to distinguish the resulting run files. A grid of BM25 parameter combinations is defined using different values of b and k1, and for each pair, a corresponding BM25Scorer object is created. These scorers are paired with descriptive run names that encode their parameter settings. For each query file, the script extracts the queries and iterates over all scoring functions. It initializes an InvertedIndex using the current scorer and document statistics, then generates a run file by applying the scorer to the queries. The output files are named using the run identifier and the appropriate suffix, ensuring clarity and traceability across different configurations and query sets. This setup enables systematic evaluation of retrieval performance across a range of BM25 parameter settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCCi-h3mK6ru"
      },
      "outputs": [],
      "source": [
        "# ---------------------- Query Files ---------------------- #\n",
        "# Path to MS MARCO 2019 extracted evaluation set\n",
        "# File contains query IDs and query text in TSV format.\n",
        "queries_file = \"eval-set-2.tsv\"\n",
        "\n",
        "# ---------------------- Scoring Functions ---------------------- #\n",
        "# List of scorer objects that implement different retrieval models.\n",
        "# Each scorer defines how to compute document scores during retrieval.\n",
        "b_l = [0.65, 0.75, 0.85]\n",
        "k1_l = [1, 1.2, 1.4]\n",
        "scorers = [\n",
        "    BM25Scorer(k1=k1, b=b)\n",
        "    for k1 in k1_l\n",
        "    for b in b_l\n",
        "]\n",
        "\n",
        "# ---------------------- Run Names ---------------------- #\n",
        "# List of run identifiers corresponding to the scorers above.\n",
        "# These names appear in the run file and are used by evaluation tools.\n",
        "run_names = [\n",
        "    \"bm25_run_b={}_k1={}\".format(b, k1)\n",
        "    for k1 in k1_l\n",
        "    for b in b_l\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rudNmqYDK6rv",
        "outputId": "a18d64b5-3a95-47fe-ee19-b4420a5c265a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "daat (1655.801 ms)\n",
            "daat (1421.533 ms)\n",
            "daat (7185.995 ms)\n",
            "daat (18658.461 ms)\n",
            "daat (3576.058 ms)\n",
            "daat (4631.403 ms)\n",
            "daat (11786.030 ms)\n",
            "daat (3661.095 ms)\n",
            "daat (7459.922 ms)\n",
            "daat (9209.614 ms)\n",
            "daat (7090.973 ms)\n",
            "daat (15366.650 ms)\n",
            "daat (4601.224 ms)\n",
            "daat (7223.803 ms)\n",
            "daat (4583.142 ms)\n",
            "daat (26391.746 ms)\n",
            "daat (5347.172 ms)\n",
            "daat (349.129 ms)\n",
            "daat (5274.575 ms)\n",
            "daat (1.253 ms)\n",
            "daat (4376.082 ms)\n",
            "daat (26702.857 ms)\n",
            "daat (2941.654 ms)\n",
            "daat (3177.396 ms)\n",
            "daat (3692.624 ms)\n",
            "daat (1231.449 ms)\n",
            "daat (3056.164 ms)\n",
            "daat (5607.698 ms)\n",
            "daat (3196.943 ms)\n",
            "daat (5174.020 ms)\n",
            "daat (22869.164 ms)\n",
            "daat (24605.258 ms)\n",
            "daat (4899.773 ms)\n",
            "daat (7667.347 ms)\n",
            "daat (1490.896 ms)\n",
            "daat (9001.701 ms)\n",
            "daat (12526.452 ms)\n",
            "daat (64460.077 ms)\n",
            "daat (13249.014 ms)\n",
            "daat (2259.607 ms)\n",
            "daat (3921.624 ms)\n",
            "daat (8711.583 ms)\n",
            "daat (4394.598 ms)\n",
            "daat (189.254 ms)\n",
            "daat (13919.914 ms)\n",
            "daat (0.635 ms)\n",
            "daat (3305.546 ms)\n",
            "daat (311.719 ms)\n",
            "daat (8923.694 ms)\n",
            "daat (3884.089 ms)\n",
            "daat (6585.105 ms)\n",
            "daat (22232.395 ms)\n",
            "daat (5889.449 ms)\n",
            "daat (17562.280 ms)\n",
            "daat (6022.466 ms)\n",
            "daat (6953.336 ms)\n",
            "daat (1122.007 ms)\n",
            "daat (14632.941 ms)\n",
            "daat (16460.733 ms)\n",
            "daat (1968.403 ms)\n",
            "Run file saved to: bm25_run_b=0.65_k1=1\n",
            "daat (507.273 ms)\n",
            "daat (1130.383 ms)\n",
            "daat (6159.202 ms)\n",
            "daat (16588.546 ms)\n",
            "daat (3179.326 ms)\n",
            "daat (6416.190 ms)\n",
            "daat (10327.771 ms)\n",
            "daat (4972.469 ms)\n",
            "daat (4843.906 ms)\n",
            "daat (6905.086 ms)\n",
            "daat (5804.922 ms)\n",
            "daat (9506.567 ms)\n",
            "daat (2727.661 ms)\n",
            "daat (3631.491 ms)\n",
            "daat (5448.734 ms)\n",
            "daat (20830.436 ms)\n",
            "daat (4974.144 ms)\n",
            "daat (344.705 ms)\n",
            "daat (5510.686 ms)\n",
            "daat (0.709 ms)\n",
            "daat (3747.207 ms)\n",
            "daat (25356.056 ms)\n",
            "daat (2832.406 ms)\n",
            "daat (3043.103 ms)\n",
            "daat (3534.399 ms)\n",
            "daat (1085.043 ms)\n",
            "daat (3613.812 ms)\n",
            "daat (5478.014 ms)\n",
            "daat (3116.520 ms)\n",
            "daat (5279.604 ms)\n",
            "daat (22681.603 ms)\n",
            "daat (24352.743 ms)\n",
            "daat (4558.713 ms)\n",
            "daat (9731.174 ms)\n",
            "daat (1901.417 ms)\n",
            "daat (8897.325 ms)\n",
            "daat (11970.706 ms)\n",
            "daat (83118.863 ms)\n",
            "daat (12300.543 ms)\n",
            "daat (2267.754 ms)\n",
            "daat (5269.090 ms)\n",
            "daat (7217.157 ms)\n",
            "daat (5843.548 ms)\n",
            "daat (339.765 ms)\n",
            "daat (13248.886 ms)\n",
            "daat (0.722 ms)\n",
            "daat (2610.247 ms)\n",
            "daat (191.540 ms)\n",
            "daat (8180.605 ms)\n",
            "daat (4927.804 ms)\n",
            "daat (5320.965 ms)\n",
            "daat (42817.270 ms)\n",
            "daat (5584.986 ms)\n",
            "daat (27106.523 ms)\n",
            "daat (8511.395 ms)\n",
            "daat (8589.579 ms)\n",
            "daat (1074.808 ms)\n",
            "daat (15807.739 ms)\n",
            "daat (29280.965 ms)\n",
            "daat (2014.764 ms)\n",
            "Run file saved to: bm25_run_b=0.75_k1=1\n",
            "daat (507.537 ms)\n",
            "daat (726.510 ms)\n",
            "daat (6751.283 ms)\n",
            "daat (16363.229 ms)\n",
            "daat (7250.769 ms)\n",
            "daat (6480.839 ms)\n",
            "daat (11469.921 ms)\n",
            "daat (3702.773 ms)\n",
            "daat (4859.958 ms)\n",
            "daat (7395.831 ms)\n",
            "daat (5580.746 ms)\n",
            "daat (9768.717 ms)\n",
            "daat (2816.280 ms)\n",
            "daat (3728.419 ms)\n",
            "daat (6978.129 ms)\n",
            "daat (19656.914 ms)\n",
            "daat (6601.668 ms)\n",
            "daat (603.974 ms)\n",
            "daat (3853.032 ms)\n",
            "daat (0.767 ms)\n",
            "daat (3769.816 ms)\n",
            "daat (26651.968 ms)\n",
            "daat (2835.065 ms)\n",
            "daat (4168.399 ms)\n",
            "daat (4033.668 ms)\n",
            "daat (633.533 ms)\n",
            "daat (2367.624 ms)\n",
            "daat (6690.636 ms)\n",
            "daat (6035.511 ms)\n",
            "daat (8119.285 ms)\n",
            "daat (37249.578 ms)\n",
            "daat (26924.337 ms)\n",
            "daat (4678.031 ms)\n",
            "daat (9042.719 ms)\n",
            "daat (2044.619 ms)\n",
            "daat (13441.434 ms)\n",
            "daat (19864.356 ms)\n",
            "daat (98336.341 ms)\n",
            "daat (19787.107 ms)\n",
            "daat (3646.717 ms)\n",
            "daat (7529.370 ms)\n",
            "daat (7431.723 ms)\n",
            "daat (6021.213 ms)\n",
            "daat (414.755 ms)\n",
            "daat (13247.443 ms)\n",
            "daat (0.852 ms)\n",
            "daat (2524.317 ms)\n",
            "daat (169.906 ms)\n",
            "daat (9852.772 ms)\n",
            "daat (4276.117 ms)\n",
            "daat (8047.134 ms)\n",
            "daat (33797.565 ms)\n",
            "daat (5516.098 ms)\n",
            "daat (17787.467 ms)\n",
            "daat (6675.826 ms)\n",
            "daat (6399.862 ms)\n",
            "daat (1066.391 ms)\n",
            "daat (16454.988 ms)\n",
            "daat (17912.731 ms)\n",
            "daat (2231.574 ms)\n",
            "Run file saved to: bm25_run_b=0.85_k1=1\n",
            "daat (527.054 ms)\n",
            "daat (740.342 ms)\n",
            "daat (4976.138 ms)\n",
            "daat (17350.446 ms)\n",
            "daat (4431.650 ms)\n",
            "daat (5239.850 ms)\n",
            "daat (12025.425 ms)\n",
            "daat (3540.498 ms)\n",
            "daat (6709.231 ms)\n",
            "daat (5319.024 ms)\n",
            "daat (6340.143 ms)\n",
            "daat (8350.230 ms)\n",
            "daat (2740.556 ms)\n",
            "daat (5428.201 ms)\n",
            "daat (4524.688 ms)\n",
            "daat (19621.476 ms)\n",
            "daat (6658.318 ms)\n",
            "daat (361.246 ms)\n",
            "daat (3834.018 ms)\n",
            "daat (0.735 ms)\n",
            "daat (4595.504 ms)\n",
            "daat (26083.346 ms)\n",
            "daat (5327.212 ms)\n",
            "daat (5802.135 ms)\n",
            "daat (6826.369 ms)\n",
            "daat (1447.663 ms)\n",
            "daat (2807.510 ms)\n",
            "daat (11125.265 ms)\n",
            "daat (4789.681 ms)\n",
            "daat (3357.669 ms)\n",
            "daat (24661.381 ms)\n",
            "daat (23199.351 ms)\n",
            "daat (5730.847 ms)\n",
            "daat (6223.896 ms)\n",
            "daat (2138.217 ms)\n",
            "daat (8229.748 ms)\n",
            "daat (12842.609 ms)\n",
            "daat (63774.433 ms)\n",
            "daat (11663.965 ms)\n",
            "daat (3111.806 ms)\n",
            "daat (4891.479 ms)\n",
            "daat (7268.937 ms)\n",
            "daat (6324.578 ms)\n",
            "daat (186.853 ms)\n",
            "daat (13807.827 ms)\n",
            "daat (0.498 ms)\n",
            "daat (2092.497 ms)\n",
            "daat (166.265 ms)\n",
            "daat (10466.268 ms)\n",
            "daat (3307.851 ms)\n",
            "daat (5555.167 ms)\n",
            "daat (23383.366 ms)\n",
            "daat (4715.979 ms)\n",
            "daat (18914.086 ms)\n",
            "daat (5383.009 ms)\n",
            "daat (6771.148 ms)\n",
            "daat (1858.207 ms)\n",
            "daat (10771.054 ms)\n",
            "daat (17411.044 ms)\n",
            "daat (2791.892 ms)\n",
            "Run file saved to: bm25_run_b=0.65_k1=1.2\n",
            "daat (482.515 ms)\n",
            "daat (698.501 ms)\n",
            "daat (4953.520 ms)\n",
            "daat (17220.400 ms)\n",
            "daat (5037.584 ms)\n",
            "daat (4682.307 ms)\n",
            "daat (11980.783 ms)\n",
            "daat (3719.625 ms)\n",
            "daat (6090.394 ms)\n",
            "daat (6095.956 ms)\n",
            "daat (6047.139 ms)\n",
            "daat (9563.259 ms)\n",
            "daat (2830.781 ms)\n",
            "daat (5523.598 ms)\n",
            "daat (4722.022 ms)\n",
            "daat (19673.818 ms)\n",
            "daat (6808.646 ms)\n",
            "daat (330.466 ms)\n",
            "daat (3787.302 ms)\n",
            "daat (0.711 ms)\n",
            "daat (4009.443 ms)\n",
            "daat (25318.013 ms)\n",
            "daat (2823.994 ms)\n",
            "daat (5061.212 ms)\n",
            "daat (3292.213 ms)\n",
            "daat (686.193 ms)\n",
            "daat (2525.350 ms)\n",
            "daat (7503.521 ms)\n",
            "daat (3255.791 ms)\n",
            "daat (3499.933 ms)\n",
            "daat (24685.393 ms)\n",
            "daat (25313.478 ms)\n",
            "daat (4991.276 ms)\n",
            "daat (7637.299 ms)\n",
            "daat (2416.188 ms)\n",
            "daat (7486.973 ms)\n",
            "daat (18098.132 ms)\n",
            "daat (66857.177 ms)\n",
            "daat (16943.526 ms)\n",
            "daat (2542.470 ms)\n",
            "daat (7337.139 ms)\n",
            "daat (9599.621 ms)\n",
            "daat (6964.307 ms)\n",
            "daat (188.718 ms)\n",
            "daat (13656.281 ms)\n",
            "daat (0.478 ms)\n",
            "daat (2119.238 ms)\n",
            "daat (264.175 ms)\n",
            "daat (10132.929 ms)\n",
            "daat (3210.844 ms)\n",
            "daat (5918.787 ms)\n",
            "daat (25953.290 ms)\n",
            "daat (7856.475 ms)\n",
            "daat (17728.221 ms)\n",
            "daat (5465.997 ms)\n",
            "daat (7499.012 ms)\n",
            "daat (1055.515 ms)\n",
            "daat (11682.686 ms)\n",
            "daat (27923.687 ms)\n",
            "daat (3591.946 ms)\n",
            "Run file saved to: bm25_run_b=0.75_k1=1.2\n",
            "daat (656.912 ms)\n",
            "daat (917.649 ms)\n",
            "daat (12593.785 ms)\n",
            "daat (32425.456 ms)\n",
            "daat (3822.603 ms)\n",
            "daat (10604.331 ms)\n",
            "daat (17720.599 ms)\n",
            "daat (9634.154 ms)\n",
            "daat (8450.471 ms)\n",
            "daat (9241.973 ms)\n",
            "daat (5434.999 ms)\n",
            "daat (9512.246 ms)\n",
            "daat (2694.234 ms)\n",
            "daat (6618.560 ms)\n",
            "daat (4552.390 ms)\n",
            "daat (27141.481 ms)\n",
            "daat (5593.355 ms)\n",
            "daat (543.642 ms)\n",
            "daat (9048.670 ms)\n",
            "daat (1.146 ms)\n",
            "daat (4611.461 ms)\n",
            "daat (29599.760 ms)\n",
            "daat (3016.621 ms)\n",
            "daat (5246.005 ms)\n",
            "daat (4119.586 ms)\n",
            "daat (1218.550 ms)\n",
            "daat (6239.739 ms)\n",
            "daat (10801.309 ms)\n",
            "daat (8248.398 ms)\n",
            "daat (3382.704 ms)\n",
            "daat (34374.195 ms)\n",
            "daat (33647.808 ms)\n",
            "daat (6360.141 ms)\n",
            "daat (11178.886 ms)\n",
            "daat (2387.593 ms)\n",
            "daat (8129.999 ms)\n",
            "daat (11514.284 ms)\n",
            "daat (83100.224 ms)\n",
            "daat (18612.897 ms)\n",
            "daat (2337.642 ms)\n",
            "daat (5343.817 ms)\n",
            "daat (7271.090 ms)\n",
            "daat (7300.621 ms)\n",
            "daat (416.099 ms)\n",
            "daat (17997.239 ms)\n",
            "daat (0.502 ms)\n",
            "daat (3011.729 ms)\n",
            "daat (284.483 ms)\n",
            "daat (13417.037 ms)\n",
            "daat (5491.395 ms)\n",
            "daat (8050.181 ms)\n",
            "daat (29379.847 ms)\n",
            "daat (5972.269 ms)\n",
            "daat (21362.661 ms)\n",
            "daat (4762.286 ms)\n",
            "daat (12388.092 ms)\n",
            "daat (1132.578 ms)\n",
            "daat (12872.044 ms)\n",
            "daat (17006.496 ms)\n",
            "daat (2094.491 ms)\n",
            "Run file saved to: bm25_run_b=0.85_k1=1.2\n",
            "daat (496.268 ms)\n",
            "daat (711.572 ms)\n",
            "daat (7040.308 ms)\n",
            "daat (17110.618 ms)\n",
            "daat (3498.446 ms)\n",
            "daat (6394.198 ms)\n",
            "daat (18583.266 ms)\n",
            "daat (5583.148 ms)\n",
            "daat (10844.022 ms)\n",
            "daat (6071.132 ms)\n",
            "daat (7903.628 ms)\n",
            "daat (11232.137 ms)\n",
            "daat (2821.817 ms)\n",
            "daat (3812.335 ms)\n",
            "daat (7049.568 ms)\n",
            "daat (21811.009 ms)\n",
            "daat (7013.914 ms)\n",
            "daat (323.426 ms)\n",
            "daat (3861.305 ms)\n",
            "daat (0.759 ms)\n",
            "daat (3821.832 ms)\n",
            "daat (39492.357 ms)\n",
            "daat (3537.056 ms)\n",
            "daat (3944.449 ms)\n",
            "daat (4232.243 ms)\n",
            "daat (673.829 ms)\n",
            "daat (2531.601 ms)\n",
            "daat (8693.375 ms)\n",
            "daat (6073.869 ms)\n",
            "daat (3489.655 ms)\n",
            "daat (24727.313 ms)\n",
            "daat (23918.407 ms)\n",
            "daat (4647.912 ms)\n",
            "daat (6803.523 ms)\n",
            "daat (2512.599 ms)\n",
            "daat (7041.914 ms)\n",
            "daat (12454.001 ms)\n",
            "daat (63420.540 ms)\n",
            "daat (11661.491 ms)\n",
            "daat (3768.373 ms)\n",
            "daat (4188.381 ms)\n",
            "daat (7582.550 ms)\n",
            "daat (6067.797 ms)\n",
            "daat (188.124 ms)\n",
            "daat (13872.512 ms)\n",
            "daat (0.588 ms)\n",
            "daat (2145.054 ms)\n",
            "daat (179.419 ms)\n",
            "daat (10111.144 ms)\n",
            "daat (3169.228 ms)\n",
            "daat (5304.235 ms)\n",
            "daat (23163.035 ms)\n",
            "daat (4731.871 ms)\n",
            "daat (18475.116 ms)\n",
            "daat (5577.157 ms)\n",
            "daat (6536.928 ms)\n",
            "daat (1827.833 ms)\n",
            "daat (10707.649 ms)\n",
            "daat (16815.286 ms)\n",
            "daat (3185.874 ms)\n",
            "Run file saved to: bm25_run_b=0.65_k1=1.4\n",
            "daat (501.602 ms)\n",
            "daat (717.942 ms)\n",
            "daat (4846.296 ms)\n",
            "daat (16985.524 ms)\n",
            "daat (4979.765 ms)\n",
            "daat (4512.340 ms)\n",
            "daat (11788.521 ms)\n",
            "daat (3536.347 ms)\n",
            "daat (5048.777 ms)\n",
            "daat (6944.296 ms)\n",
            "daat (5595.637 ms)\n",
            "daat (9654.006 ms)\n",
            "daat (2859.274 ms)\n",
            "daat (4393.178 ms)\n",
            "daat (5725.147 ms)\n",
            "daat (19631.041 ms)\n",
            "daat (6863.787 ms)\n",
            "daat (333.879 ms)\n",
            "daat (3761.587 ms)\n",
            "daat (0.723 ms)\n",
            "daat (3761.666 ms)\n",
            "daat (25277.720 ms)\n",
            "daat (2757.754 ms)\n",
            "daat (3807.586 ms)\n",
            "daat (4204.883 ms)\n",
            "daat (665.503 ms)\n",
            "daat (2320.419 ms)\n",
            "daat (5826.593 ms)\n",
            "daat (4618.459 ms)\n",
            "daat (3344.247 ms)\n",
            "daat (24689.362 ms)\n",
            "daat (22489.699 ms)\n",
            "daat (6451.016 ms)\n",
            "daat (6178.161 ms)\n",
            "daat (1426.293 ms)\n",
            "daat (8980.710 ms)\n",
            "daat (12629.406 ms)\n",
            "daat (64669.995 ms)\n",
            "daat (12369.361 ms)\n",
            "daat (2305.273 ms)\n",
            "daat (5406.097 ms)\n",
            "daat (7363.737 ms)\n",
            "daat (6221.835 ms)\n",
            "daat (179.128 ms)\n",
            "daat (13569.381 ms)\n",
            "daat (0.890 ms)\n",
            "daat (2279.736 ms)\n",
            "daat (171.656 ms)\n",
            "daat (8404.146 ms)\n",
            "daat (4890.648 ms)\n",
            "daat (5297.554 ms)\n",
            "daat (23516.845 ms)\n",
            "daat (4729.045 ms)\n",
            "daat (17770.079 ms)\n",
            "daat (6735.674 ms)\n",
            "daat (6402.255 ms)\n",
            "daat (1067.247 ms)\n",
            "daat (11721.164 ms)\n",
            "daat (16327.627 ms)\n",
            "daat (2454.437 ms)\n",
            "Run file saved to: bm25_run_b=0.75_k1=1.4\n",
            "daat (813.301 ms)\n",
            "daat (1172.855 ms)\n",
            "daat (5419.300 ms)\n",
            "daat (16356.307 ms)\n",
            "daat (3125.886 ms)\n",
            "daat (6449.147 ms)\n",
            "daat (10762.557 ms)\n",
            "daat (4314.408 ms)\n",
            "daat (4768.859 ms)\n",
            "daat (7319.291 ms)\n",
            "daat (5542.949 ms)\n",
            "daat (9555.451 ms)\n",
            "daat (2713.889 ms)\n",
            "daat (3610.283 ms)\n",
            "daat (6099.458 ms)\n",
            "daat (19428.474 ms)\n",
            "daat (4906.376 ms)\n",
            "daat (321.359 ms)\n",
            "daat (5574.073 ms)\n",
            "daat (0.725 ms)\n",
            "daat (3740.444 ms)\n",
            "daat (25274.984 ms)\n",
            "daat (2716.030 ms)\n",
            "daat (3123.727 ms)\n",
            "daat (3751.825 ms)\n",
            "daat (1131.457 ms)\n",
            "daat (3111.988 ms)\n",
            "daat (5564.283 ms)\n",
            "daat (3409.844 ms)\n",
            "daat (5056.259 ms)\n",
            "daat (22837.022 ms)\n",
            "daat (24173.116 ms)\n",
            "daat (4674.779 ms)\n",
            "daat (7890.549 ms)\n",
            "daat (1490.790 ms)\n",
            "daat (8947.107 ms)\n",
            "daat (11146.212 ms)\n",
            "daat (64985.370 ms)\n",
            "daat (12375.305 ms)\n",
            "daat (2314.133 ms)\n",
            "daat (3599.023 ms)\n",
            "daat (9058.488 ms)\n",
            "daat (4418.452 ms)\n",
            "daat (201.277 ms)\n",
            "daat (13664.448 ms)\n",
            "daat (0.795 ms)\n",
            "daat (2273.175 ms)\n",
            "daat (167.243 ms)\n",
            "daat (10084.323 ms)\n",
            "daat (3153.131 ms)\n",
            "daat (7063.555 ms)\n",
            "daat (21546.010 ms)\n",
            "daat (6484.522 ms)\n",
            "daat (17453.679 ms)\n",
            "daat (4822.203 ms)\n",
            "daat (8192.009 ms)\n",
            "daat (1065.685 ms)\n",
            "daat (11818.199 ms)\n",
            "daat (16318.406 ms)\n",
            "daat (1964.817 ms)\n",
            "Run file saved to: bm25_run_b=0.85_k1=1.4\n"
          ]
        }
      ],
      "source": [
        "# Extract queries from the current file\n",
        "# queries: List of tuples (query_id, query_text)\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "# Iterate over each scoring function and its run name\n",
        "for scorer, run_name in zip(scorers, run_names):\n",
        "\n",
        "    # Initialize the inverted index with the current scoring function\n",
        "    # This allows different retrieval models (e.g., TF, TF-IDF, BM25)\n",
        "    inv_ind = InvertedIndex(\n",
        "        lexicon,       # term -> (termid, ...) mapping   # TODO exact pls\n",
        "        inv_d,         # list of numpy arrays: doc IDs per term\n",
        "        inv_f,         # list of numpy arrays: term frequencies per term\n",
        "        doc_index,     # document statistics\n",
        "        stats,         # global statistics (e.g., total # of documents)   # TODO exact pls\n",
        "        scorer=scorer  # scoring function to use for this run\n",
        "    )\n",
        "\n",
        "    # Generate and write a TREC-formatted run file for the current query set\n",
        "    # The filename combines the run name and the run suffix\n",
        "    write_run_file(\n",
        "        queries,              # queries to process\n",
        "        inv_ind,              # inverted index with current scoring function\n",
        "        run_name,             # output filename for this run\n",
        "        run_name              # run identifier (appears in run file)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSiM-lFHK6rw"
      },
      "source": [
        "#### Configuring Score Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpeEZKnUK6rx"
      },
      "source": [
        "I'm initializing key variables to streamline the evaluation of performance scores, ensuring the process runs efficiently and consistently.\n",
        "This code sets up the evaluation framework for a series of BM25 retrieval runs, each defined by a unique combination of the parameters b and k1. It constructs a list of method identifiers based on these parameter pairs, appending a consistent suffix to match the naming convention of the corresponding run files. The evaluation focuses on three standard information retrieval metrics: Average Precision (AP), normalized Discounted Cumulative Gain at rank 10 (nDCG@10), and Mean Reciprocal Rank at rank 10 (MRR@10). Relevance judgments are loaded from a TREC-formatted qrels file, which serves as the ground truth for scoring. For each method, the corresponding run file is read and parsed using ir_measures, and the resulting run data is stored in a list for subsequent evaluation. This setup ensures that all parameter configurations are systematically prepared for performance comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2ZZGxfgK6rx"
      },
      "outputs": [],
      "source": [
        "import ir_measures\n",
        "from ir_measures import * # import natural measure name\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# List of retrieval/scoring methods\n",
        "# TODO praticamente una ridefinizione di run_names?\n",
        "methods = [\n",
        "    f\"bm25_run_b={b}_k1={k1}\"\n",
        "    for k1 in k1_l\n",
        "    for b in b_l\n",
        "]\n",
        "\n",
        "# Metrics to evaluate\n",
        "metrics = [\n",
        "    (\"AP\", AP),\n",
        "    (\"nDCG@10\", nDCG@10),\n",
        "    (\"MRR@10\", MRR@10)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ7QtKyIK6ry"
      },
      "outputs": [],
      "source": [
        "###### Step 1: Load relevance judgments (qrels)\n",
        "\n",
        "# qrels_file contains the ground-truth relevance labels for queries\n",
        "qrels_file = 'eval-qrels-2.txt'\n",
        "\n",
        "# Read the qrels file using ir_measures utility\n",
        "# Each entry represents a (query_id, doc_id, relevance) tuple\n",
        "qrel = list(ir_measures.read_trec_qrels(qrels_file))\n",
        "\n",
        "\n",
        "###### Step 2: Load runs for each retrieval method\n",
        "\n",
        "# List of runs\n",
        "runs = []\n",
        "\n",
        "# 'methods' is the list of run filenames,\n",
        "# each corresponding to the output of a retrieval method\n",
        "for method in methods:\n",
        "\n",
        "    # The run file for this method\n",
        "    run_file = method  # TODO WTF? perchè ridefinirlo\n",
        "\n",
        "    # Read the run file using ir_measures utility\n",
        "    # Each entry represents a (query_id, doc_id, score) tuple\n",
        "    run_data = list(ir_measures.read_trec_run(run_file))\n",
        "\n",
        "    # Append the run data to the list of runs\n",
        "    runs.append(run_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgU-nZR5K6ry"
      },
      "source": [
        "#### Computing Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW_51iVyK6rz"
      },
      "source": [
        "This code segment constructs a structured evaluation of retrieval performance across multiple methods and metrics. For each metric defined in the metrics list, such as Average Precision or nDCG@10, it initializes a table where each row corresponds to a retrieval method and each column holds the per-query scores for that method. Using the ir_measures library, it computes the metric values for each query in the run associated with a given method. These per-query scores are stored as tuples and deep-copied to ensure data integrity and prevent unintended modifications. Once all methods have been evaluated for a particular metric, the resulting table is appended to the scores list, which ultimately holds a complete set of evaluation results for all metrics across all retrieval configurations. This setup enables systematic comparison and statistical analysis of retrieval performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfhSlnCLK6rz"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# This will store per-metric tables of per-query scores\n",
        "scores = []\n",
        "\n",
        "for metric_name, metric_func in metrics:\n",
        "\n",
        "    # Table: rows = methods (BM25 combinations), columns = per-query scores\n",
        "    table = []\n",
        "\n",
        "    for method_idx, method in enumerate(methods):\n",
        "        run_data = runs[method_idx]\n",
        "\n",
        "        # Compute the metric for each query in the run\n",
        "        per_query_scores = tuple(\n",
        "            m.value for m in ir_measures.iter_calc([metric_func], qrel, run_data)\n",
        "        )\n",
        "\n",
        "        # Append a deep copy to avoid accidental modifications\n",
        "        table.append(deepcopy(per_query_scores))  # TODO WTF? qui sicuro non serve\n",
        "\n",
        "    # Append the table for this metric to the overall scores list\n",
        "    scores.append(deepcopy(table)) # TODO pure qua non serve immagino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2knaIfH3K6rz"
      },
      "source": [
        "#### Statistical Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGXXzYtbQvES"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.multitest import multipletests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "def p_values_correction(\n",
        "    metric_idx: int,\n",
        "    method: str\n",
        "):\n",
        "    \"\"\"\n",
        "    Performs pairwise t-tests between scoring methods for a given metric,\n",
        "    applies multiple testing correction, and returns a DataFrame of signed corrected p-values.\n",
        "\n",
        "    Parameters:\n",
        "        metric_idx (int): Index of the metric to evaluate.\n",
        "        method (str): Correction method to use ('bonferroni', 'holm', 'fdr_bh', etc.).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Matrix of corrected p-values with direction indicators.\n",
        "    \"\"\"\n",
        "    # TODO questa si ritrova i methods dal global senza renderlo esplicito, not troppo carino, anche scores\n",
        "\n",
        "    # Initialize p-value matrix\n",
        "    p_values = pd.DataFrame(index=methods, columns=methods, dtype=object)  # NOTE: row / columns labels are methods names (BM25 combinations)\n",
        "\n",
        "    # Collect raw p-values from pairwise comparisons\n",
        "    raw_pvals = []\n",
        "    comparisons = []\n",
        "\n",
        "    # Make pair-wise tests\n",
        "    for row_method in methods:\n",
        "        for col_method in methods:\n",
        "\n",
        "            # Skipping diagonal because it's the same method\n",
        "            if row_method == col_method:\n",
        "                p_values.loc[row_method, col_method] = np.nan\n",
        "                continue\n",
        "\n",
        "            # Get per-query scores for both methods, and the metric_idx metric\n",
        "            scores_a = scores[metric_idx][methods.index(row_method)]\n",
        "            scores_b = scores[metric_idx][methods.index(col_method)]\n",
        "\n",
        "            # Run paired t-test\n",
        "            t_stat, p_val = ttest_rel(scores_a, scores_b)\n",
        "            raw_pvals.append(p_val)\n",
        "            comparisons.append((row_method, col_method, t_stat >= 0))  # NOTE: Store direction (True = the row method tends to perform better or equal than the column method)\n",
        "\n",
        "    # Apply multiple testing correction\n",
        "    _, corrected_pvals, _, _ = multipletests(raw_pvals, method=method)\n",
        "\n",
        "    # Fill in the corrected p-values with direction indicators\n",
        "    for i, (row_method, col_method, is_greater) in enumerate(comparisons):\n",
        "        sign = '+' if is_greater else '-'\n",
        "        p_values.loc[row_method, col_method] = f\"({sign}){corrected_pvals[i]:.6f}\"\n",
        "\n",
        "    return p_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsTYU7iUK6r0"
      },
      "source": [
        "This segment of code applies the Benjamini-Hochberg (BH) correction to the p-values obtained from pairwise statistical comparisons across different retrieval methods for three evaluation metrics: MAP, nDCG@10, and MRR@10. For each metric, the p_values_correction function is called with the corresponding index and the \"fdr_bh\" method to adjust for multiple comparisons while controlling the false discovery rate. The corrected p-values are stored in separate DataFrames—p_values_MAP, p_values_nDCG, and p_values_MRR—each representing the significance of performance differences between methods. These tables are then converted to markdown format for easy visualization or reporting, enabling a clear and interpretable summary of which method comparisons remain statistically significant after correction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "h7rXQcfXK6r0",
        "outputId": "e562429a-bcb6-4a4e-f1fc-c4a05423492c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|                        | bm25_run_b=0.65_k1=1   | bm25_run_b=0.75_k1=1   | bm25_run_b=0.85_k1=1   | bm25_run_b=0.65_k1=1.2   | bm25_run_b=0.75_k1=1.2   | bm25_run_b=0.85_k1=1.2   | bm25_run_b=0.65_k1=1.4   | bm25_run_b=0.75_k1=1.4   | bm25_run_b=0.85_k1=1.4   |\\n|:-----------------------|:-----------------------|:-----------------------|:-----------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|\\n| bm25_run_b=0.65_k1=1   | nan                    | (+)0.122513            | (+)0.122513            | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              |\\n| bm25_run_b=0.75_k1=1   | (-)0.122513            | nan                    | (+)0.122513            | (-)0.933471              | (+)0.122513              | (+)0.122513              | (+)0.261466              | (+)0.122513              | (+)0.122513              |\\n| bm25_run_b=0.85_k1=1   | (-)0.122513            | (-)0.122513            | nan                    | (-)0.216359              | (-)0.933471              | (+)0.209427              | (-)0.943246              | (+)0.365486              | (+)0.122513              |\\n| bm25_run_b=0.65_k1=1.2 | (-)0.122513            | (+)0.933471            | (+)0.216359            | nan                      | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              |\\n| bm25_run_b=0.75_k1=1.2 | (-)0.122513            | (-)0.122513            | (+)0.933471            | (-)0.122513              | nan                      | (+)0.122513              | (+)0.943246              | (+)0.122513              | (+)0.122513              |\\n| bm25_run_b=0.85_k1=1.2 | (-)0.122513            | (-)0.122513            | (-)0.209427            | (-)0.122513              | (-)0.122513              | nan                      | (-)0.231197              | (+)0.873522              | (+)0.122513              |\\n| bm25_run_b=0.65_k1=1.4 | (-)0.122513            | (-)0.261466            | (+)0.943246            | (-)0.122513              | (-)0.943246              | (+)0.231197              | nan                      | (+)0.122513              | (+)0.122513              |\\n| bm25_run_b=0.75_k1=1.4 | (-)0.122513            | (-)0.122513            | (-)0.365486            | (-)0.122513              | (-)0.122513              | (-)0.873522              | (-)0.122513              | nan                      | (+)0.122513              |\\n| bm25_run_b=0.85_k1=1.4 | (-)0.122513            | (-)0.122513            | (-)0.122513            | (-)0.122513              | (-)0.122513              | (-)0.122513              | (-)0.122513              | (-)0.122513              | nan                      |'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MAP = p_values_correction(0, \"fdr_bh\")\n",
        "p_values_MAP.to_markdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "7b7Buv2NK6r1",
        "outputId": "a97a03dc-bb53-4632-bfd9-4cc06c3e7ac6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|                        | bm25_run_b=0.65_k1=1   | bm25_run_b=0.75_k1=1   | bm25_run_b=0.85_k1=1   | bm25_run_b=0.65_k1=1.2   | bm25_run_b=0.75_k1=1.2   | bm25_run_b=0.85_k1=1.2   | bm25_run_b=0.65_k1=1.4   | bm25_run_b=0.75_k1=1.4   | bm25_run_b=0.85_k1=1.4   |\\n|:-----------------------|:-----------------------|:-----------------------|:-----------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|\\n| bm25_run_b=0.65_k1=1   | nan                    | (+)0.249449            | (+)0.095179            | (+)0.140184              | (+)0.043462              | (+)0.043462              | (+)0.140184              | (+)0.043462              | (+)0.043462              |\\n| bm25_run_b=0.75_k1=1   | (-)0.249449            | nan                    | (+)0.283433            | (-)0.709305              | (+)0.108797              | (+)0.108797              | (-)0.894233              | (+)0.108797              | (+)0.108797              |\\n| bm25_run_b=0.85_k1=1   | (-)0.095179            | (-)0.283433            | nan                    | (-)0.169155              | (+)0.817367              | (+)0.189504              | (-)0.266548              | (+)0.800955              | (+)0.155886              |\\n| bm25_run_b=0.65_k1=1.2 | (-)0.140184            | (+)0.709305            | (+)0.169155            | nan                      | (+)0.108797              | (+)0.095179              | (+)0.643535              | (+)0.108797              | (+)0.095041              |\\n| bm25_run_b=0.75_k1=1.2 | (-)0.043462            | (-)0.108797            | (-)0.817367            | (-)0.108797              | nan                      | (+)0.653847              | (-)0.108797              | (+)0.870052              | (+)0.568091              |\\n| bm25_run_b=0.85_k1=1.2 | (-)0.043462            | (-)0.108797            | (-)0.189504            | (-)0.095179              | (-)0.653847              | nan                      | (-)0.081059              | (-)0.659967              | (+)0.220320              |\\n| bm25_run_b=0.65_k1=1.4 | (-)0.140184            | (+)0.894233            | (+)0.266548            | (-)0.643535              | (+)0.108797              | (+)0.081059              | nan                      | (+)0.108797              | (+)0.052287              |\\n| bm25_run_b=0.75_k1=1.4 | (-)0.043462            | (-)0.108797            | (-)0.800955            | (-)0.108797              | (-)0.870052              | (+)0.659967              | (-)0.108797              | nan                      | (+)0.582671              |\\n| bm25_run_b=0.85_k1=1.4 | (-)0.043462            | (-)0.108797            | (-)0.155886            | (-)0.095041              | (-)0.568091              | (-)0.220320              | (-)0.052287              | (-)0.582671              | nan                      |'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_nDCG = p_values_correction(1, \"fdr_bh\")\n",
        "p_values_nDCG.to_markdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "6l53h_fhK6r1",
        "outputId": "f57e8881-6545-4189-f679-008637dc51a6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|                        | bm25_run_b=0.65_k1=1   | bm25_run_b=0.75_k1=1   | bm25_run_b=0.85_k1=1   | bm25_run_b=0.65_k1=1.2   | bm25_run_b=0.75_k1=1.2   | bm25_run_b=0.85_k1=1.2   | bm25_run_b=0.65_k1=1.4   | bm25_run_b=0.75_k1=1.4   | bm25_run_b=0.85_k1=1.4   |\\n|:-----------------------|:-----------------------|:-----------------------|:-----------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|\\n| bm25_run_b=0.65_k1=1   | nan                    | (+)nan                 | (-)nan                 | (-)nan                   | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\\n| bm25_run_b=0.75_k1=1   | (-)nan                 | nan                    | (-)nan                 | (-)nan                   | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\\n| bm25_run_b=0.85_k1=1   | (-)nan                 | (+)nan                 | nan                    | (-)nan                   | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\\n| bm25_run_b=0.65_k1=1.2 | (-)nan                 | (+)nan                 | (-)nan                 | nan                      | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\\n| bm25_run_b=0.75_k1=1.2 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | nan                      | (-)nan                   | (-)nan                   | (-)nan                   | (-)nan                   |\\n| bm25_run_b=0.85_k1=1.2 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | (+)nan                   | nan                      | (-)nan                   | (+)nan                   | (-)nan                   |\\n| bm25_run_b=0.65_k1=1.4 | (+)nan                 | (+)nan                 | (+)nan                 | (+)nan                   | (+)nan                   | (+)nan                   | nan                      | (+)nan                   | (+)nan                   |\\n| bm25_run_b=0.75_k1=1.4 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | (-)nan                   | (-)nan                   | (-)nan                   | nan                      | (-)nan                   |\\n| bm25_run_b=0.85_k1=1.4 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | (+)nan                   | (-)nan                   | (-)nan                   | (+)nan                   | nan                      |'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MRR = p_values_correction(2, \"fdr_bh\")\n",
        "p_values_MRR.to_markdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJE1vCP5K6r2"
      },
      "source": [
        "#### MAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnjeKNj81650"
      },
      "source": [
        "|                        | bm25_run_b=0.65_k1=1   | bm25_run_b=0.75_k1=1   | bm25_run_b=0.85_k1=1   | bm25_run_b=0.65_k1=1.2   | bm25_run_b=0.75_k1=1.2   | bm25_run_b=0.85_k1=1.2   | bm25_run_b=0.65_k1=1.4   | bm25_run_b=0.75_k1=1.4   | bm25_run_b=0.85_k1=1.4   |\n",
        "|:-----------------------|:-----------------------|:-----------------------|:-----------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|\n",
        "| bm25_run_b=0.65_k1=1   | nan                    | (+)0.122513            | (+)0.122513            | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              |\n",
        "| bm25_run_b=0.75_k1=1   | (-)0.122513            | nan                    | (+)0.122513            | (-)0.933471              | (+)0.122513              | (+)0.122513              | (+)0.261466              | (+)0.122513              | (+)0.122513              |\n",
        "| bm25_run_b=0.85_k1=1   | (-)0.122513            | (-)0.122513            | nan                    | (-)0.216359              | (-)0.933471              | (+)0.209427              | (-)0.943246              | (+)0.365486              | (+)0.122513              |\n",
        "| bm25_run_b=0.65_k1=1.2 | (-)0.122513            | (+)0.933471            | (+)0.216359            | nan                      | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              | (+)0.122513              |\n",
        "| bm25_run_b=0.75_k1=1.2 | (-)0.122513            | (-)0.122513            | (+)0.933471            | (-)0.122513              | nan                      | (+)0.122513              | (+)0.943246              | (+)0.122513              | (+)0.122513              |\n",
        "| bm25_run_b=0.85_k1=1.2 | (-)0.122513            | (-)0.122513            | (-)0.209427            | (-)0.122513              | (-)0.122513              | nan                      | (-)0.231197              | (+)0.873522              | (+)0.122513              |\n",
        "| bm25_run_b=0.65_k1=1.4 | (-)0.122513            | (-)0.261466            | (+)0.943246            | (-)0.122513              | (-)0.943246              | (+)0.231197              | nan                      | (+)0.122513              | (+)0.122513              |\n",
        "| bm25_run_b=0.75_k1=1.4 | (-)0.122513            | (-)0.122513            | (-)0.365486            | (-)0.122513              | (-)0.122513              | (-)0.873522              | (-)0.122513              | nan                      | (+)0.122513              |\n",
        "| bm25_run_b=0.85_k1=1.4 | (-)0.122513            | (-)0.122513            | (-)0.122513            | (-)0.122513              | (-)0.122513              | (-)0.122513              | (-)0.122513              | (-)0.122513              | nan                      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uxYuzu3K6r2"
      },
      "source": [
        "#### nDCG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIx142BS2HKg"
      },
      "source": [
        "|                        | bm25_run_b=0.65_k1=1   | bm25_run_b=0.75_k1=1   | bm25_run_b=0.85_k1=1   | bm25_run_b=0.65_k1=1.2   | bm25_run_b=0.75_k1=1.2   | bm25_run_b=0.85_k1=1.2   | bm25_run_b=0.65_k1=1.4   | bm25_run_b=0.75_k1=1.4   | bm25_run_b=0.85_k1=1.4   |\n",
        "|:-----------------------|:-----------------------|:-----------------------|:-----------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|\n",
        "| bm25_run_b=0.65_k1=1   | nan                    | (+)0.249449            | (+)0.095179            | (+)0.140184              | (+)0.043462              | (+)0.043462              | (+)0.140184              | (+)0.043462              | (+)0.043462              |\n",
        "| bm25_run_b=0.75_k1=1   | (-)0.249449            | nan                    | (+)0.283433            | (-)0.709305              | (+)0.108797              | (+)0.108797              | (-)0.894233              | (+)0.108797              | (+)0.108797              |\n",
        "| bm25_run_b=0.85_k1=1   | (-)0.095179            | (-)0.283433            | nan                    | (-)0.169155              | (+)0.817367              | (+)0.189504              | (-)0.266548              | (+)0.800955              | (+)0.155886              |\n",
        "| bm25_run_b=0.65_k1=1.2 | (-)0.140184            | (+)0.709305            | (+)0.169155            | nan                      | (+)0.108797              | (+)0.095179              | (+)0.643535              | (+)0.108797              | (+)0.095041              |\n",
        "| bm25_run_b=0.75_k1=1.2 | (-)0.043462            | (-)0.108797            | (-)0.817367            | (-)0.108797              | nan                      | (+)0.653847              | (-)0.108797              | (+)0.870052              | (+)0.568091              |\n",
        "| bm25_run_b=0.85_k1=1.2 | (-)0.043462            | (-)0.108797            | (-)0.189504            | (-)0.095179              | (-)0.653847              | nan                      | (-)0.081059              | (-)0.659967              | (+)0.220320              |\n",
        "| bm25_run_b=0.65_k1=1.4 | (-)0.140184            | (+)0.894233            | (+)0.266548            | (-)0.643535              | (+)0.108797              | (+)0.081059              | nan                      | (+)0.108797              | (+)0.052287              |\n",
        "| bm25_run_b=0.75_k1=1.4 | (-)0.043462            | (-)0.108797            | (-)0.800955            | (-)0.108797              | (-)0.870052              | (+)0.659967              | (-)0.108797              | nan                      | (+)0.582671              |\n",
        "| bm25_run_b=0.85_k1=1.4 | (-)0.043462            | (-)0.108797            | (-)0.155886            | (-)0.095041              | (-)0.568091              | (-)0.220320              | (-)0.052287              | (-)0.582671              | nan                      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZqzFlqSK6r3"
      },
      "source": [
        "#### MRR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFzJim702Z9z"
      },
      "source": [
        "Although it may seem unusual to encounter many NaN values, this outcome is not unexpected.\n",
        "In most cases, the highest score among relevant documents remains largely unaffected across different combinations.\n",
        "As a result, the position of the first relevant document does not change, which explains why NaN values appear in the evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIzYSvuY2TrE"
      },
      "source": [
        "|                        | bm25_run_b=0.65_k1=1   | bm25_run_b=0.75_k1=1   | bm25_run_b=0.85_k1=1   | bm25_run_b=0.65_k1=1.2   | bm25_run_b=0.75_k1=1.2   | bm25_run_b=0.85_k1=1.2   | bm25_run_b=0.65_k1=1.4   | bm25_run_b=0.75_k1=1.4   | bm25_run_b=0.85_k1=1.4   |\n",
        "|:-----------------------|:-----------------------|:-----------------------|:-----------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------|\n",
        "| bm25_run_b=0.65_k1=1   | nan                    | (+)nan                 | (-)nan                 | (-)nan                   | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\n",
        "| bm25_run_b=0.75_k1=1   | (-)nan                 | nan                    | (-)nan                 | (-)nan                   | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\n",
        "| bm25_run_b=0.85_k1=1   | (-)nan                 | (+)nan                 | nan                    | (-)nan                   | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\n",
        "| bm25_run_b=0.65_k1=1.2 | (-)nan                 | (+)nan                 | (-)nan                 | nan                      | (+)nan                   | (+)nan                   | (-)nan                   | (+)nan                   | (+)nan                   |\n",
        "| bm25_run_b=0.75_k1=1.2 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | nan                      | (-)nan                   | (-)nan                   | (-)nan                   | (-)nan                   |\n",
        "| bm25_run_b=0.85_k1=1.2 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | (+)nan                   | nan                      | (-)nan                   | (+)nan                   | (-)nan                   |\n",
        "| bm25_run_b=0.65_k1=1.4 | (+)nan                 | (+)nan                 | (+)nan                 | (+)nan                   | (+)nan                   | (+)nan                   | nan                      | (+)nan                   | (+)nan                   |\n",
        "| bm25_run_b=0.75_k1=1.4 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | (-)nan                   | (-)nan                   | (-)nan                   | nan                      | (-)nan                   |\n",
        "| bm25_run_b=0.85_k1=1.4 | (-)nan                 | (-)nan                 | (-)nan                 | (-)nan                   | (+)nan                   | (-)nan                   | (-)nan                   | (+)nan                   | nan                      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w3ZJDhuK6r4"
      },
      "source": [
        "The best model is: b=0.65, k1=1 according both nDCG and MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UpYuOEgr-jY"
      },
      "outputs": [],
      "source": [
        "# TODO: qui bisogna giustificarla meglio, non sempre è statisticamente significativa la differenza (anzi quasi mai)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL_3p4esfh_-"
      },
      "source": [
        "### Compute Run Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_hby7JkxAjy"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZR_nh1rgTmN"
      },
      "source": [
        "\n",
        "The two functions, extract_queries() and write_run_file(), together form a crucial part of the retrieval and evaluation pipeline in an information retrieval (IR) system, specifically handling the preparation of input queries and the generation of output run files for evaluation.\n",
        "\n",
        "The extract_queries() function is responsible for reading a tab-separated values (TSV) file that contains pairs of query identifiers and their corresponding query texts. Each line in the file is expected to follow the format query_id<TAB>query_text. The function parses this file line by line, splitting each entry into a tuple of (query_id, query) and appending it to a list. It also includes a safeguard to skip malformed lines that don't match the expected format, ensuring robustness against minor formatting errors. The resulting list of tuples provides a structured and standardized way to store multiple queries, which can then be processed in bulk by the retrieval system.\n",
        "\n",
        "The write_run_file() function, on the other hand, takes these extracted queries and runs them through the retrieval engine using a provided inverted index. For each query, it calls the query_process() function to obtain a ranked list of documents, represented as pairs of (score, docid) values. These results are then formatted according to the TREC standard, a widely used evaluation format in IR research, which includes columns for the query ID, document number, rank position, score, and run name (an identifier for the retrieval experiment). Before writing to the file, document identifiers are cleaned and standardized by removing prefixes (e.g., “DOC”) to match the TREC conventions. The final run file, saved to the specified output path, serves as an input for evaluation tools like trec_eval or ir_measures, enabling performance comparison across different retrieval models. Together, these functions automate the process of preparing queries, retrieving ranked results, and producing evaluation-ready outputs — ensuring reproducibility, consistency, and compatibility with standard IR benchmarking frameworks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EShlKgcer-jZ"
      },
      "outputs": [],
      "source": [
        "# TODO: questi sono metodi sono identici a prima? in caso toglierei, no?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQJWkY-_ltMB"
      },
      "outputs": [],
      "source": [
        "def extract_queries(\n",
        "    filename: str\n",
        ") -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Reads a TSV file containing query IDs and query texts,\n",
        "        and returns them as a list of (query_id, query) tuples.\n",
        "\n",
        "    Arguments:\n",
        "        filename (str): Path to the TSV file.\n",
        "          Each line should contain 'query_id<TAB>query_text'.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list where each element is a tuple\n",
        "          containing (query_id, query_text).\n",
        "    \"\"\"\n",
        "    queries: List[Tuple[str, str]] = []\n",
        "\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "\n",
        "            # Skipping malformed lines\n",
        "            try:\n",
        "                query_id, query = line.strip().split(\"\\t\")\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            # Appending query_id and query text\n",
        "            queries.append((query_id, query))\n",
        "\n",
        "    return queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTT4k__Rm-1Q"
      },
      "outputs": [],
      "source": [
        "def write_run_file(\n",
        "    queries: list[tuple[str, str]],\n",
        "    index: InvertedIndex,\n",
        "    output_path: str,\n",
        "    run_name: str = \"my_run\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Generates a TREC-formatted run file from a set of queries and the inverted index.\n",
        "\n",
        "    Arguments:\n",
        "        queries (Dict[int, str]): Mapping from query IDs to query strings.\n",
        "        index (InvertedIndex): The inverted index used for retrieval.\n",
        "        output_path (str): Path to save the output run file.\n",
        "        run_name (str): Identifier for the run (appears in the last column).\n",
        "    \"\"\"\n",
        "\n",
        "    with open(output_path, \"w\") as f:\n",
        "        for qid, query in queries:\n",
        "\n",
        "            # List of scores and docids ordered by score\n",
        "            results: list[tuple[np.float64, np.int32]] = query_process(query, index)\n",
        "\n",
        "            # Iterating over results, converting docid into docno while\n",
        "            # removing DOC and storing the line in the run file\n",
        "            for rank, (score, docid) in enumerate(results, start=1):\n",
        "                docno: str = doc_index[docid - 1][0]\n",
        "                docno: str = docno.replace(\"DOC\", \"\")\n",
        "                f.write(f\"{qid} Q0 {docno} {rank} {score:.6f} {run_name}\\n\")\n",
        "\n",
        "    print(f\"Run file saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyZUWnGKxDTu"
      },
      "source": [
        "#### Creating Run Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnjuYmbDgnQi"
      },
      "source": [
        "This section of the code defines and executes the experimental pipeline used to evaluate multiple retrieval models across different query datasets a common setup in information retrieval research. It is organized into four main parts: query file configuration, run suffix definition, scoring model specification, and run generation.\n",
        "\n",
        "First, the code defines query_files, a path to query files from the MS MARCO test sets for 2019 first evaluation set. Each file consists of query IDs and their corresponding text in TSV format, enabling the system to process queries from different years independently.\n",
        "\n",
        "Next, the code defines a list of scoring function objects under scorers, representing various retrieval models ranging from simple ones like TF (Term Frequency) and IDF (Inverse Document Frequency) to more sophisticated ones such as TF-IDF and the BM series (BM11, BM15, BM25). Each scorer encapsulates a mathematical formula used to assign relevance scores to documents based on their relationship with the query terms. The run_names list mirrors the scorers, assigning a readable identifier (e.g., tf_run, bm25_run) that appears in the output run files and evaluation logs.\n",
        "\n",
        "Finally, the main loop iterates through each combination of query file and run suffix, calling the helper function extract_queries() to read and parse all queries. For every scorer in the list, a new InvertedIndex object is instantiated this allows each scoring function to be applied independently while keeping the underlying data structures (lexicon, posting lists, document stats) the same. The results are then passed to the write_run_file() function, which retrieves the top-ranked documents for each query and writes them in TREC format to an output file named according to the scoring model and year (e.g., bm25_run_2019).\n",
        "\n",
        "In essence, this code automates a systematic retrieval experiment where multiple scoring models are evaluated on multiple query datasets. By separating configurations (queries, scorers, and filenames), it ensures modularity, reproducibility, and scalability allowing researchers to efficiently compare retrieval performance across different models and datasets in a controlled and well-documented framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-upfBNn1PyI"
      },
      "outputs": [],
      "source": [
        "# ---------------------- Query Files ---------------------- #\n",
        "# Path to MS MARCO first evaluation set query file.\n",
        "# File contains query IDs and query text in TSV format.\n",
        "queries_file = \"eval-set-1.tsv\"\n",
        "\n",
        "\n",
        "# ---------------------- Scoring Functions ---------------------- #\n",
        "# List of scorer objects that implement different retrieval models.\n",
        "# Each scorer defines how to compute document scores during retrieval.\n",
        "scorers = [\n",
        "    TFScorer(),                   # simple term frequency scoring\n",
        "    IDFScorer(),                  # inverse document frequency scoring\n",
        "    TFIDFScorer(),                # combined TF-IDF scoring\n",
        "    BM11Scorer(),                 # BM11 variant\n",
        "    BM15Scorer(),                 # BM15 variant\n",
        "    BM25Scorer(k1=1.0, b=0.65)    # standard BM25 scoring\n",
        "]\n",
        "\n",
        "# ---------------------- Run Names ---------------------- #\n",
        "# List of run identifiers corresponding to the scorers above.\n",
        "# These names appear in the run file and are used by evaluation tools.\n",
        "run_names = [\n",
        "    \"tf_run\",     # run using TF scoring\n",
        "    \"idf_run\",    # run using IDF scoring\n",
        "    \"tfidf_run\",  # run using TF-IDF scoring\n",
        "    \"bm11_run\",   # run using BM11 scoring\n",
        "    \"bm15_run\",   # run using BM15 scoring\n",
        "    \"bm25_run\"    # run using BM25 scoring\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vOrtiEA-0NhV",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "82c9442b-a8d5-4682-fafa-53475550483c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "daat (3369.512 ms)\n",
            "daat (2413.840 ms)\n",
            "daat (0.427 ms)\n",
            "daat (305.093 ms)\n",
            "daat (9204.375 ms)\n",
            "daat (3810.138 ms)\n",
            "daat (2050.464 ms)\n",
            "daat (7559.655 ms)\n",
            "daat (1640.114 ms)\n",
            "daat (1007.523 ms)\n",
            "daat (4176.325 ms)\n",
            "daat (7079.831 ms)\n",
            "daat (632.310 ms)\n",
            "daat (10328.781 ms)\n",
            "daat (5875.533 ms)\n",
            "daat (6849.895 ms)\n",
            "daat (4421.413 ms)\n",
            "daat (28512.858 ms)\n",
            "daat (1766.466 ms)\n",
            "daat (516.128 ms)\n",
            "daat (1155.939 ms)\n",
            "daat (3631.293 ms)\n",
            "daat (382.923 ms)\n",
            "daat (11000.242 ms)\n",
            "daat (24289.334 ms)\n",
            "daat (2051.642 ms)\n",
            "daat (5133.271 ms)\n",
            "daat (24727.500 ms)\n",
            "daat (979.397 ms)\n",
            "daat (10214.860 ms)\n",
            "daat (2285.490 ms)\n",
            "daat (1798.054 ms)\n",
            "daat (332.321 ms)\n",
            "daat (10536.668 ms)\n",
            "daat (2293.660 ms)\n",
            "daat (1661.789 ms)\n",
            "daat (6393.504 ms)\n",
            "daat (8357.380 ms)\n",
            "daat (1432.653 ms)\n",
            "daat (3025.335 ms)\n",
            "daat (5967.372 ms)\n",
            "daat (5656.662 ms)\n",
            "daat (10190.184 ms)\n",
            "daat (6652.640 ms)\n",
            "daat (5685.286 ms)\n",
            "daat (21590.929 ms)\n",
            "daat (3258.810 ms)\n",
            "daat (5142.411 ms)\n",
            "daat (11924.356 ms)\n",
            "daat (1965.310 ms)\n",
            "daat (1408.371 ms)\n",
            "daat (100.683 ms)\n",
            "daat (2627.657 ms)\n",
            "daat (9115.373 ms)\n",
            "daat (475.168 ms)\n",
            "daat (915.565 ms)\n",
            "daat (974.439 ms)\n",
            "daat (1690.560 ms)\n",
            "daat (19765.923 ms)\n",
            "daat (16688.407 ms)\n",
            "daat (1489.524 ms)\n",
            "daat (9081.353 ms)\n",
            "daat (6012.223 ms)\n",
            "daat (4617.261 ms)\n",
            "daat (13172.989 ms)\n",
            "daat (2475.690 ms)\n",
            "daat (3319.993 ms)\n",
            "daat (3248.155 ms)\n",
            "daat (5038.710 ms)\n",
            "daat (636.916 ms)\n",
            "daat (2776.514 ms)\n",
            "daat (9871.651 ms)\n",
            "daat (386.530 ms)\n",
            "daat (10681.442 ms)\n",
            "daat (5998.071 ms)\n",
            "daat (1215.881 ms)\n",
            "daat (5052.863 ms)\n",
            "daat (1844.385 ms)\n",
            "daat (1.386 ms)\n",
            "daat (6051.109 ms)\n",
            "daat (1053.348 ms)\n",
            "daat (8677.305 ms)\n",
            "daat (1098.964 ms)\n",
            "daat (7659.755 ms)\n",
            "daat (3944.040 ms)\n",
            "daat (12768.603 ms)\n",
            "daat (3197.067 ms)\n",
            "daat (2612.328 ms)\n",
            "daat (146.452 ms)\n",
            "daat (4640.431 ms)\n",
            "daat (12660.038 ms)\n",
            "daat (10026.767 ms)\n",
            "daat (10733.260 ms)\n",
            "daat (775.608 ms)\n",
            "daat (1017.900 ms)\n",
            "daat (1660.294 ms)\n",
            "daat (423.645 ms)\n",
            "daat (229.442 ms)\n",
            "daat (3406.312 ms)\n",
            "daat (4302.284 ms)\n",
            "daat (5167.481 ms)\n",
            "daat (7992.983 ms)\n",
            "daat (4843.607 ms)\n",
            "daat (1945.720 ms)\n",
            "daat (4121.262 ms)\n",
            "daat (5716.533 ms)\n",
            "daat (3068.978 ms)\n",
            "daat (603.544 ms)\n",
            "daat (0.353 ms)\n",
            "daat (4356.952 ms)\n",
            "daat (1963.854 ms)\n",
            "daat (5410.325 ms)\n",
            "daat (1997.605 ms)\n",
            "daat (8982.557 ms)\n",
            "daat (3486.165 ms)\n",
            "daat (4901.726 ms)\n",
            "daat (4175.079 ms)\n",
            "daat (4719.658 ms)\n",
            "daat (0.359 ms)\n",
            "daat (8104.944 ms)\n",
            "daat (4054.974 ms)\n",
            "daat (819.461 ms)\n",
            "daat (4069.266 ms)\n",
            "daat (402.567 ms)\n",
            "daat (42.337 ms)\n",
            "daat (989.993 ms)\n",
            "daat (1485.818 ms)\n",
            "daat (9679.091 ms)\n",
            "daat (254.753 ms)\n",
            "daat (3534.933 ms)\n",
            "daat (8738.564 ms)\n",
            "daat (3072.830 ms)\n",
            "daat (10887.879 ms)\n",
            "daat (0.277 ms)\n",
            "daat (12489.185 ms)\n",
            "daat (1865.884 ms)\n",
            "daat (1588.535 ms)\n",
            "daat (3423.257 ms)\n",
            "daat (8779.905 ms)\n",
            "daat (5191.370 ms)\n",
            "Run file saved to: tf_run\n",
            "daat (3053.218 ms)\n",
            "daat (2924.679 ms)\n",
            "daat (0.334 ms)\n",
            "daat (458.642 ms)\n",
            "daat (5514.376 ms)\n",
            "daat (2986.093 ms)\n",
            "daat (1906.278 ms)\n",
            "daat (6905.416 ms)\n",
            "daat (1566.504 ms)\n",
            "daat (858.406 ms)\n",
            "daat (3848.527 ms)\n",
            "daat (6030.576 ms)\n",
            "daat (1005.087 ms)\n",
            "daat (8147.814 ms)\n",
            "daat (6890.228 ms)\n",
            "daat (5581.663 ms)\n",
            "daat (3040.375 ms)\n",
            "daat (27116.331 ms)\n",
            "daat (1620.589 ms)\n",
            "daat (496.468 ms)\n",
            "daat (1902.131 ms)\n",
            "daat (4298.811 ms)\n",
            "daat (372.324 ms)\n",
            "daat (8076.128 ms)\n",
            "daat (22821.490 ms)\n",
            "daat (1840.942 ms)\n",
            "daat (6069.275 ms)\n",
            "daat (21498.712 ms)\n",
            "daat (896.261 ms)\n",
            "daat (9682.846 ms)\n",
            "daat (2105.306 ms)\n",
            "daat (1678.907 ms)\n",
            "daat (292.094 ms)\n",
            "daat (9686.466 ms)\n",
            "daat (2068.518 ms)\n",
            "daat (1447.958 ms)\n",
            "daat (4787.805 ms)\n",
            "daat (9099.701 ms)\n",
            "daat (1331.928 ms)\n",
            "daat (2275.065 ms)\n",
            "daat (6247.295 ms)\n",
            "daat (5332.365 ms)\n",
            "daat (9623.355 ms)\n",
            "daat (5676.573 ms)\n",
            "daat (4691.532 ms)\n",
            "daat (21563.356 ms)\n",
            "daat (1746.737 ms)\n",
            "daat (5170.404 ms)\n",
            "daat (10332.171 ms)\n",
            "daat (1807.542 ms)\n",
            "daat (2143.226 ms)\n",
            "daat (158.047 ms)\n",
            "daat (3385.947 ms)\n",
            "daat (6614.368 ms)\n",
            "daat (417.939 ms)\n",
            "daat (825.249 ms)\n",
            "daat (917.242 ms)\n",
            "daat (2666.964 ms)\n",
            "daat (18459.764 ms)\n",
            "daat (15024.761 ms)\n",
            "daat (1382.293 ms)\n",
            "daat (9842.757 ms)\n",
            "daat (4341.610 ms)\n",
            "daat (4364.440 ms)\n",
            "daat (8534.666 ms)\n",
            "daat (1388.051 ms)\n",
            "daat (2299.008 ms)\n",
            "daat (2128.127 ms)\n",
            "daat (6684.225 ms)\n",
            "daat (564.433 ms)\n",
            "daat (2582.694 ms)\n",
            "daat (9048.709 ms)\n",
            "daat (490.533 ms)\n",
            "daat (8222.642 ms)\n",
            "daat (7391.742 ms)\n",
            "daat (1137.258 ms)\n",
            "daat (2958.820 ms)\n",
            "daat (1723.340 ms)\n",
            "daat (1.047 ms)\n",
            "daat (7617.058 ms)\n",
            "daat (948.318 ms)\n",
            "daat (6429.009 ms)\n",
            "daat (1050.574 ms)\n",
            "daat (8048.863 ms)\n",
            "daat (2976.667 ms)\n",
            "daat (12205.534 ms)\n",
            "daat (2939.679 ms)\n",
            "daat (2386.509 ms)\n",
            "daat (131.635 ms)\n",
            "daat (5639.966 ms)\n",
            "daat (11771.239 ms)\n",
            "daat (8291.669 ms)\n",
            "daat (10136.554 ms)\n",
            "daat (675.910 ms)\n",
            "daat (908.895 ms)\n",
            "daat (1527.151 ms)\n",
            "daat (360.733 ms)\n",
            "daat (199.337 ms)\n",
            "daat (3097.919 ms)\n",
            "daat (3685.011 ms)\n",
            "daat (5262.303 ms)\n",
            "daat (7049.863 ms)\n",
            "daat (5306.100 ms)\n",
            "daat (1900.547 ms)\n",
            "daat (3797.392 ms)\n",
            "daat (4800.704 ms)\n",
            "daat (3486.756 ms)\n",
            "daat (553.533 ms)\n",
            "daat (0.258 ms)\n",
            "daat (4283.617 ms)\n",
            "daat (1520.504 ms)\n",
            "daat (4941.541 ms)\n",
            "daat (2411.218 ms)\n",
            "daat (7828.048 ms)\n",
            "daat (3967.181 ms)\n",
            "daat (4462.048 ms)\n",
            "daat (3254.177 ms)\n",
            "daat (3066.209 ms)\n",
            "daat (0.268 ms)\n",
            "daat (9489.662 ms)\n",
            "daat (2305.725 ms)\n",
            "daat (403.661 ms)\n",
            "daat (5023.483 ms)\n",
            "daat (643.407 ms)\n",
            "daat (66.810 ms)\n",
            "daat (1273.227 ms)\n",
            "daat (1407.454 ms)\n",
            "daat (7162.482 ms)\n",
            "daat (211.976 ms)\n",
            "daat (5196.390 ms)\n",
            "daat (6556.456 ms)\n",
            "daat (2794.516 ms)\n",
            "daat (10183.779 ms)\n",
            "daat (0.167 ms)\n",
            "daat (12218.957 ms)\n",
            "daat (1282.628 ms)\n",
            "daat (1544.714 ms)\n",
            "daat (3123.134 ms)\n",
            "daat (8150.963 ms)\n",
            "daat (4833.697 ms)\n",
            "Run file saved to: idf_run\n",
            "daat (5557.547 ms)\n",
            "daat (2882.562 ms)\n",
            "daat (0.226 ms)\n",
            "daat (308.538 ms)\n",
            "daat (5422.888 ms)\n",
            "daat (4889.882 ms)\n",
            "daat (2751.672 ms)\n",
            "daat (6295.492 ms)\n",
            "daat (1908.077 ms)\n",
            "daat (1804.210 ms)\n",
            "daat (5688.823 ms)\n",
            "daat (5684.063 ms)\n",
            "daat (739.351 ms)\n",
            "daat (11720.046 ms)\n",
            "daat (8009.753 ms)\n",
            "daat (7033.844 ms)\n",
            "daat (5207.650 ms)\n",
            "daat (32272.086 ms)\n",
            "daat (2094.688 ms)\n",
            "daat (572.086 ms)\n",
            "daat (1376.360 ms)\n",
            "daat (5028.519 ms)\n",
            "daat (801.896 ms)\n",
            "daat (10306.346 ms)\n",
            "daat (26463.257 ms)\n",
            "daat (2385.625 ms)\n",
            "daat (7586.681 ms)\n",
            "daat (27307.393 ms)\n",
            "daat (1163.113 ms)\n",
            "daat (10568.178 ms)\n",
            "daat (3124.708 ms)\n",
            "daat (2101.548 ms)\n",
            "daat (409.961 ms)\n",
            "daat (11683.814 ms)\n",
            "daat (2706.866 ms)\n",
            "daat (1777.228 ms)\n",
            "daat (7813.758 ms)\n",
            "daat (8854.139 ms)\n",
            "daat (2285.449 ms)\n",
            "daat (3983.825 ms)\n",
            "daat (5463.147 ms)\n",
            "daat (8171.889 ms)\n",
            "daat (9640.875 ms)\n",
            "daat (8554.217 ms)\n",
            "daat (5069.897 ms)\n",
            "daat (25520.024 ms)\n",
            "daat (2179.808 ms)\n",
            "daat (7239.030 ms)\n",
            "daat (13158.566 ms)\n",
            "daat (2304.111 ms)\n",
            "daat (1656.602 ms)\n",
            "daat (109.623 ms)\n",
            "daat (3089.378 ms)\n",
            "daat (10055.266 ms)\n",
            "daat (562.231 ms)\n",
            "daat (1042.100 ms)\n",
            "daat (1113.307 ms)\n",
            "daat (1928.789 ms)\n",
            "daat (22536.940 ms)\n",
            "daat (17762.262 ms)\n",
            "daat (1796.999 ms)\n",
            "daat (11678.487 ms)\n",
            "daat (6282.526 ms)\n",
            "daat (6260.741 ms)\n",
            "daat (9811.919 ms)\n",
            "daat (1881.854 ms)\n",
            "daat (2963.859 ms)\n",
            "daat (2645.383 ms)\n",
            "daat (7722.567 ms)\n",
            "daat (731.369 ms)\n",
            "daat (3195.992 ms)\n",
            "daat (11427.227 ms)\n",
            "daat (451.746 ms)\n",
            "daat (12218.744 ms)\n",
            "daat (7113.395 ms)\n",
            "daat (1428.401 ms)\n",
            "daat (5688.752 ms)\n",
            "daat (2167.678 ms)\n",
            "daat (1.346 ms)\n",
            "daat (6906.990 ms)\n",
            "daat (1556.680 ms)\n",
            "daat (9417.878 ms)\n",
            "daat (1268.981 ms)\n",
            "daat (9515.749 ms)\n",
            "daat (3653.958 ms)\n",
            "daat (14178.760 ms)\n",
            "daat (3690.014 ms)\n",
            "daat (4814.735 ms)\n",
            "daat (170.426 ms)\n",
            "daat (4678.576 ms)\n",
            "daat (14588.923 ms)\n",
            "daat (11186.029 ms)\n",
            "daat (12095.890 ms)\n",
            "daat (869.222 ms)\n",
            "daat (1188.414 ms)\n",
            "daat (1960.816 ms)\n",
            "daat (475.840 ms)\n",
            "daat (262.263 ms)\n",
            "daat (3795.447 ms)\n",
            "daat (4740.190 ms)\n",
            "daat (5844.986 ms)\n",
            "daat (9350.554 ms)\n",
            "daat (4706.416 ms)\n",
            "daat (2272.839 ms)\n",
            "daat (6325.565 ms)\n",
            "daat (4707.028 ms)\n",
            "daat (3540.064 ms)\n",
            "daat (672.113 ms)\n",
            "daat (0.301 ms)\n",
            "daat (6895.421 ms)\n",
            "daat (1955.196 ms)\n",
            "daat (4497.525 ms)\n",
            "daat (2300.096 ms)\n",
            "daat (10713.735 ms)\n",
            "daat (3352.365 ms)\n",
            "daat (6691.427 ms)\n",
            "daat (3932.168 ms)\n",
            "daat (3713.289 ms)\n",
            "daat (0.310 ms)\n",
            "daat (10844.672 ms)\n",
            "daat (2872.701 ms)\n",
            "daat (528.609 ms)\n",
            "daat (6568.177 ms)\n",
            "daat (550.925 ms)\n",
            "daat (48.120 ms)\n",
            "daat (1218.511 ms)\n",
            "daat (1712.656 ms)\n",
            "daat (10642.217 ms)\n",
            "daat (276.580 ms)\n",
            "daat (4084.363 ms)\n",
            "daat (9711.360 ms)\n",
            "daat (3598.181 ms)\n",
            "daat (12401.060 ms)\n",
            "daat (0.201 ms)\n",
            "daat (14625.942 ms)\n",
            "daat (1609.880 ms)\n",
            "daat (1902.452 ms)\n",
            "daat (4506.842 ms)\n",
            "daat (9006.865 ms)\n",
            "daat (7608.367 ms)\n",
            "Run file saved to: tfidf_run\n",
            "daat (4247.474 ms)\n",
            "daat (2867.162 ms)\n",
            "daat (0.509 ms)\n",
            "daat (366.684 ms)\n",
            "daat (7599.068 ms)\n",
            "daat (3790.096 ms)\n",
            "daat (2455.238 ms)\n",
            "daat (8430.964 ms)\n",
            "daat (2009.866 ms)\n",
            "daat (1151.558 ms)\n",
            "daat (4928.029 ms)\n",
            "daat (7974.664 ms)\n",
            "daat (802.263 ms)\n",
            "daat (12307.706 ms)\n",
            "daat (6272.530 ms)\n",
            "daat (9041.781 ms)\n",
            "daat (3969.662 ms)\n",
            "daat (33959.197 ms)\n",
            "daat (3089.222 ms)\n",
            "daat (606.422 ms)\n",
            "daat (1387.950 ms)\n",
            "daat (4581.853 ms)\n",
            "daat (464.133 ms)\n",
            "daat (11790.475 ms)\n",
            "daat (27487.766 ms)\n",
            "daat (2567.426 ms)\n",
            "daat (8016.251 ms)\n",
            "daat (27977.285 ms)\n",
            "daat (1195.149 ms)\n",
            "daat (10827.520 ms)\n",
            "daat (3506.969 ms)\n",
            "daat (2288.646 ms)\n",
            "daat (460.102 ms)\n",
            "daat (12471.599 ms)\n",
            "daat (2815.468 ms)\n",
            "daat (1926.935 ms)\n",
            "daat (8286.502 ms)\n",
            "daat (9736.836 ms)\n",
            "daat (2931.926 ms)\n",
            "daat (2858.232 ms)\n",
            "daat (5581.648 ms)\n",
            "daat (8578.615 ms)\n",
            "daat (11888.581 ms)\n",
            "daat (7176.872 ms)\n",
            "daat (7254.617 ms)\n",
            "daat (26190.415 ms)\n",
            "daat (2913.001 ms)\n",
            "daat (5728.104 ms)\n",
            "daat (13724.686 ms)\n",
            "daat (2458.127 ms)\n",
            "daat (2327.132 ms)\n",
            "daat (209.700 ms)\n",
            "daat (4400.555 ms)\n",
            "daat (8647.840 ms)\n",
            "daat (1098.692 ms)\n",
            "daat (1957.814 ms)\n",
            "daat (1440.481 ms)\n",
            "daat (2025.568 ms)\n",
            "daat (21726.132 ms)\n",
            "daat (20152.412 ms)\n",
            "daat (1910.623 ms)\n",
            "daat (12059.263 ms)\n",
            "daat (5639.048 ms)\n",
            "daat (7304.408 ms)\n",
            "daat (8510.011 ms)\n",
            "daat (2729.585 ms)\n",
            "daat (4071.533 ms)\n",
            "daat (2806.515 ms)\n",
            "daat (6812.071 ms)\n",
            "daat (1341.828 ms)\n",
            "daat (3942.487 ms)\n",
            "daat (11675.421 ms)\n",
            "daat (480.055 ms)\n",
            "daat (11145.372 ms)\n",
            "daat (8270.314 ms)\n",
            "daat (1471.051 ms)\n",
            "daat (4867.564 ms)\n",
            "daat (3210.044 ms)\n",
            "daat (2.531 ms)\n",
            "daat (7379.036 ms)\n",
            "daat (1284.290 ms)\n",
            "daat (10509.158 ms)\n",
            "daat (1326.435 ms)\n",
            "daat (10023.189 ms)\n",
            "daat (3955.821 ms)\n",
            "daat (14936.588 ms)\n",
            "daat (5030.863 ms)\n",
            "daat (3961.526 ms)\n",
            "daat (196.485 ms)\n",
            "daat (4790.064 ms)\n",
            "daat (15318.960 ms)\n",
            "daat (11860.391 ms)\n",
            "daat (12678.259 ms)\n",
            "daat (900.771 ms)\n",
            "daat (1227.490 ms)\n",
            "daat (1924.750 ms)\n",
            "daat (498.745 ms)\n",
            "daat (273.013 ms)\n",
            "daat (5855.781 ms)\n",
            "daat (3243.018 ms)\n",
            "daat (6306.724 ms)\n",
            "daat (9335.263 ms)\n",
            "daat (5632.529 ms)\n",
            "daat (3658.013 ms)\n",
            "daat (4911.686 ms)\n",
            "daat (5090.737 ms)\n",
            "daat (5184.031 ms)\n",
            "daat (723.800 ms)\n",
            "daat (0.319 ms)\n",
            "daat (5268.704 ms)\n",
            "daat (2115.839 ms)\n",
            "daat (6557.152 ms)\n",
            "daat (2482.875 ms)\n",
            "daat (11149.478 ms)\n",
            "daat (3469.790 ms)\n",
            "daat (5183.685 ms)\n",
            "daat (5892.430 ms)\n",
            "daat (4012.297 ms)\n",
            "daat (0.360 ms)\n",
            "daat (11253.941 ms)\n",
            "daat (3063.785 ms)\n",
            "daat (580.040 ms)\n",
            "daat (6152.005 ms)\n",
            "daat (884.414 ms)\n",
            "daat (89.634 ms)\n",
            "daat (1487.518 ms)\n",
            "daat (1864.321 ms)\n",
            "daat (10766.350 ms)\n",
            "daat (545.502 ms)\n",
            "daat (4353.966 ms)\n",
            "daat (10281.775 ms)\n",
            "daat (3723.072 ms)\n",
            "daat (12826.439 ms)\n",
            "daat (0.200 ms)\n",
            "daat (15141.283 ms)\n",
            "daat (1689.289 ms)\n",
            "daat (1946.554 ms)\n",
            "daat (4973.750 ms)\n",
            "daat (9149.835 ms)\n",
            "daat (8291.772 ms)\n",
            "Run file saved to: bm11_run\n",
            "daat (4711.012 ms)\n",
            "daat (3170.426 ms)\n",
            "daat (0.255 ms)\n",
            "daat (386.399 ms)\n",
            "daat (8471.520 ms)\n",
            "daat (4186.674 ms)\n",
            "daat (3383.135 ms)\n",
            "daat (8703.403 ms)\n",
            "daat (2324.693 ms)\n",
            "daat (1307.044 ms)\n",
            "daat (7196.393 ms)\n",
            "daat (6620.102 ms)\n",
            "daat (878.402 ms)\n",
            "daat (13308.755 ms)\n",
            "daat (8818.374 ms)\n",
            "daat (9199.095 ms)\n",
            "daat (5010.943 ms)\n",
            "daat (35455.393 ms)\n",
            "daat (3876.815 ms)\n",
            "daat (693.671 ms)\n",
            "daat (1570.257 ms)\n",
            "daat (5057.276 ms)\n",
            "daat (550.105 ms)\n",
            "daat (12773.803 ms)\n",
            "daat (29348.304 ms)\n",
            "daat (3105.980 ms)\n",
            "daat (8352.687 ms)\n",
            "daat (30321.538 ms)\n",
            "daat (1303.329 ms)\n",
            "daat (12613.494 ms)\n",
            "daat (3070.227 ms)\n",
            "daat (3857.800 ms)\n",
            "daat (785.898 ms)\n",
            "daat (12301.936 ms)\n",
            "daat (3958.965 ms)\n",
            "daat (2050.789 ms)\n",
            "daat (7519.869 ms)\n",
            "daat (11312.491 ms)\n",
            "daat (2239.200 ms)\n",
            "daat (4654.141 ms)\n",
            "daat (6240.700 ms)\n",
            "daat (9245.490 ms)\n",
            "daat (12751.228 ms)\n",
            "daat (7880.013 ms)\n",
            "daat (7812.035 ms)\n",
            "daat (28392.530 ms)\n",
            "daat (2660.337 ms)\n",
            "daat (7292.827 ms)\n",
            "daat (16013.581 ms)\n",
            "daat (2996.105 ms)\n",
            "daat (2065.289 ms)\n",
            "daat (133.601 ms)\n",
            "daat (3932.603 ms)\n",
            "daat (11374.017 ms)\n",
            "daat (667.552 ms)\n",
            "daat (1415.576 ms)\n",
            "daat (1330.254 ms)\n",
            "daat (3956.427 ms)\n",
            "daat (23367.611 ms)\n",
            "daat (21139.879 ms)\n",
            "daat (2136.621 ms)\n",
            "daat (12966.233 ms)\n",
            "daat (6203.850 ms)\n",
            "daat (7825.251 ms)\n",
            "daat (10191.337 ms)\n",
            "daat (2822.891 ms)\n",
            "daat (3312.364 ms)\n",
            "daat (3041.672 ms)\n",
            "daat (8559.990 ms)\n",
            "daat (880.151 ms)\n",
            "daat (3681.107 ms)\n",
            "daat (12475.413 ms)\n",
            "daat (556.726 ms)\n",
            "daat (13095.735 ms)\n",
            "daat (9236.893 ms)\n",
            "daat (2145.763 ms)\n",
            "daat (4329.365 ms)\n",
            "daat (2618.430 ms)\n",
            "daat (1.604 ms)\n",
            "daat (9722.364 ms)\n",
            "daat (1535.856 ms)\n",
            "daat (10907.080 ms)\n",
            "daat (1475.770 ms)\n",
            "daat (10690.511 ms)\n",
            "daat (4284.235 ms)\n",
            "daat (15859.992 ms)\n",
            "daat (4263.959 ms)\n",
            "daat (5381.692 ms)\n",
            "daat (200.253 ms)\n",
            "daat (5392.693 ms)\n",
            "daat (16414.769 ms)\n",
            "daat (12569.870 ms)\n",
            "daat (13347.802 ms)\n",
            "daat (1044.240 ms)\n",
            "daat (1332.633 ms)\n",
            "daat (2798.961 ms)\n",
            "daat (961.551 ms)\n",
            "daat (491.271 ms)\n",
            "daat (4974.554 ms)\n",
            "daat (3586.479 ms)\n",
            "daat (8242.663 ms)\n",
            "daat (8391.278 ms)\n",
            "daat (7261.888 ms)\n",
            "daat (2705.891 ms)\n",
            "daat (5847.917 ms)\n",
            "daat (6412.466 ms)\n",
            "daat (3987.760 ms)\n",
            "daat (820.343 ms)\n",
            "daat (0.329 ms)\n",
            "daat (7574.582 ms)\n",
            "daat (2432.005 ms)\n",
            "daat (5211.480 ms)\n",
            "daat (4078.121 ms)\n",
            "daat (10391.299 ms)\n",
            "daat (5619.821 ms)\n",
            "daat (5575.122 ms)\n",
            "daat (5407.264 ms)\n",
            "daat (5309.800 ms)\n",
            "daat (0.396 ms)\n",
            "daat (12206.232 ms)\n",
            "daat (3370.000 ms)\n",
            "daat (635.375 ms)\n",
            "daat (5760.769 ms)\n",
            "daat (1168.281 ms)\n",
            "daat (127.667 ms)\n",
            "daat (2353.746 ms)\n",
            "daat (1985.627 ms)\n",
            "daat (11612.603 ms)\n",
            "daat (552.582 ms)\n",
            "daat (4774.376 ms)\n",
            "daat (10740.839 ms)\n",
            "daat (4042.200 ms)\n",
            "daat (13846.748 ms)\n",
            "daat (0.182 ms)\n",
            "daat (16120.137 ms)\n",
            "daat (1854.158 ms)\n",
            "daat (3076.648 ms)\n",
            "daat (5485.328 ms)\n",
            "daat (11085.424 ms)\n",
            "daat (6829.449 ms)\n",
            "Run file saved to: bm15_run\n",
            "daat (5614.851 ms)\n",
            "daat (3781.013 ms)\n",
            "daat (0.250 ms)\n",
            "daat (404.267 ms)\n",
            "daat (6226.288 ms)\n",
            "daat (5865.816 ms)\n",
            "daat (2664.765 ms)\n",
            "daat (8030.260 ms)\n",
            "daat (3442.575 ms)\n",
            "daat (1316.443 ms)\n",
            "daat (5214.094 ms)\n",
            "daat (8385.311 ms)\n",
            "daat (903.107 ms)\n",
            "daat (13251.788 ms)\n",
            "daat (6935.061 ms)\n",
            "daat (9618.165 ms)\n",
            "daat (4392.240 ms)\n",
            "daat (37018.054 ms)\n",
            "daat (2382.713 ms)\n",
            "daat (755.103 ms)\n",
            "daat (1646.450 ms)\n",
            "daat (6892.799 ms)\n",
            "daat (669.025 ms)\n",
            "daat (12889.539 ms)\n",
            "daat (30039.404 ms)\n",
            "daat (2852.731 ms)\n",
            "daat (6905.406 ms)\n",
            "daat (31619.431 ms)\n",
            "daat (1616.488 ms)\n",
            "daat (11782.421 ms)\n",
            "daat (3629.117 ms)\n",
            "daat (2510.207 ms)\n",
            "daat (451.544 ms)\n",
            "daat (13358.931 ms)\n",
            "daat (3004.171 ms)\n",
            "daat (2092.174 ms)\n",
            "daat (8683.601 ms)\n",
            "daat (11864.290 ms)\n",
            "daat (1916.317 ms)\n",
            "daat (3134.182 ms)\n",
            "daat (7892.170 ms)\n",
            "daat (7400.537 ms)\n",
            "daat (12714.924 ms)\n",
            "daat (9554.029 ms)\n",
            "daat (5744.986 ms)\n",
            "daat (28247.753 ms)\n",
            "daat (2598.289 ms)\n",
            "daat (8074.231 ms)\n",
            "daat (14681.862 ms)\n",
            "daat (2785.116 ms)\n",
            "daat (1935.101 ms)\n",
            "daat (135.626 ms)\n",
            "daat (5520.223 ms)\n",
            "daat (9274.241 ms)\n",
            "daat (1015.441 ms)\n",
            "daat (2106.504 ms)\n",
            "daat (1876.656 ms)\n",
            "daat (2197.522 ms)\n",
            "daat (24361.014 ms)\n",
            "daat (20170.984 ms)\n",
            "daat (2110.253 ms)\n",
            "daat (12969.641 ms)\n",
            "daat (7379.676 ms)\n",
            "daat (6581.989 ms)\n",
            "daat (11207.067 ms)\n",
            "daat (2107.700 ms)\n",
            "daat (3325.516 ms)\n",
            "daat (3858.710 ms)\n",
            "daat (7903.554 ms)\n",
            "daat (874.046 ms)\n",
            "daat (3716.236 ms)\n",
            "daat (12638.897 ms)\n",
            "daat (601.402 ms)\n",
            "daat (13222.002 ms)\n",
            "daat (9875.223 ms)\n",
            "daat (1652.706 ms)\n",
            "daat (4302.895 ms)\n",
            "daat (4024.837 ms)\n",
            "daat (2.683 ms)\n",
            "daat (8347.543 ms)\n",
            "daat (1414.803 ms)\n",
            "daat (11079.641 ms)\n",
            "daat (1442.108 ms)\n",
            "daat (10809.457 ms)\n",
            "daat (4206.270 ms)\n",
            "daat (16066.928 ms)\n",
            "daat (6022.903 ms)\n",
            "daat (3577.830 ms)\n",
            "daat (231.404 ms)\n",
            "daat (6002.376 ms)\n",
            "daat (17578.419 ms)\n",
            "daat (11708.257 ms)\n",
            "daat (12523.357 ms)\n",
            "daat (1838.218 ms)\n",
            "daat (2096.831 ms)\n",
            "daat (2237.811 ms)\n",
            "daat (552.734 ms)\n",
            "daat (299.088 ms)\n",
            "daat (4521.795 ms)\n",
            "daat (4637.501 ms)\n",
            "daat (7138.817 ms)\n",
            "daat (10272.371 ms)\n",
            "daat (5508.712 ms)\n",
            "daat (2696.387 ms)\n",
            "daat (7181.107 ms)\n",
            "daat (5136.937 ms)\n",
            "daat (5517.198 ms)\n",
            "daat (1169.214 ms)\n",
            "daat (0.335 ms)\n",
            "daat (5785.326 ms)\n",
            "daat (2303.539 ms)\n",
            "daat (7052.564 ms)\n",
            "daat (2718.266 ms)\n",
            "daat (11855.074 ms)\n",
            "daat (3878.193 ms)\n",
            "daat (6456.165 ms)\n",
            "daat (5584.585 ms)\n",
            "daat (4420.578 ms)\n",
            "daat (0.362 ms)\n",
            "daat (12081.089 ms)\n",
            "daat (3361.632 ms)\n",
            "daat (629.845 ms)\n",
            "daat (7276.633 ms)\n",
            "daat (622.391 ms)\n",
            "daat (60.035 ms)\n",
            "daat (1382.374 ms)\n",
            "daat (2007.269 ms)\n",
            "daat (11929.901 ms)\n",
            "daat (362.480 ms)\n",
            "daat (4776.587 ms)\n",
            "daat (10799.855 ms)\n",
            "daat (4538.022 ms)\n",
            "daat (13878.879 ms)\n",
            "daat (1.401 ms)\n",
            "daat (18173.519 ms)\n",
            "daat (1798.377 ms)\n",
            "daat (2170.683 ms)\n",
            "daat (4463.074 ms)\n",
            "daat (10800.641 ms)\n",
            "daat (8320.793 ms)\n",
            "Run file saved to: bm25_run\n"
          ]
        }
      ],
      "source": [
        "# Extract queries from the current file\n",
        "# queries: List of tuples (query_id, query_text)\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "# Iterate over each scoring function and its run name\n",
        "for scorer, run_name in zip(scorers, run_names):\n",
        "\n",
        "    # Initialize the inverted index with the current scoring function\n",
        "    # This allows different retrieval models (e.g., TF, TF-IDF, BM25)\n",
        "    inv_ind = InvertedIndex(\n",
        "        lexicon,       # term -> (termid, ...) mapping\n",
        "        inv_d,         # list of numpy arrays: doc IDs per term\n",
        "        inv_f,         # list of numpy arrays: term frequencies per term\n",
        "        doc_index,     # document statistics\n",
        "        stats,         # global statistics (e.g., total # of documents)\n",
        "        scorer=scorer  # scoring function to use for this run\n",
        "    )\n",
        "\n",
        "    # Generate and write a TREC-formatted run file for the current query set\n",
        "    # The filename combines the run name and the run suffix\n",
        "    write_run_file(\n",
        "        queries,              # queries to process\n",
        "        inv_ind,              # inverted index with current scoring function\n",
        "        run_name,             # output filename for this run\n",
        "        run_name              # run identifier (appears in run file)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pupz1UXzaYM8"
      },
      "source": [
        "### Compute Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGYIXgJUh5iR"
      },
      "source": [
        "This section of the code defines the evaluation phase of the information retrieval experiment where multiple scoring methods are systematically compared using standard performance metrics. It begins by listing the retrieval models (methods) being evaluated, such as TF, IDF, TF-IDF, and the BM family variants (BM11, BM15, BM25). Each method corresponds to a previously generated run file, named according to a consistent naming convention.\n",
        "\n",
        "The metrics list specifies the evaluation measures used to assess retrieval effectiveness in this case, Average Precision (AP), Normalized Discounted Cumulative Gain at rank 10 (nDCG@10), and Mean Reciprocal Rank at rank 10 (MRR@10). These metrics capture different aspects of retrieval performance: AP measures overall precision across recall levels, nDCG focuses on ranking quality and relevance distribution, while MRR emphasizes how early the first relevant document appears in the ranking.\n",
        "\n",
        "The code then loads the relevance judgments (qrels_file), which provide ground-truth information about which documents are relevant for each query. Using ir_measures, each run file (containing the ranked retrieval results for a method) is read and stored in the runs list. This ensures that for every retrieval method, the corresponding set of query-document scores is available for evaluation.\n",
        "\n",
        "In the main loop, the code iterates over each metric defined earlier. For each metric, it initializes a table that will hold the per-query scores of all methods. Then, for every method in methods, it retrieves the corresponding run data and computes the metric's value for each query using ir_measures.iter_calc(). The results a sequence of scores (one per query) are stored in table. A deep copy of the scores is appended to avoid unintended data overwriting across iterations.\n",
        "\n",
        "Finally, each metric's full table (containing all methods' per-query results) is stored in the scores list. This structure effectively creates a 3D matrix of evaluation results: one dimension for metrics, one for retrieval methods, and one for queries. This organized data structure is essential for later statistical analysis (e.g., paired t-tests, p-value computation) to compare the significance of performance differences between scoring methods across queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tydxKq-hcAjK"
      },
      "source": [
        "#### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBcwrqSdcX0d"
      },
      "outputs": [],
      "source": [
        "import ir_measures\n",
        "from ir_measures import * # import natural measure name\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "\n",
        "# List of retrieval/scoring methods\n",
        "methods = [\"tf\", \"idf\", \"tfidf\", \"bm11\", \"bm15\", \"bm25\"]\n",
        "\n",
        "# Metrics to evaluate\n",
        "metrics = [\n",
        "    (\"AP\", AP),\n",
        "    (\"nDCG@10\", nDCG@10),\n",
        "    (\"MRR@10\", MRR@10)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEuJh1cSb7aS"
      },
      "source": [
        "#### Loading Qrels and Runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDrAdd_Ccdma"
      },
      "outputs": [],
      "source": [
        "##### Step 1: Load relevance judgments (qrels)\n",
        "\n",
        "# qrels_file contains the ground-truth relevance labels for queries\n",
        "qrels_file = 'eval-qrels-1.txt'\n",
        "\n",
        "# Read the qrels file using ir_measures utility\n",
        "# Each entry represents a (query_id, doc_id, relevance) tuple\n",
        "qrel = list(ir_measures.read_trec_qrels(qrels_file))\n",
        "\n",
        "\n",
        "\n",
        "##### Step 2: Load runs for each retrieval method\n",
        "\n",
        "# List of runs\n",
        "runs = []\n",
        "\n",
        "# 'methods' is the list of run filenames,\n",
        "# each corresponding to the output of a retrieval method\n",
        "for method in methods:\n",
        "\n",
        "    # The run file for this method\n",
        "    run_file = method + \"_run\"\n",
        "\n",
        "    # Read the run file using ir_measures utility\n",
        "    # Each entry represents a (query_id, doc_id, score) tuple\n",
        "    run_data = list(ir_measures.read_trec_run(run_file))\n",
        "\n",
        "    # Append the run data to the list of runs\n",
        "    runs.append(run_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9I9CbNdb9js"
      },
      "source": [
        "#### Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeHqTfPEr-jb"
      },
      "outputs": [],
      "source": [
        "# TODO: penso codice uguale a sopra, no? fare metodo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eWni7pschGS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "# This will store per-metric tables of per-query scores\n",
        "scores = []\n",
        "\n",
        "for metric_name, metric_func in metrics:\n",
        "\n",
        "    # Table: rows = methods, columns = per-query scores\n",
        "    table = []\n",
        "\n",
        "    for method_idx, method in enumerate(methods):\n",
        "        run_data = runs[method_idx]\n",
        "\n",
        "        # Compute the metric for each query in the run\n",
        "        per_query_scores = tuple(\n",
        "            m.value for m in ir_measures.iter_calc([metric_func], qrel, run_data)\n",
        "        )\n",
        "\n",
        "        # Append a deep copy to avoid accidental modifications\n",
        "        table.append(deepcopy(per_query_scores))\n",
        "\n",
        "    # Append the table for this metric to the overall scores list\n",
        "    scores.append(deepcopy(table))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMs748QxcEfM"
      },
      "source": [
        "### Statistical Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC8F4973ifQJ"
      },
      "source": [
        "This section of the code performs a pairwise statistical significance analysis between different retrieval methods using paired t-tests and summarizes the results in a structured table of p-values. The goal is to determine whether the differences in retrieval performance between methods are statistically meaningful, based on the per-query scores obtained for a specific evaluation metric (e.g., MRR@10).\n",
        "\n",
        "The process begins by creating a pandas DataFrame called p_values, where both the rows and columns correspond to the list of retrieval methods (e.g., TF, IDF, BM25). Each cell in this matrix will later contain the p-value resulting from a statistical comparison between the two methods in the corresponding row and column. A dtype=object is used to allow storage of string-formatted results that combine both the p-value and the performance direction.\n",
        "\n",
        "The code then iterates over all possible pairs of methods using nested loops. For each pair, it retrieves the per-query scores of the two methods (a and b) from the scores data structure. The diagonal entries where a method is compared to itself are set to NaN, since self-comparison is meaningless. The key statistical operation here is the paired t-test (ttest_rel(a, b)), which evaluates whether the mean difference between the two methods' per-query performances is statistically significant. The test assumes that the queries are paired, meaning each query serves as a common evaluation unit across all methods.\n",
        "\n",
        "The t-statistic returned by the test indicates the direction of the difference: a positive value means that the method in the row tends to perform better than the one in the column. The p-value reflects the probability that the observed difference occurred by chance lower values (e.g., < 0.05) suggest a statistically significant difference. The code captures both the direction and significance by storing the result as a string, such as \"(+)0.013257\" (indicating that the row method outperformed the column method with p=0.013257) or \"(-)0.427896\" (indicating worse performance).\n",
        "\n",
        "Finally, the resulting p_values DataFrame provides a compact visual summary of statistical relationships between all pairs of methods. By converting it to Markdown (p_values.to_markdown())."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-3qvcC4yDLm"
      },
      "source": [
        "We want *p_value < 0.05*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "lrx0E5cOck5b",
        "outputId": "fe33fd61-07a8-461c-829e-daf13fa7fb4f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (-)0.037434 | (-)0.006425 | (-)0.000985 | (-)0.010726 | (-)0.002332 |\\n| idf   | (+)0.037434 | nan         | (+)0.815053 | (-)0.567260 | (-)0.552977 | (-)0.265345 |\\n| tfidf | (+)0.006425 | (-)0.815053 | nan         | (-)0.232571 | (-)0.451618 | (-)0.224335 |\\n| bm11  | (+)0.000985 | (+)0.567260 | (+)0.232571 | nan         | (+)0.951553 | (-)0.572126 |\\n| bm15  | (+)0.010726 | (+)0.552977 | (+)0.451618 | (-)0.951553 | nan         | (-)0.488398 |\\n| bm25  | (+)0.002332 | (+)0.265345 | (+)0.224335 | (+)0.572126 | (+)0.488398 | nan         |'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# TODO: sopra c'era la funzione per fare questo!!!! se sopra aveva il correction method e basta per me questa parte si può eliminare compleamente, mi pare inutile e rindondante\n",
        "\n",
        "# ----------------- Prepare p-value DataFrame ----------------- #\n",
        "# Rows and columns represent the scoring methods\n",
        "p_values = pd.DataFrame(index=methods, columns=methods, dtype=object)\n",
        "\n",
        "# ----------------- Compute pairwise t-tests ----------------- #\n",
        "# scores[metric_idx][method_idx] gives per-query scores for that method\n",
        "\n",
        "metric_idx = 2    # Change this to 0 for AP, 1 for nDCG@10, etc.\n",
        "\n",
        "for row_method in methods:\n",
        "    for col_method in methods:\n",
        "        if row_method == col_method:\n",
        "            # Diagonal: comparison with itself is meaningless\n",
        "            p_values.loc[row_method, col_method] = np.nan\n",
        "            continue\n",
        "\n",
        "        # Retrieve per-query scores for the two methods\n",
        "        a = scores[metric_idx][methods.index(row_method)]\n",
        "        b = scores[metric_idx][methods.index(col_method)]\n",
        "\n",
        "        # Run paired t-test\n",
        "        # ttest_rel returns (t-statistic, p-value)\n",
        "        t_stat, p_val = ttest_rel(a, b)\n",
        "\n",
        "        # Determine if method in row performed better than column\n",
        "        # Positive t_stat -> row_method > col_method\n",
        "        greater = t_stat >= 0\n",
        "\n",
        "        # Store p-value as a string with sign indication (+/-)\n",
        "        p_values.loc[row_method, col_method] = f\"({'+' if greater else '-'}){p_val:.6f}\"\n",
        "\n",
        "# ----------------- Result ----------------- #\n",
        "# p_values DataFrame now contains a matrix of signed p-values\n",
        "# Rows = row_method, Columns = col_method\n",
        "# Example: \"(+)0.023456\" means row_method performed better than col_method with p=0.023456\n",
        "p_values.to_markdown()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VlLW0OGcIra"
      },
      "source": [
        "#### MAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U81j9Pt7vRH"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (+)0.022078 | (-)0.000639 | (-)0.000001 | (-)0.000001 | (-)0.000000 |\n",
        "| idf   | (-)0.022078 | nan         | (-)0.000020 | (-)0.000000 | (-)0.000000 | (-)0.000000 |\n",
        "| tfidf | (+)0.000639 | (+)0.000020 | nan         | (-)0.000000 | (-)0.000012 | (-)0.000001 |\n",
        "| bm11  | (+)0.000001 | (+)0.000000 | (+)0.000000 | nan         | (-)0.604252 | (-)0.014204 |\n",
        "| bm15  | (+)0.000001 | (+)0.000000 | (+)0.000012 | (+)0.604252 | nan         | (-)0.000156 |\n",
        "| bm25  | (+)0.000000 | (+)0.000000 | (+)0.000001 | (+)0.014204 | (+)0.000156 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJiNfCYrcKW0"
      },
      "source": [
        "#### nDCG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w3OJ3lw79V1"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)0.026656 | (-)0.025302 | (-)0.000172 | (-)0.006351 | (-)0.000448 |\n",
        "| idf   | (+)0.026656 | nan         | (+)0.719015 | (-)0.063093 | (-)0.576542 | (-)0.152149 |\n",
        "| tfidf | (+)0.025302 | (-)0.719015 | nan         | (-)0.003755 | (-)0.279346 | (-)0.037860 |\n",
        "| bm11  | (+)0.000172 | (+)0.063093 | (+)0.003755 | nan         | (+)0.146553 | (+)0.603104 |\n",
        "| bm15  | (+)0.006351 | (+)0.576542 | (+)0.279346 | (-)0.146553 | nan         | (-)0.039888 |\n",
        "| bm25  | (+)0.000448 | (+)0.152149 | (+)0.037860 | (-)0.603104 | (+)0.039888 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-WUGtqfcL-0"
      },
      "source": [
        "#### MRR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6JxugPH8Rvw"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)0.037434 | (-)0.006425 | (-)0.000985 | (-)0.010726 | (-)0.002332 |\n",
        "| idf   | (+)0.037434 | nan         | (+)0.815053 | (-)0.567260 | (-)0.552977 | (-)0.265345 |\n",
        "| tfidf | (+)0.006425 | (-)0.815053 | nan         | (-)0.232571 | (-)0.451618 | (-)0.224335 |\n",
        "| bm11  | (+)0.000985 | (+)0.567260 | (+)0.232571 | nan         | (+)0.951553 | (-)0.572126 |\n",
        "| bm15  | (+)0.010726 | (+)0.552977 | (+)0.451618 | (-)0.951553 | nan         | (-)0.488398 |\n",
        "| bm25  | (+)0.002332 | (+)0.265345 | (+)0.224335 | (+)0.572126 | (+)0.488398 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p22bbPFZyPxj"
      },
      "source": [
        "#### Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgFf3g2vySI5"
      },
      "source": [
        "When conducting multiple statistical tests simultaneously, it's essential to apply a correction method to account for the increased risk of false positives that is, incorrectly identifying a result as significant purely by chance. This phenomenon is known as the multiple comparisons problem. To mitigate it, several correction techniques are available, each with different levels of stringency.\n",
        "\n",
        "Among the most commonly used methods are Bonferroni, Holm, and Benjamini-Hochberg (BH) corrections. The Bonferroni correction is the most conservative of the three. It strictly controls the family-wise error rate by dividing the significance threshold (e.g., 0.05) by the number of tests. While this approach effectively minimizes false positives, it can be overly stringent, especially when dealing with a large number of comparisons, potentially leading to a high rate of false negatives (missed true effects).\n",
        "\n",
        "The Holm correction offers a more balanced alternative. It also controls the family-wise error rate but does so using a step-down procedure that is generally less conservative than Bonferroni. This makes it a good middle ground for researchers who want to maintain rigorous standards without being excessively restrictive.\n",
        "\n",
        "On the other end of the spectrum is the Benjamini-Hochberg (BH) procedure, which controls the false discovery rate the expected proportion of false positives among the rejected hypotheses. This method is less conservative and more powerful, making it particularly well-suited for exploratory analyses or studies involving a large number of tests, such as genomics, psychology, or machine learning model comparisons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftyf5phI5NCQ"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.multitest import multipletests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "\n",
        "# TODO Già definitaaaaa\n",
        "\n",
        "def p_values_correction(\n",
        "    metric_idx: int,\n",
        "    method: str\n",
        "):\n",
        "    \"\"\"\n",
        "    Performs pairwise t-tests between scoring methods for a given metric,\n",
        "    applies multiple testing correction, and returns a DataFrame of signed corrected p-values.\n",
        "\n",
        "    Parameters:\n",
        "        metric_idx (int): Index of the metric to evaluate.\n",
        "        method (str): Correction method to use ('bonferroni', 'holm', 'fdr_bh', etc.).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Matrix of corrected p-values with direction indicators.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize p-value matrix\n",
        "    p_values = pd.DataFrame(index=methods, columns=methods, dtype=object)\n",
        "\n",
        "    # Collect raw p-values from pairwise comparisons\n",
        "    raw_pvals = []\n",
        "    comparisons = []\n",
        "\n",
        "    # Make pair-wise tests\n",
        "    for row_method in methods:\n",
        "        for col_method in methods:\n",
        "\n",
        "            # Skipping diagonal because it's the same method\n",
        "            if row_method == col_method:\n",
        "                p_values.loc[row_method, col_method] = np.nan\n",
        "                continue\n",
        "\n",
        "            # Get per-query scores for both methods\n",
        "            scores_a = scores[metric_idx][methods.index(row_method)]\n",
        "            scores_b = scores[metric_idx][methods.index(col_method)]\n",
        "\n",
        "            # Run paired t-test\n",
        "            t_stat, p_val = ttest_rel(scores_a, scores_b)\n",
        "            raw_pvals.append(p_val)\n",
        "            comparisons.append((row_method, col_method, t_stat >= 0))  # Store direction\n",
        "\n",
        "    # Apply multiple testing correction\n",
        "    reject, corrected_pvals, _, _ = multipletests(raw_pvals, method=method)\n",
        "\n",
        "    # Fill in the corrected p-values with direction indicators\n",
        "    for i, (row_method, col_method, is_greater) in enumerate(comparisons):\n",
        "        sign = '+' if is_greater else '-'\n",
        "        p_values.loc[row_method, col_method] = f\"({sign}){corrected_pvals[i]:.6f}\"\n",
        "\n",
        "    return p_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smwvYxxjsaYh"
      },
      "source": [
        "### Bonferroni Correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "vZpWG-pk2Y-L",
        "outputId": "ae9da785-84c0-4443-882d-1441a2f4c9ec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (+)0.662326 | (-)0.019180 | (-)0.000018 | (-)0.000035 | (-)0.000008 |\\n| idf   | (-)0.662326 | nan         | (-)0.000614 | (-)0.000005 | (-)0.000008 | (-)0.000003 |\\n| tfidf | (+)0.019180 | (+)0.000614 | nan         | (-)0.000002 | (-)0.000360 | (-)0.000028 |\\n| bm11  | (+)0.000018 | (+)0.000005 | (+)0.000002 | nan         | (-)1.000000 | (-)0.426132 |\\n| bm15  | (+)0.000035 | (+)0.000008 | (+)0.000360 | (+)1.000000 | nan         | (-)0.004671 |\\n| bm25  | (+)0.000008 | (+)0.000003 | (+)0.000028 | (+)0.426132 | (+)0.004671 | nan         |'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MAP = p_values_correction(0, \"bonferroni\")\n",
        "p_values_MAP.to_markdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "hJ2pNdwU21zQ",
        "outputId": "ab5b4c40-ac3c-44b5-ad52-f4d530c686c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (-)0.799677 | (-)0.759054 | (-)0.005171 | (-)0.190535 | (-)0.013443 |\\n| idf   | (+)0.799677 | nan         | (+)1.000000 | (-)1.000000 | (-)1.000000 | (-)1.000000 |\\n| tfidf | (+)0.759054 | (-)1.000000 | nan         | (-)0.112659 | (-)1.000000 | (-)1.000000 |\\n| bm11  | (+)0.005171 | (+)1.000000 | (+)0.112659 | nan         | (+)1.000000 | (+)1.000000 |\\n| bm15  | (+)0.190535 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)1.000000 |\\n| bm25  | (+)0.013443 | (+)1.000000 | (+)1.000000 | (-)1.000000 | (+)1.000000 | nan         |'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_nDCG = p_values_correction(1, \"bonferroni\")\n",
        "p_values_nDCG.to_markdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "M9OleeyI24vW",
        "outputId": "845297f5-7998-487d-be53-ae21522a4c15"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (-)1.000000 | (-)0.192760 | (-)0.029555 | (-)0.321778 | (-)0.069963 |\\n| idf   | (+)1.000000 | nan         | (+)1.000000 | (-)1.000000 | (-)1.000000 | (-)1.000000 |\\n| tfidf | (+)0.192760 | (-)1.000000 | nan         | (-)1.000000 | (-)1.000000 | (-)1.000000 |\\n| bm11  | (+)0.029555 | (+)1.000000 | (+)1.000000 | nan         | (+)1.000000 | (-)1.000000 |\\n| bm15  | (+)0.321778 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)1.000000 |\\n| bm25  | (+)0.069963 | (+)1.000000 | (+)1.000000 | (+)1.000000 | (+)1.000000 | nan         |'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MRR = p_values_correction(2, \"bonferroni\")\n",
        "p_values_MRR.to_markdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr8m3W2K3JRW"
      },
      "source": [
        "#### MAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d73Z-BlB8hOs"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (+)0.662326 | (-)0.019180 | (-)0.000018 | (-)0.000035 | (-)0.000008 |\n",
        "| idf   | (-)0.662326 | nan         | (-)0.000614 | (-)0.000005 | (-)0.000008 | (-)0.000003 |\n",
        "| tfidf | (+)0.019180 | (+)0.000614 | nan         | (-)0.000002 | (-)0.000360 | (-)0.000028 |\n",
        "| bm11  | (+)0.000018 | (+)0.000005 | (+)0.000002 | nan         | (-)1.000000 | (-)0.426132 |\n",
        "| bm15  | (+)0.000035 | (+)0.000008 | (+)0.000360 | (+)1.000000 | nan         | (-)0.004671 |\n",
        "| bm25  | (+)0.000008 | (+)0.000003 | (+)0.000028 | (+)0.426132 | (+)0.004671 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJVMNzy-3XXI"
      },
      "source": [
        "#### nDCG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGYs4gfl8mf3"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)0.799677 | (-)0.759054 | (-)0.005171 | (-)0.190535 | (-)0.013443 |\n",
        "| idf   | (+)0.799677 | nan         | (+)1.000000 | (-)1.000000 | (-)1.000000 | (-)1.000000 |\n",
        "| tfidf | (+)0.759054 | (-)1.000000 | nan         | (-)0.112659 | (-)1.000000 | (-)1.000000 |\n",
        "| bm11  | (+)0.005171 | (+)1.000000 | (+)0.112659 | nan         | (+)1.000000 | (+)1.000000 |\n",
        "| bm15  | (+)0.190535 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)1.000000 |\n",
        "| bm25  | (+)0.013443 | (+)1.000000 | (+)1.000000 | (-)1.000000 | (+)1.000000 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9ZunGmU3ebq"
      },
      "source": [
        "#### MRR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmZnZ-bn8r38"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)1.000000 | (-)0.192760 | (-)0.029555 | (-)0.321778 | (-)0.069963 |\n",
        "| idf   | (+)1.000000 | nan         | (+)1.000000 | (-)1.000000 | (-)1.000000 | (-)1.000000 |\n",
        "| tfidf | (+)0.192760 | (-)1.000000 | nan         | (-)1.000000 | (-)1.000000 | (-)1.000000 |\n",
        "| bm11  | (+)0.029555 | (+)1.000000 | (+)1.000000 | nan         | (+)1.000000 | (-)1.000000 |\n",
        "| bm15  | (+)0.321778 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)1.000000 |\n",
        "| bm25  | (+)0.069963 | (+)1.000000 | (+)1.000000 | (+)1.000000 | (+)1.000000 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohoDLEzt3rhv"
      },
      "source": [
        "### Holm Correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "fjyrI1Qg3y1K",
        "outputId": "dcf4b0b3-edca-4e4a-e719-163b125c3569"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (+)0.088310 | (-)0.005115 | (-)0.000012 | (-)0.000019 | (-)0.000006 |\\n| idf   | (-)0.088310 | nan         | (-)0.000246 | (-)0.000004 | (-)0.000006 | (-)0.000003 |\\n| tfidf | (+)0.005115 | (+)0.000246 | nan         | (-)0.000002 | (-)0.000168 | (-)0.000017 |\\n| bm11  | (+)0.000012 | (+)0.000004 | (+)0.000002 | nan         | (-)1.000000 | (-)0.085226 |\\n| bm15  | (+)0.000019 | (+)0.000006 | (+)0.000168 | (+)1.000000 | nan         | (-)0.001557 |\\n| bm25  | (+)0.000006 | (+)0.000003 | (+)0.000017 | (+)0.085226 | (+)0.001557 | nan         |'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MAP = p_values_correction(0, \"holm\")\n",
        "p_values_MAP.to_markdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "iAucixn13y1R",
        "outputId": "9b12dd1b-8d98-4535-eb31-40ea56d83fa5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (-)0.556639 | (-)0.556639 | (-)0.005171 | (-)0.152428 | (-)0.012547 |\\n| idf   | (+)0.556639 | nan         | (+)1.000000 | (-)0.883304 | (-)1.000000 | (-)1.000000 |\\n| tfidf | (+)0.556639 | (-)1.000000 | nan         | (-)0.097638 | (-)1.000000 | (-)0.681482 |\\n| bm11  | (+)0.005171 | (+)0.883304 | (+)0.097638 | nan         | (+)1.000000 | (+)1.000000 |\\n| bm15  | (+)0.152428 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)0.681482 |\\n| bm25  | (+)0.012547 | (+)1.000000 | (+)0.681482 | (-)1.000000 | (+)0.681482 | nan         |'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_nDCG = p_values_correction(1, \"holm\")\n",
        "p_values_nDCG.to_markdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "sZwUXV6l3y1T",
        "outputId": "5958d767-07b1-446a-a838-a4f9a8bb797a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (-)0.823548 | (-)0.167059 | (-)0.029555 | (-)0.257422 | (-)0.065298 |\\n| idf   | (+)0.823548 | nan         | (+)1.000000 | (-)1.000000 | (-)1.000000 | (-)1.000000 |\\n| tfidf | (+)0.167059 | (-)1.000000 | nan         | (-)1.000000 | (-)1.000000 | (-)1.000000 |\\n| bm11  | (+)0.029555 | (+)1.000000 | (+)1.000000 | nan         | (+)1.000000 | (-)1.000000 |\\n| bm15  | (+)0.257422 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)1.000000 |\\n| bm25  | (+)0.065298 | (+)1.000000 | (+)1.000000 | (+)1.000000 | (+)1.000000 | nan         |'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MRR = p_values_correction(2, \"holm\")\n",
        "p_values_MRR.to_markdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05sgWB7C3-Pq"
      },
      "source": [
        "#### MAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpvGRxCs9047"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (+)0.088310 | (-)0.005115 | (-)0.000012 | (-)0.000019 | (-)0.000006 |\n",
        "| idf   | (-)0.088310 | nan         | (-)0.000246 | (-)0.000004 | (-)0.000006 | (-)0.000003 |\n",
        "| tfidf | (+)0.005115 | (+)0.000246 | nan         | (-)0.000002 | (-)0.000168 | (-)0.000017 |\n",
        "| bm11  | (+)0.000012 | (+)0.000004 | (+)0.000002 | nan         | (-)1.000000 | (-)0.085226 |\n",
        "| bm15  | (+)0.000019 | (+)0.000006 | (+)0.000168 | (+)1.000000 | nan         | (-)0.001557 |\n",
        "| bm25  | (+)0.000006 | (+)0.000003 | (+)0.000017 | (+)0.085226 | (+)0.001557 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iis_1uOB4C7x"
      },
      "source": [
        "#### nDCG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B4EB2Yk93U5"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)0.556639 | (-)0.556639 | (-)0.005171 | (-)0.152428 | (-)0.012547 |\n",
        "| idf   | (+)0.556639 | nan         | (+)1.000000 | (-)0.883304 | (-)1.000000 | (-)1.000000 |\n",
        "| tfidf | (+)0.556639 | (-)1.000000 | nan         | (-)0.097638 | (-)1.000000 | (-)0.681482 |\n",
        "| bm11  | (+)0.005171 | (+)0.883304 | (+)0.097638 | nan         | (+)1.000000 | (+)1.000000 |\n",
        "| bm15  | (+)0.152428 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)0.681482 |\n",
        "| bm25  | (+)0.012547 | (+)1.000000 | (+)0.681482 | (-)1.000000 | (+)0.681482 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlbYFri84IcD"
      },
      "source": [
        "#### MRR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0KwaRbp95zH"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)0.823548 | (-)0.167059 | (-)0.029555 | (-)0.257422 | (-)0.065298 |\n",
        "| idf   | (+)0.823548 | nan         | (+)1.000000 | (-)1.000000 | (-)1.000000 | (-)1.000000 |\n",
        "| tfidf | (+)0.167059 | (-)1.000000 | nan         | (-)1.000000 | (-)1.000000 | (-)1.000000 |\n",
        "| bm11  | (+)0.029555 | (+)1.000000 | (+)1.000000 | nan         | (+)1.000000 | (-)1.000000 |\n",
        "| bm15  | (+)0.257422 | (+)1.000000 | (+)1.000000 | (-)1.000000 | nan         | (-)1.000000 |\n",
        "| bm25  | (+)0.065298 | (+)1.000000 | (+)1.000000 | (+)1.000000 | (+)1.000000 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF_RnZSZ4NmA"
      },
      "source": [
        "### Benjamini-Hochberg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "V6UkO2Rv4X4y",
        "outputId": "476dcb63-4705-4f44-8906-4ef4ddad51b4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (+)0.023654 | (-)0.000799 | (-)0.000001 | (-)0.000002 | (-)0.000001 |\\n| idf   | (-)0.023654 | nan         | (-)0.000031 | (-)0.000001 | (-)0.000001 | (-)0.000001 |\\n| tfidf | (+)0.000799 | (+)0.000031 | nan         | (-)0.000001 | (-)0.000020 | (-)0.000002 |\\n| bm11  | (+)0.000001 | (+)0.000001 | (+)0.000001 | nan         | (-)0.604252 | (-)0.016390 |\\n| bm15  | (+)0.000002 | (+)0.000001 | (+)0.000020 | (+)0.604252 | nan         | (-)0.000212 |\\n| bm25  | (+)0.000001 | (+)0.000001 | (+)0.000002 | (+)0.016390 | (+)0.000212 | nan         |'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MAP = p_values_correction(0, \"fdr_bh\")\n",
        "p_values_MAP.to_markdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "buIk15J14X41",
        "outputId": "ea94661d-c337-4a43-8f46-c9f925e058ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (-)0.066640 | (-)0.066640 | (-)0.002585 | (-)0.023817 | (-)0.003361 |\\n| idf   | (+)0.066640 | nan         | (+)0.719015 | (-)0.105155 | (-)0.646183 | (-)0.207476 |\\n| tfidf | (+)0.066640 | (-)0.719015 | nan         | (-)0.018777 | (-)0.349183 | (-)0.074790 |\\n| bm11  | (+)0.002585 | (+)0.105155 | (+)0.018777 | nan         | (+)0.207476 | (+)0.646183 |\\n| bm15  | (+)0.023817 | (+)0.646183 | (+)0.349183 | (-)0.207476 | nan         | (-)0.074790 |\\n| bm25  | (+)0.003361 | (+)0.207476 | (+)0.074790 | (-)0.646183 | (+)0.074790 | nan         |'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_nDCG = p_values_correction(1, \"fdr_bh\")\n",
        "p_values_nDCG.to_markdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "EDp2NqbT4X42",
        "outputId": "12ea5397-a37c-4d14-821a-a6d87669927d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\\n|:------|:------------|:------------|:------------|:------------|:------------|:------------|\\n| tf    | nan         | (-)0.112302 | (-)0.032127 | (-)0.014777 | (-)0.040222 | (-)0.017491 |\\n| idf   | (+)0.112302 | nan         | (+)0.873271 | (-)0.660146 | (-)0.660146 | (-)0.497523 |\\n| tfidf | (+)0.032127 | (-)0.873271 | nan         | (-)0.497523 | (-)0.660146 | (-)0.497523 |\\n| bm11  | (+)0.014777 | (+)0.660146 | (+)0.497523 | nan         | (+)0.951553 | (-)0.660146 |\\n| bm15  | (+)0.040222 | (+)0.660146 | (+)0.660146 | (-)0.951553 | nan         | (-)0.660146 |\\n| bm25  | (+)0.017491 | (+)0.497523 | (+)0.497523 | (+)0.660146 | (+)0.660146 | nan         |'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_values_MRR = p_values_correction(2, \"fdr_bh\")\n",
        "p_values_MRR.to_markdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx4Js_Q_4loe"
      },
      "source": [
        "#### MAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMidXWbE-Gvh"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (+)0.023654 | (-)0.000799 | (-)0.000001 | (-)0.000002 | (-)0.000001 |\n",
        "| idf   | (-)0.023654 | nan         | (-)0.000031 | (-)0.000001 | (-)0.000001 | (-)0.000001 |\n",
        "| tfidf | (+)0.000799 | (+)0.000031 | nan         | (-)0.000001 | (-)0.000020 | (-)0.000002 |\n",
        "| bm11  | (+)0.000001 | (+)0.000001 | (+)0.000001 | nan         | (-)0.604252 | (-)0.016390 |\n",
        "| bm15  | (+)0.000002 | (+)0.000001 | (+)0.000020 | (+)0.604252 | nan         | (-)0.000212 |\n",
        "| bm25  | (+)0.000001 | (+)0.000001 | (+)0.000002 | (+)0.016390 | (+)0.000212 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCxYX7Cl4pxp"
      },
      "source": [
        "#### nDCG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSRHhWG-I0k"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)0.066640 | (-)0.066640 | (-)0.002585 | (-)0.023817 | (-)0.003361 |\n",
        "| idf   | (+)0.066640 | nan         | (+)0.719015 | (-)0.105155 | (-)0.646183 | (-)0.207476 |\n",
        "| tfidf | (+)0.066640 | (-)0.719015 | nan         | (-)0.018777 | (-)0.349183 | (-)0.074790 |\n",
        "| bm11  | (+)0.002585 | (+)0.105155 | (+)0.018777 | nan         | (+)0.207476 | (+)0.646183 |\n",
        "| bm15  | (+)0.023817 | (+)0.646183 | (+)0.349183 | (-)0.207476 | nan         | (-)0.074790 |\n",
        "| bm25  | (+)0.003361 | (+)0.207476 | (+)0.074790 | (-)0.646183 | (+)0.074790 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ9h7tok4vmV"
      },
      "source": [
        "#### MRR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0SwD8rg-LE8"
      },
      "source": [
        "|       | tf          | idf         | tfidf       | bm11        | bm15        | bm25        |\n",
        "|:------|:------------|:------------|:------------|:------------|:------------|:------------|\n",
        "| tf    | nan         | (-)0.112302 | (-)0.032127 | (-)0.014777 | (-)0.040222 | (-)0.017491 |\n",
        "| idf   | (+)0.112302 | nan         | (+)0.873271 | (-)0.660146 | (-)0.660146 | (-)0.497523 |\n",
        "| tfidf | (+)0.032127 | (-)0.873271 | nan         | (-)0.497523 | (-)0.660146 | (-)0.497523 |\n",
        "| bm11  | (+)0.014777 | (+)0.660146 | (+)0.497523 | nan         | (+)0.951553 | (-)0.660146 |\n",
        "| bm15  | (+)0.040222 | (+)0.660146 | (+)0.660146 | (-)0.951553 | nan         | (-)0.660146 |\n",
        "| bm25  | (+)0.017491 | (+)0.497523 | (+)0.497523 | (+)0.660146 | (+)0.660146 | nan         |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R_Ryg7PjXUT"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyzDUlmni6eL"
      },
      "source": [
        "It is clear from the results that BM25 consistently outperforms the other scoring models, reaffirming its status as one of the most effective and robust retrieval functions. However, the Mean Reciprocal Rank (MRR) metric does not fully reflect this superiority a somewhat expected outcome, since MRR is a rank-sensitive measure that emphasizes the position of the first relevant document rather than overall retrieval quality. This makes MRR less aligned with models like BM25 that optimize for broader ranking effectiveness across multiple relevant documents, rather than focusing solely on the top-ranked one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXEK6nYbXcrp"
      },
      "source": [
        "### Test Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D2gtn99ZR6l"
      },
      "source": [
        "We import the test queries and generate a run file using our BM25 tuned model.\n",
        "\n",
        "\n",
        "This code prepares and executes an information retrieval experiment on the MS MARCO 2020 test set using a tuned BM25 model. It begins by specifying the path to the query file and extracting the queries as (query_id, query_text) pairs.\n",
        "\n",
        "A BM25 scorer is then instantiated with custom hyperparameters (k1=1, b=0.65) to control term frequency saturation and document length normalization. The inverted index is initialized with the dataset's lexicon, posting lists, term frequencies, document statistics, and global collection statistics, while associating it with the chosen scoring function.\n",
        "\n",
        "Finally, the script generates a TREC-formatted run file, which records the retrieval results for all queries under the identifier \"bm25_test_run\". This run file can later be used for evaluation against relevance judgments to measure the effectiveness of the tuned BM25 implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjZqCWqyXsW_"
      },
      "outputs": [],
      "source": [
        "# Path to MS MARCO test set query file (2020)\n",
        "queries_file = \"msmarco-test2020-queries.tsv\"\n",
        "\n",
        "# BM25 Scorer function with tuned hyperparameters\n",
        "scorer = BM25Scorer(k1=1, b=0.65)\n",
        "\n",
        "# Name of the test run of BM25\n",
        "run_name = \"bm25_test_run\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pUg39UYyXsXF",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "42201e27-d60b-4e09-dcc4-583595cde833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "daat (5.908 ms)\n",
            "daat (99.231 ms)\n",
            "daat (1687.472 ms)\n",
            "daat (600.627 ms)\n",
            "daat (31482.802 ms)\n",
            "daat (1869.177 ms)\n",
            "daat (7115.235 ms)\n",
            "daat (677.498 ms)\n",
            "daat (7921.152 ms)\n",
            "daat (1630.932 ms)\n",
            "daat (269.542 ms)\n",
            "daat (2813.742 ms)\n",
            "daat (12593.451 ms)\n",
            "daat (1399.809 ms)\n",
            "daat (4613.180 ms)\n",
            "daat (7813.129 ms)\n",
            "daat (2946.128 ms)\n",
            "daat (15919.087 ms)\n",
            "daat (18695.359 ms)\n",
            "daat (2413.388 ms)\n",
            "daat (2314.335 ms)\n",
            "daat (14942.277 ms)\n",
            "daat (21152.215 ms)\n",
            "daat (5793.670 ms)\n",
            "daat (1059.728 ms)\n",
            "daat (3074.444 ms)\n",
            "daat (2205.235 ms)\n",
            "daat (124.034 ms)\n",
            "daat (2854.110 ms)\n",
            "daat (8239.803 ms)\n",
            "daat (1447.088 ms)\n",
            "daat (14727.180 ms)\n",
            "daat (3270.055 ms)\n",
            "daat (4103.326 ms)\n",
            "daat (128.123 ms)\n",
            "daat (2307.709 ms)\n",
            "daat (9108.725 ms)\n",
            "daat (9299.859 ms)\n",
            "daat (6150.089 ms)\n",
            "daat (7239.929 ms)\n",
            "daat (5182.303 ms)\n",
            "daat (5805.129 ms)\n",
            "daat (5305.539 ms)\n",
            "daat (4654.574 ms)\n",
            "daat (14663.310 ms)\n",
            "daat (3674.541 ms)\n",
            "daat (3049.235 ms)\n",
            "daat (17106.726 ms)\n",
            "daat (8503.889 ms)\n",
            "daat (4615.597 ms)\n",
            "daat (12761.919 ms)\n",
            "daat (2809.077 ms)\n",
            "daat (3560.375 ms)\n",
            "daat (9975.400 ms)\n",
            "daat (2639.735 ms)\n",
            "daat (6730.763 ms)\n",
            "daat (5009.095 ms)\n",
            "daat (1040.207 ms)\n",
            "daat (1753.845 ms)\n",
            "daat (5444.146 ms)\n",
            "daat (13045.765 ms)\n",
            "daat (32174.462 ms)\n",
            "daat (9420.441 ms)\n",
            "daat (14144.523 ms)\n",
            "daat (7642.604 ms)\n",
            "daat (11854.276 ms)\n",
            "daat (6153.847 ms)\n",
            "daat (6770.545 ms)\n",
            "daat (9709.899 ms)\n",
            "daat (7919.632 ms)\n",
            "daat (7134.265 ms)\n",
            "daat (1859.460 ms)\n",
            "daat (3073.468 ms)\n",
            "daat (2802.870 ms)\n",
            "daat (6894.228 ms)\n",
            "daat (2650.010 ms)\n",
            "daat (19849.046 ms)\n",
            "daat (4892.435 ms)\n",
            "daat (4235.704 ms)\n",
            "daat (2818.949 ms)\n",
            "daat (3173.335 ms)\n",
            "daat (7733.354 ms)\n",
            "daat (15302.675 ms)\n",
            "daat (92.703 ms)\n",
            "daat (12863.408 ms)\n",
            "daat (4464.910 ms)\n",
            "daat (1384.793 ms)\n",
            "daat (1711.535 ms)\n",
            "daat (4316.298 ms)\n",
            "daat (2697.741 ms)\n",
            "daat (19888.145 ms)\n",
            "daat (5068.899 ms)\n",
            "daat (2358.048 ms)\n",
            "daat (4490.046 ms)\n",
            "daat (3014.308 ms)\n",
            "daat (16748.519 ms)\n",
            "daat (3519.357 ms)\n",
            "daat (8022.496 ms)\n",
            "daat (6747.486 ms)\n",
            "daat (4496.839 ms)\n",
            "daat (8029.405 ms)\n",
            "daat (5989.821 ms)\n",
            "daat (13055.372 ms)\n",
            "daat (6709.893 ms)\n",
            "daat (16383.547 ms)\n",
            "daat (8333.075 ms)\n",
            "daat (16155.981 ms)\n",
            "daat (28947.653 ms)\n",
            "daat (21508.477 ms)\n",
            "daat (15001.166 ms)\n",
            "daat (3593.747 ms)\n",
            "daat (12033.552 ms)\n",
            "daat (8042.732 ms)\n",
            "daat (29937.433 ms)\n",
            "daat (16910.550 ms)\n",
            "daat (7608.581 ms)\n",
            "daat (18142.514 ms)\n",
            "daat (6540.540 ms)\n",
            "daat (3184.688 ms)\n",
            "daat (6444.408 ms)\n",
            "daat (30817.474 ms)\n",
            "daat (9199.125 ms)\n",
            "daat (5585.614 ms)\n",
            "daat (204.345 ms)\n",
            "daat (8454.146 ms)\n",
            "daat (92.906 ms)\n",
            "daat (1516.830 ms)\n",
            "daat (6553.479 ms)\n",
            "daat (5291.275 ms)\n",
            "daat (5847.390 ms)\n",
            "daat (3329.188 ms)\n",
            "daat (12494.545 ms)\n",
            "daat (9088.043 ms)\n",
            "daat (1918.468 ms)\n",
            "daat (5049.447 ms)\n",
            "daat (11524.802 ms)\n",
            "daat (4896.935 ms)\n",
            "daat (6222.751 ms)\n",
            "daat (2765.719 ms)\n",
            "daat (5082.953 ms)\n",
            "daat (3318.467 ms)\n",
            "daat (926.654 ms)\n",
            "daat (345.070 ms)\n",
            "daat (2639.626 ms)\n",
            "daat (1996.975 ms)\n",
            "daat (1379.295 ms)\n",
            "daat (12080.504 ms)\n",
            "daat (20941.551 ms)\n",
            "daat (7452.122 ms)\n",
            "daat (8254.136 ms)\n",
            "daat (2556.636 ms)\n",
            "daat (11891.082 ms)\n",
            "daat (2677.618 ms)\n",
            "daat (8425.853 ms)\n",
            "daat (519.384 ms)\n",
            "daat (8097.125 ms)\n",
            "daat (1458.614 ms)\n",
            "daat (1329.905 ms)\n",
            "daat (11618.454 ms)\n",
            "daat (3027.877 ms)\n",
            "daat (4.676 ms)\n",
            "daat (167.825 ms)\n",
            "daat (284.329 ms)\n",
            "daat (981.203 ms)\n",
            "daat (0.335 ms)\n",
            "daat (528.523 ms)\n",
            "daat (632.015 ms)\n",
            "daat (2487.234 ms)\n",
            "daat (395.214 ms)\n",
            "daat (0.551 ms)\n",
            "daat (2010.942 ms)\n",
            "daat (0.347 ms)\n",
            "daat (3449.830 ms)\n",
            "daat (2394.489 ms)\n",
            "daat (27257.041 ms)\n",
            "daat (2202.282 ms)\n",
            "daat (7111.029 ms)\n",
            "daat (5464.799 ms)\n",
            "daat (7354.628 ms)\n",
            "daat (2184.169 ms)\n",
            "daat (2369.983 ms)\n",
            "daat (9044.119 ms)\n",
            "daat (2385.860 ms)\n",
            "daat (11267.463 ms)\n",
            "daat (6407.862 ms)\n",
            "daat (9393.229 ms)\n",
            "daat (4889.562 ms)\n",
            "daat (11357.796 ms)\n",
            "daat (7160.185 ms)\n",
            "daat (5750.266 ms)\n",
            "daat (1860.410 ms)\n",
            "daat (6402.565 ms)\n",
            "daat (6163.620 ms)\n",
            "daat (3077.144 ms)\n",
            "daat (2052.259 ms)\n",
            "daat (0.874 ms)\n",
            "daat (3405.159 ms)\n",
            "daat (5734.916 ms)\n",
            "daat (0.299 ms)\n",
            "daat (3415.482 ms)\n",
            "Run file saved to: bm25_test_run\n"
          ]
        }
      ],
      "source": [
        "# Extract queries from the current file\n",
        "# queries: List of tuples (query_id, query_text)\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "# Initialize the inverted index with the current scoring function\n",
        "# This allows different retrieval models (e.g., TF, TF-IDF, BM25)\n",
        "inv_ind = InvertedIndex(\n",
        "    lexicon,       # term -> (termid, ...) mapping\n",
        "    inv_d,         # list of numpy arrays: doc IDs per term\n",
        "    inv_f,         # list of numpy arrays: term frequencies per term\n",
        "    doc_index,     # document statistics\n",
        "    stats,         # global statistics (e.g., total # of documents)\n",
        "    scorer=scorer  # scoring function to use for this run\n",
        ")\n",
        "\n",
        "# Generate and write a TREC-formatted run file for the current query set\n",
        "# The filename combines the run name and the run suffix\n",
        "write_run_file(\n",
        "    queries,              # queries to process\n",
        "    inv_ind,              # inverted index with current scoring function\n",
        "    run_name,             # output filename for this run\n",
        "    run_name              # run identifier (appears in run file)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDY0KIoPZirn"
      },
      "source": [
        "We define the evaluation metrics of interest, load the relevance judgments (qrels), and compute the results using the TREC evaluation framework.\n",
        "\n",
        "This code evaluates the performance of a BM25 retrieval run on the MS MARCO 2020 test set using several standard information retrieval metrics. It begins by defining the metrics of interest: Average Precision (AP), normalized Discounted Cumulative Gain at rank 10 (nDCG@10), and Mean Reciprocal Rank at rank 10 (MRR@10).\n",
        "\n",
        "The ground-truth relevance judgments (qrels) are loaded from the file 2020qrels-pass.txt, while the BM25 run results are read from the corresponding run file. For each metric, the script computes per-query scores using the ir_measures library, ensuring that the results are stored by appending to a table structure. Finally, the per-query scores are printed, providing a detailed view of how the BM25 model performs across different evaluation measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4LbfUTqYYBD"
      },
      "outputs": [],
      "source": [
        "# List of retrieval/scoring methods\n",
        "method = \"bm25\"\n",
        "\n",
        "# Metrics to evaluate\n",
        "metrics = [\n",
        "    (\"AP\", AP),\n",
        "    (\"nDCG@10\", nDCG@10),\n",
        "    (\"MRR@10\", MRR@10)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKuKS8rlYYBM"
      },
      "outputs": [],
      "source": [
        "# qrels_file contains the ground-truth relevance labels for queries\n",
        "qrels_file = '2020qrels-pass.txt'\n",
        "\n",
        "# Read the qrels file using ir_measures utility\n",
        "# Each entry represents a (query_id, doc_id, relevance) tuple\n",
        "qrel = list(ir_measures.read_trec_qrels(qrels_file))\n",
        "\n",
        "# The run file for this method\n",
        "run_file = method + \"_test_run\"\n",
        "\n",
        "# Read the run file using ir_measures utility\n",
        "# Each entry represents a (query_id, doc_id, score) tuple\n",
        "run_data = list(ir_measures.read_trec_run(run_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4elGaNunYYBO",
        "outputId": "bf576f83-3396-4ff6-85b4-4300c4332d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'AP': 0.3680402948054137, 'nDCG@10': 0.5123122754755617, 'MRR@10': 0.8271604938271605}\n"
          ]
        }
      ],
      "source": [
        "# This will store score per-metric, averaged among all queries\n",
        "scores = {}\n",
        "\n",
        "for metric_name, metric_func in metrics:\n",
        "\n",
        "    # Compute the metric for each query in the run\n",
        "    per_query_scores = tuple(\n",
        "        m.value for m in ir_measures.iter_calc([metric_func], qrel, run_data)\n",
        "    )\n",
        "\n",
        "    # Compute the average metric for each query\n",
        "    metric_score = sum(per_query_scores) / len(per_query_scores)\n",
        "\n",
        "    # Add the score to a dictionary\n",
        "    scores[metric_name] = metric_score\n",
        "\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3o8j-0mBjUh"
      },
      "source": [
        "| Metric   | Score   |\n",
        "|----------|---------|\n",
        "| AP       | 0.3680  |\n",
        "| nDCG@10  | 0.5123  |\n",
        "| MRR@10   | 0.8272  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxTP9fNtj70o"
      },
      "source": [
        "## PyTerrier Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0U_wk4NmDdG"
      },
      "source": [
        "### Creating PyTerrier Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L33ODZvjEC1K"
      },
      "source": [
        "This code demonstrates a complete workflow for indexing and retrieving documents using PyTerrier with the BM25 model. It begins by initializing PyTerrier and loading a tab-separated file (collection.tar) into a Pandas DataFrame, where each row contains a document identifier (docno) and its text. Since PyTerrier requires string inputs, the DataFrame is converted to string format before indexing. The DFIndexer is then used to build an index in the folder index_3docs, and the resulting index reference is loaded with IndexFactory. Collection statistics such as the number of documents and average length are printed to provide insight into the indexed dataset. Retrieval is performed using the BM25 weighting model, with the query \"document\", and the top-ranked result's document ID, rank, and score are displayed. Finally, the code iterates through all retrieved results, printing each document's identifier, rank, and BM25 score, thereby illustrating how to inspect and analyze search outputs in a structured way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317,
          "referenced_widgets": [
            "8d8e9e2cde9e48b4ae65a3f6ca0f3971",
            "7b4adbdab2b44d8f93dbf85a410399f9",
            "202e636dbc8f43778af5fd48690606b4",
            "5319ca1f5b284bbca8dc32d266f48fb4",
            "669c29f40d3e42afb53e43f839674ea2",
            "7b92dca187d04ae3b94456aff3e1b874",
            "bbf0b39c2a874b6cb0709da3ea7f9734",
            "5b657b95156345a784a9eb893a21ae88",
            "00b857d19c3a4ba397c03c527dbb068b",
            "4143252a40b64f10ac9913e9f5f4f2bb",
            "c16926e22a4e4effa62f541cd391d65c",
            "bb6f5131320946bf8df4f08680926d67",
            "4795452a1560470b8ac87bda0672d5cc",
            "61301684073d499fa8f103c57d91fe7a",
            "7d4e211a31994e3cac7e0e780de0e420",
            "54f75f0613f0476d8d37924dd68b9291",
            "38052302c7454396a178f8511ff59446",
            "2b0d0362c0a6469c8b97cfeeaf216e62",
            "b3dae090c20e4ccca0f2aa9ad071f8c0",
            "d9d6dae4300444a885d723d3378073eb",
            "2d9d29e9e85143a09d3bd513b9e0a1f4",
            "094df0987f104438803de6529bca321a"
          ]
        },
        "id": "yTwoHoEDcNOW",
        "outputId": "0257d82d-8402-488b-882b-3d732d2c12ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "terrier-assemblies 5.11 jar-with-dependencies not found, downloading to /root/.pyterrier...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d8e9e2cde9e48b4ae65a3f6ca0f3971",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "https://repo1.maven.org/maven2/org/terrier/terrier-assemblies/5.11/terrier-assemblies-5.11-jar-with-dependenci…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n",
            "terrier-python-helper 0.0.8 jar not found, downloading to /root/.pyterrier...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb6f5131320946bf8df4f08680926d67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "https://repo1.maven.org/maven2/org/terrier/terrier-python-helper/0.0.8/terrier-python-helper-0.0.8.jar:   0%| …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Java started and loaded: pyterrier.java.colab, pyterrier.java, pyterrier.java.24, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
            "/tmp/ipython-input-2775686768.py:3: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
            "java is now started automatically with default settings. To force initialisation early, run:\n",
            "pt.java.init() # optional, forces java initialisation\n",
            "  pt.init()\n"
          ]
        }
      ],
      "source": [
        "import pyterrier as pt\n",
        "\n",
        "# Initializing Pyterrier\n",
        "pt.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUJuyMPRfBCl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the file as a tab-separated file (TSV)\n",
        "df = pd.read_csv(\n",
        "    \"collection.tar\",  # TODO: che è collection.tar? quando è stata scaricata? aggiungere qualsiasi cosa sia, o cambiare nome\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"docno\", \"text\"],\n",
        "    skiprows=1\n",
        ")\n",
        "\n",
        "# PyTerrier wants strings and not integer\n",
        "df = df.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "v2Zi4SdrdOf1",
        "outputId": "23d2c060-af34-43e6-b89c-683f27574d46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3638899273.py:1: DeprecationWarning: Call to deprecated class DFIndexer. (use pt.terrier.IterDictIndexer().index(dataframe.to_dict(orient='records')) instead) -- Deprecated since version 0.11.0.\n",
            "  indexer = pt.DFIndexer(\"./index_3docs\", overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "08:05:05.068 [main] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (35723) - further warnings are suppressed\n",
            "09:36:09.927 [main] WARN org.terrier.structures.indexing.Indexer -- Indexed 265 empty documents\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./index_3docs/data.properties'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize a Terrier DFIndexer to build an index in the folder \"index_3docs\".\n",
        "# Setting overwrite=True ensures that any existing index in this folder is replaced.\n",
        "indexer = pt.DFIndexer(\"./index_3docs\", overwrite=True)\n",
        "\n",
        "# Index the documents using the DataFrame columns:\n",
        "# - \"text\": the document content\n",
        "# - \"docno\": the unique document identifier\n",
        "indexref = indexer.index(df[\"text\"], df[\"docno\"])\n",
        "\n",
        "# Print a string representation of the index reference (for debugging/inspection).\n",
        "indexref.toString()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1haDB3Plpxg",
        "outputId": "c71bc934-87e7-4c49-8508-9c2bf1c2b159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents: 8841822\n",
            "Number of terms: 1168845\n",
            "Number of postings: 215136819\n",
            "Number of fields: 0\n",
            "Number of tokens: 288586998\n",
            "Field names: []\n",
            "Positions:   false\n",
            "\n",
            "7020668\n",
            "0\n",
            "13.24502440525085\n",
            "docno: 7020668, rank: 0, score: 13.24502440525085\n",
            "docno: 7020666, rank: 1, score: 13.24245619740485\n",
            "docno: 5752808, rank: 2, score: 13.005899012907783\n",
            "docno: 5707062, rank: 3, score: 12.967163280052093\n",
            "docno: 5752809, rank: 4, score: 12.965962005008993\n",
            "docno: 1877654, rank: 5, score: 12.906734864605493\n",
            "docno: 7406563, rank: 6, score: 12.864100306050426\n",
            "docno: 1015990, rank: 7, score: 12.862031500056508\n",
            "docno: 7451610, rank: 8, score: 12.862031500056508\n",
            "docno: 5589815, rank: 9, score: 12.84735118132147\n",
            "docno: 5589809, rank: 10, score: 12.819280318777322\n",
            "docno: 7551108, rank: 11, score: 12.811201574359899\n",
            "docno: 2995443, rank: 12, score: 12.793665209666331\n",
            "docno: 3517429, rank: 13, score: 12.793665209666331\n",
            "docno: 4246251, rank: 14, score: 12.793665209666331\n",
            "docno: 2205195, rank: 15, score: 12.789978375281924\n",
            "docno: 8307115, rank: 16, score: 12.789978375281924\n",
            "docno: 2970523, rank: 17, score: 12.784148660224224\n",
            "docno: 2019395, rank: 18, score: 12.772959504423497\n",
            "docno: 8596666, rank: 19, score: 12.772959504423497\n",
            "docno: 895070, rank: 20, score: 12.746436159680572\n",
            "docno: 5806807, rank: 21, score: 12.746436159680572\n",
            "docno: 6983830, rank: 22, score: 12.734945063939932\n",
            "docno: 8242973, rank: 23, score: 12.734945063939932\n",
            "docno: 4700802, rank: 24, score: 12.726021859086275\n",
            "docno: 248836, rank: 25, score: 12.72253417833887\n",
            "docno: 2232063, rank: 26, score: 12.718892293571718\n",
            "docno: 4070019, rank: 27, score: 12.71124257552337\n",
            "docno: 5305619, rank: 28, score: 12.71124257552337\n",
            "docno: 7612933, rank: 29, score: 12.71124257552337\n",
            "docno: 8200823, rank: 30, score: 12.71124257552337\n",
            "docno: 2733838, rank: 31, score: 12.703189408527345\n",
            "docno: 7898445, rank: 32, score: 12.703189408527345\n",
            "docno: 6930142, rank: 33, score: 12.69715622655126\n",
            "docno: 7318335, rank: 34, score: 12.688719393016664\n",
            "docno: 2970524, rank: 35, score: 12.68565423270892\n",
            "docno: 8229561, rank: 36, score: 12.662296796226766\n",
            "docno: 5806803, rank: 37, score: 12.659590989879899\n",
            "docno: 6020799, rank: 38, score: 12.659590989879899\n",
            "docno: 5589811, rank: 39, score: 12.658361460150422\n",
            "docno: 505433, rank: 40, score: 12.628801037074016\n",
            "docno: 4124649, rank: 41, score: 12.628801037074016\n",
            "docno: 537456, rank: 42, score: 12.62588745845828\n",
            "docno: 8011293, rank: 43, score: 12.617570351044284\n",
            "docno: 8802580, rank: 44, score: 12.617570351044284\n",
            "docno: 8802581, rank: 45, score: 12.617570351044284\n",
            "docno: 3909565, rank: 46, score: 12.611339707812506\n",
            "docno: 4246248, rank: 47, score: 12.611339707812506\n",
            "docno: 8011295, rank: 48, score: 12.611339707812506\n",
            "docno: 785636, rank: 49, score: 12.602627137974318\n",
            "docno: 1293609, rank: 50, score: 12.602627137974318\n",
            "docno: 7610538, rank: 51, score: 12.602627137974318\n",
            "docno: 903443, rank: 52, score: 12.592858588924717\n",
            "docno: 7570511, rank: 53, score: 12.592858588924717\n",
            "docno: 1649130, rank: 54, score: 12.589580831463397\n",
            "docno: 4790494, rank: 55, score: 12.589580831463397\n",
            "docno: 8783572, rank: 56, score: 12.589580831463397\n",
            "docno: 6275577, rank: 57, score: 12.577183257800401\n",
            "docno: 6246408, rank: 58, score: 12.57519217078162\n",
            "docno: 2019394, rank: 59, score: 12.561974852080342\n",
            "docno: 5808523, rank: 60, score: 12.561974852080342\n",
            "docno: 301412, rank: 61, score: 12.543517215220108\n",
            "docno: 1812126, rank: 62, score: 12.543517215220108\n",
            "docno: 3501715, rank: 63, score: 12.543517215220108\n",
            "docno: 3909562, rank: 64, score: 12.543517215220108\n",
            "docno: 8565864, rank: 65, score: 12.543517215220108\n",
            "docno: 8799243, rank: 66, score: 12.543517215220108\n",
            "docno: 2258059, rank: 67, score: 12.534489674601723\n",
            "docno: 903440, rank: 68, score: 12.53309770575807\n",
            "docno: 1358938, rank: 69, score: 12.53309770575807\n",
            "docno: 2307666, rank: 70, score: 12.53309770575807\n",
            "docno: 3154809, rank: 71, score: 12.53309770575807\n",
            "docno: 989401, rank: 72, score: 12.512994949487114\n",
            "docno: 3909566, rank: 73, score: 12.512994949487114\n",
            "docno: 4738470, rank: 74, score: 12.512994949487114\n",
            "docno: 8001348, rank: 75, score: 12.512994949487114\n",
            "docno: 1160149, rank: 76, score: 12.511526822495929\n",
            "docno: 903450, rank: 77, score: 12.510646111652145\n",
            "docno: 2869357, rank: 78, score: 12.510646111652145\n",
            "docno: 5990381, rank: 79, score: 12.491284116335871\n",
            "docno: 7570861, rank: 80, score: 12.491284116335871\n",
            "docno: 3328409, rank: 81, score: 12.484959188773843\n",
            "docno: 3507476, rank: 82, score: 12.484959188773843\n",
            "docno: 6639557, rank: 83, score: 12.484959188773843\n",
            "docno: 7034127, rank: 84, score: 12.484959188773843\n",
            "docno: 7708372, rank: 85, score: 12.484959188773843\n",
            "docno: 8313990, rank: 86, score: 12.484959188773843\n",
            "docno: 5310578, rank: 87, score: 12.475050368647942\n",
            "docno: 5624714, rank: 88, score: 12.475050368647942\n",
            "docno: 103167, rank: 89, score: 12.464395514654608\n",
            "docno: 2535947, rank: 90, score: 12.464395514654608\n",
            "docno: 6731802, rank: 91, score: 12.464395514654608\n",
            "docno: 8300156, rank: 92, score: 12.464395514654608\n",
            "docno: 8578087, rank: 93, score: 12.464395514654608\n",
            "docno: 5146262, rank: 94, score: 12.462453262807337\n",
            "docno: 6375311, rank: 95, score: 12.449748600646254\n",
            "docno: 7108090, rank: 96, score: 12.449748600646254\n",
            "docno: 2268410, rank: 97, score: 12.443140314978962\n",
            "docno: 2760310, rank: 98, score: 12.443140314978962\n",
            "docno: 5604005, rank: 99, score: 12.443140314978962\n",
            "docno: 6361544, rank: 100, score: 12.443140314978962\n",
            "docno: 8517859, rank: 101, score: 12.443140314978962\n",
            "docno: 6173223, rank: 102, score: 12.438785985462678\n",
            "docno: 1220590, rank: 103, score: 12.426945365150608\n",
            "docno: 1744748, rank: 104, score: 12.426945365150608\n",
            "docno: 2095454, rank: 105, score: 12.426945365150608\n",
            "docno: 2507414, rank: 106, score: 12.426945365150608\n",
            "docno: 2715878, rank: 107, score: 12.426945365150608\n",
            "docno: 2791590, rank: 108, score: 12.426945365150608\n",
            "docno: 4514039, rank: 109, score: 12.426945365150608\n",
            "docno: 5806801, rank: 110, score: 12.426945365150608\n",
            "docno: 6666439, rank: 111, score: 12.426945365150608\n",
            "docno: 8489500, rank: 112, score: 12.417910877227362\n",
            "docno: 330417, rank: 113, score: 12.408488393963589\n",
            "docno: 262264, rank: 114, score: 12.402731828862533\n",
            "docno: 6731803, rank: 115, score: 12.402731828862533\n",
            "docno: 7824276, rank: 116, score: 12.398258191792635\n",
            "docno: 5588333, rank: 117, score: 12.394681605094595\n",
            "docno: 7667388, rank: 118, score: 12.394681605094595\n",
            "docno: 4400455, rank: 119, score: 12.391756841367984\n",
            "docno: 4467133, rank: 120, score: 12.391756841367984\n",
            "docno: 895077, rank: 121, score: 12.371190203723751\n",
            "docno: 1329492, rank: 122, score: 12.371190203723751\n",
            "docno: 5733721, rank: 123, score: 12.371190203723751\n",
            "docno: 8229560, rank: 124, score: 12.371190203723751\n",
            "docno: 142540, rank: 125, score: 12.369468193201275\n",
            "docno: 1649123, rank: 126, score: 12.369468193201275\n",
            "docno: 2903206, rank: 127, score: 12.369468193201275\n",
            "docno: 3081741, rank: 128, score: 12.369468193201275\n",
            "docno: 3909561, rank: 129, score: 12.369468193201275\n",
            "docno: 3953046, rank: 130, score: 12.369468193201275\n",
            "docno: 4021389, rank: 131, score: 12.369468193201275\n",
            "docno: 5622224, rank: 132, score: 12.369468193201275\n",
            "docno: 5808524, rank: 133, score: 12.369468193201275\n",
            "docno: 5882613, rank: 134, score: 12.369468193201275\n",
            "docno: 6053643, rank: 135, score: 12.369468193201275\n",
            "docno: 5908962, rank: 136, score: 12.368320452490059\n",
            "docno: 7612931, rank: 137, score: 12.368320452490059\n",
            "docno: 7612932, rank: 138, score: 12.368320452490059\n",
            "docno: 903444, rank: 139, score: 12.366408024550607\n",
            "docno: 1160151, rank: 140, score: 12.366408024550607\n",
            "docno: 2258058, rank: 141, score: 12.366408024550607\n",
            "docno: 8284853, rank: 142, score: 12.337501812099712\n",
            "docno: 2305736, rank: 143, score: 12.334721079241008\n",
            "docno: 2686727, rank: 144, score: 12.320836196150765\n",
            "docno: 3035428, rank: 145, score: 12.320836196150765\n",
            "docno: 3844842, rank: 146, score: 12.320836196150765\n",
            "docno: 4396472, rank: 147, score: 12.320836196150765\n",
            "docno: 6731801, rank: 148, score: 12.320836196150765\n",
            "docno: 8446541, rank: 149, score: 12.320836196150765\n",
            "docno: 238128, rank: 150, score: 12.312520260835987\n",
            "docno: 638687, rank: 151, score: 12.312520260835987\n",
            "docno: 2850386, rank: 152, score: 12.312520260835987\n",
            "docno: 3746103, rank: 153, score: 12.312520260835987\n",
            "docno: 3862835, rank: 154, score: 12.312520260835987\n",
            "docno: 4443615, rank: 155, score: 12.312520260835987\n",
            "docno: 4716457, rank: 156, score: 12.312520260835987\n",
            "docno: 5443499, rank: 157, score: 12.312520260835987\n",
            "docno: 5689576, rank: 158, score: 12.312520260835987\n",
            "docno: 6432527, rank: 159, score: 12.312520260835987\n",
            "docno: 6666442, rank: 160, score: 12.312520260835987\n",
            "docno: 6827250, rank: 161, score: 12.312520260835987\n",
            "docno: 7240008, rank: 162, score: 12.312520260835987\n",
            "docno: 7514554, rank: 163, score: 12.312520260835987\n",
            "docno: 7709929, rank: 164, score: 12.312520260835987\n",
            "docno: 8164040, rank: 165, score: 12.312520260835987\n",
            "docno: 8229562, rank: 166, score: 12.312520260835987\n",
            "docno: 8307114, rank: 167, score: 12.312520260835987\n",
            "docno: 8376663, rank: 168, score: 12.312520260835987\n",
            "docno: 8446536, rank: 169, score: 12.312520260835987\n",
            "docno: 8069283, rank: 170, score: 12.309109298919932\n",
            "docno: 6423471, rank: 171, score: 12.303196104380174\n",
            "docno: 7824273, rank: 172, score: 12.303196104380174\n",
            "docno: 3462751, rank: 173, score: 12.3000673846947\n",
            "docno: 4971655, rank: 174, score: 12.3000673846947\n",
            "docno: 8363989, rank: 175, score: 12.3000673846947\n",
            "docno: 8725832, rank: 176, score: 12.3000673846947\n",
            "docno: 5588337, rank: 177, score: 12.295812595738596\n",
            "docno: 6564744, rank: 178, score: 12.286332525050092\n",
            "docno: 7558743, rank: 179, score: 12.279368473957225\n",
            "docno: 703308, rank: 180, score: 12.273715146974112\n",
            "docno: 1428098, rank: 181, score: 12.273715146974112\n",
            "docno: 2275484, rank: 182, score: 12.273715146974112\n",
            "docno: 3259815, rank: 183, score: 12.260581326499658\n",
            "docno: 5589817, rank: 184, score: 12.260581326499658\n",
            "docno: 6273208, rank: 185, score: 12.260581326499658\n",
            "docno: 2174538, rank: 186, score: 12.256094291837755\n",
            "docno: 3283508, rank: 187, score: 12.256094291837755\n",
            "docno: 3746102, rank: 188, score: 12.256094291837755\n",
            "docno: 3909560, rank: 189, score: 12.256094291837755\n",
            "docno: 3953594, rank: 190, score: 12.256094291837755\n",
            "docno: 4016352, rank: 191, score: 12.256094291837755\n",
            "docno: 4362089, rank: 192, score: 12.256094291837755\n",
            "docno: 4413518, rank: 193, score: 12.256094291837755\n",
            "docno: 4579140, rank: 194, score: 12.256094291837755\n",
            "docno: 5524904, rank: 195, score: 12.256094291837755\n",
            "docno: 5844841, rank: 196, score: 12.256094291837755\n",
            "docno: 7257613, rank: 197, score: 12.256094291837755\n",
            "docno: 7670974, rank: 198, score: 12.256094291837755\n",
            "docno: 7843469, rank: 199, score: 12.256094291837755\n",
            "docno: 7989812, rank: 200, score: 12.256094291837755\n",
            "docno: 8011292, rank: 201, score: 12.256094291837755\n",
            "docno: 8802583, rank: 202, score: 12.256094291837755\n",
            "docno: 1018623, rank: 203, score: 12.247475584378035\n",
            "docno: 353455, rank: 204, score: 12.246146628783336\n",
            "docno: 2121017, rank: 205, score: 12.246146628783336\n",
            "docno: 8440504, rank: 206, score: 12.246146628783336\n",
            "docno: 896164, rank: 207, score: 12.229757670974506\n",
            "docno: 1335614, rank: 208, score: 12.229757670974506\n",
            "docno: 1799941, rank: 209, score: 12.229757670974506\n",
            "docno: 2154136, rank: 210, score: 12.229757670974506\n",
            "docno: 4122689, rank: 211, score: 12.229757670974506\n",
            "docno: 5604003, rank: 212, score: 12.229757670974506\n",
            "docno: 5870074, rank: 213, score: 12.229757670974506\n",
            "docno: 6620194, rank: 214, score: 12.229757670974506\n",
            "docno: 7931994, rank: 215, score: 12.229757670974506\n",
            "docno: 7931995, rank: 216, score: 12.229757670974506\n",
            "docno: 8090633, rank: 217, score: 12.229757670974506\n",
            "docno: 1501215, rank: 218, score: 12.226953153578695\n",
            "docno: 7961451, rank: 219, score: 12.226953153578695\n",
            "docno: 7020661, rank: 220, score: 12.209580678105228\n",
            "docno: 2022734, rank: 221, score: 12.206222753989891\n",
            "docno: 4246246, rank: 222, score: 12.206222753989891\n",
            "docno: 378778, rank: 223, score: 12.200183142763265\n",
            "docno: 447475, rank: 224, score: 12.200183142763265\n",
            "docno: 602502, rank: 225, score: 12.200183142763265\n",
            "docno: 932072, rank: 226, score: 12.200183142763265\n",
            "docno: 2795720, rank: 227, score: 12.200183142763265\n",
            "docno: 3081742, rank: 228, score: 12.200183142763265\n",
            "docno: 4246250, rank: 229, score: 12.200183142763265\n",
            "docno: 4514042, rank: 230, score: 12.200183142763265\n",
            "docno: 4604662, rank: 231, score: 12.200183142763265\n",
            "docno: 5534851, rank: 232, score: 12.200183142763265\n",
            "docno: 6401678, rank: 233, score: 12.200183142763265\n",
            "docno: 6697903, rank: 234, score: 12.200183142763265\n",
            "docno: 6731798, rank: 235, score: 12.200183142763265\n",
            "docno: 7132953, rank: 236, score: 12.200183142763265\n",
            "docno: 7496457, rank: 237, score: 12.200183142763265\n",
            "docno: 7575196, rank: 238, score: 12.200183142763265\n",
            "docno: 6368508, rank: 239, score: 12.196834130389766\n",
            "docno: 665926, rank: 240, score: 12.190721027088298\n",
            "docno: 903446, rank: 241, score: 12.190721027088298\n",
            "docno: 4579138, rank: 242, score: 12.190721027088298\n",
            "docno: 5182448, rank: 243, score: 12.190721027088298\n",
            "docno: 7132950, rank: 244, score: 12.190721027088298\n",
            "docno: 5086920, rank: 245, score: 12.186113932765373\n",
            "docno: 650142, rank: 246, score: 12.18054612760887\n",
            "docno: 4764815, rank: 247, score: 12.18054612760887\n",
            "docno: 5270267, rank: 248, score: 12.18054612760887\n",
            "docno: 6181506, rank: 249, score: 12.18054612760887\n",
            "docno: 6398612, rank: 250, score: 12.18054612760887\n",
            "docno: 8285303, rank: 251, score: 12.18054612760887\n",
            "docno: 8489503, rank: 252, score: 12.178691323014018\n",
            "docno: 437903, rank: 253, score: 12.166558346334952\n",
            "docno: 3707283, rank: 254, score: 12.166558346334952\n",
            "docno: 111391, rank: 255, score: 12.160247198183521\n",
            "docno: 258625, rank: 256, score: 12.160247198183521\n",
            "docno: 750182, rank: 257, score: 12.160247198183521\n",
            "docno: 768641, rank: 258, score: 12.160247198183521\n",
            "docno: 896165, rank: 259, score: 12.160247198183521\n",
            "docno: 1293610, rank: 260, score: 12.160247198183521\n",
            "docno: 2535954, rank: 261, score: 12.160247198183521\n",
            "docno: 2850383, rank: 262, score: 12.160247198183521\n",
            "docno: 3290810, rank: 263, score: 12.160247198183521\n",
            "docno: 3765788, rank: 264, score: 12.160247198183521\n",
            "docno: 4428658, rank: 265, score: 12.160247198183521\n",
            "docno: 4632505, rank: 266, score: 12.160247198183521\n",
            "docno: 4656485, rank: 267, score: 12.160247198183521\n",
            "docno: 4913011, rank: 268, score: 12.160247198183521\n",
            "docno: 7973057, rank: 269, score: 12.160247198183521\n",
            "docno: 8323264, rank: 270, score: 12.160247198183521\n",
            "docno: 8587748, rank: 271, score: 12.160247198183521\n",
            "docno: 671146, rank: 272, score: 12.144779799928113\n",
            "docno: 2355151, rank: 273, score: 12.144779799928113\n",
            "docno: 4306134, rank: 274, score: 12.144779799928113\n",
            "docno: 5244947, rank: 275, score: 12.144779799928113\n",
            "docno: 5990379, rank: 276, score: 12.144779799928113\n",
            "docno: 6076614, rank: 277, score: 12.144779799928113\n",
            "docno: 6586728, rank: 278, score: 12.144779799928113\n",
            "docno: 7127114, rank: 279, score: 12.144779799928113\n",
            "docno: 7337504, rank: 280, score: 12.144779799928113\n",
            "docno: 7612930, rank: 281, score: 12.144779799928113\n",
            "docno: 7614418, rank: 282, score: 12.144779799928113\n",
            "docno: 7020659, rank: 283, score: 12.136150784952683\n",
            "docno: 903448, rank: 284, score: 12.134490042543229\n",
            "docno: 5373630, rank: 285, score: 12.134490042543229\n",
            "docno: 5386076, rank: 286, score: 12.134490042543229\n",
            "docno: 6238080, rank: 287, score: 12.134490042543229\n",
            "docno: 6686816, rank: 288, score: 12.134490042543229\n",
            "docno: 85142, rank: 289, score: 12.127150884577661\n",
            "docno: 478311, rank: 290, score: 12.127150884577661\n",
            "docno: 537461, rank: 291, score: 12.127150884577661\n",
            "docno: 1964750, rank: 292, score: 12.127150884577661\n",
            "docno: 8115480, rank: 293, score: 12.127150884577661\n",
            "docno: 3092157, rank: 294, score: 12.121652339458887\n",
            "docno: 3226781, rank: 295, score: 12.121652339458887\n",
            "docno: 3707280, rank: 296, score: 12.117379139266573\n",
            "docno: 1587659, rank: 297, score: 12.09426514190508\n",
            "docno: 3895665, rank: 298, score: 12.09426514190508\n",
            "docno: 4903615, rank: 299, score: 12.09426514190508\n",
            "docno: 5134951, rank: 300, score: 12.09426514190508\n",
            "docno: 6488918, rank: 301, score: 12.09426514190508\n",
            "docno: 8565867, rank: 302, score: 12.09426514190508\n",
            "docno: 8746237, rank: 303, score: 12.09426514190508\n",
            "docno: 395584, rank: 304, score: 12.091522415365494\n",
            "docno: 1023501, rank: 305, score: 12.091522415365494\n",
            "docno: 1302053, rank: 306, score: 12.091522415365494\n",
            "docno: 1653164, rank: 307, score: 12.091522415365494\n",
            "docno: 2119812, rank: 308, score: 12.091522415365494\n",
            "docno: 2240319, rank: 309, score: 12.091522415365494\n",
            "docno: 2258063, rank: 310, score: 12.091522415365494\n",
            "docno: 2351890, rank: 311, score: 12.091522415365494\n",
            "docno: 2761480, rank: 312, score: 12.091522415365494\n",
            "docno: 4272143, rank: 313, score: 12.091522415365494\n",
            "docno: 6191049, rank: 314, score: 12.091522415365494\n",
            "docno: 6623709, rank: 315, score: 12.091522415365494\n",
            "docno: 6675754, rank: 316, score: 12.091522415365494\n",
            "docno: 6835015, rank: 317, score: 12.091522415365494\n",
            "docno: 7976980, rank: 318, score: 12.091522415365494\n",
            "docno: 8725833, rank: 319, score: 12.091522415365494\n",
            "docno: 8740613, rank: 320, score: 12.091522415365494\n",
            "docno: 537462, rank: 321, score: 12.089877376473835\n",
            "docno: 1539385, rank: 322, score: 12.089877376473835\n",
            "docno: 1670391, rank: 323, score: 12.089877376473835\n",
            "docno: 2011352, rank: 324, score: 12.089877376473835\n",
            "docno: 2137369, rank: 325, score: 12.089877376473835\n",
            "docno: 2535952, rank: 326, score: 12.089877376473835\n",
            "docno: 3472672, rank: 327, score: 12.089877376473835\n",
            "docno: 3578879, rank: 328, score: 12.089877376473835\n",
            "docno: 3844840, rank: 329, score: 12.089877376473835\n",
            "docno: 4043041, rank: 330, score: 12.089877376473835\n",
            "docno: 4579135, rank: 331, score: 12.089877376473835\n",
            "docno: 4579142, rank: 332, score: 12.089877376473835\n",
            "docno: 5534849, rank: 333, score: 12.089877376473835\n",
            "docno: 6666440, rank: 334, score: 12.089877376473835\n",
            "docno: 7718518, rank: 335, score: 12.089877376473835\n",
            "docno: 8116668, rank: 336, score: 12.089877376473835\n",
            "docno: 8481212, rank: 337, score: 12.089877376473835\n",
            "docno: 96103, rank: 338, score: 12.088780932529962\n",
            "docno: 5244945, rank: 339, score: 12.088780932529962\n",
            "docno: 8396200, rank: 340, score: 12.088780932529962\n",
            "docno: 5310579, rank: 341, score: 12.087997880036879\n",
            "docno: 5574033, rank: 342, score: 12.087997880036879\n",
            "docno: 7755980, rank: 343, score: 12.087997880036879\n",
            "docno: 8247874, rank: 344, score: 12.087997880036879\n",
            "docno: 983497, rank: 345, score: 12.087410657236891\n",
            "docno: 4134739, rank: 346, score: 12.087410657236891\n",
            "docno: 5470341, rank: 347, score: 12.087410657236891\n",
            "docno: 4400450, rank: 348, score: 12.086953967835287\n",
            "docno: 3459882, rank: 349, score: 12.086588641160084\n",
            "docno: 3244998, rank: 350, score: 12.061512562945472\n",
            "docno: 903451, rank: 351, score: 12.059337971023298\n",
            "docno: 3686719, rank: 352, score: 12.059337971023298\n",
            "docno: 1818470, rank: 353, score: 12.056681201074499\n",
            "docno: 976093, rank: 354, score: 12.049096876067267\n",
            "docno: 7558936, rank: 355, score: 12.049096876067267\n",
            "docno: 7967974, rank: 356, score: 12.049096876067267\n",
            "docno: 1583012, rank: 357, score: 12.043414891248505\n",
            "docno: 3121284, rank: 358, score: 12.043414891248505\n",
            "docno: 5868446, rank: 359, score: 12.043414891248505\n",
            "docno: 7102755, rank: 360, score: 12.043414891248505\n",
            "docno: 31314, rank: 361, score: 12.03546910951412\n",
            "docno: 180877, rank: 362, score: 12.03546910951412\n",
            "docno: 946621, rank: 363, score: 12.03546910951412\n",
            "docno: 1428100, rank: 364, score: 12.03546910951412\n",
            "docno: 1934003, rank: 365, score: 12.03546910951412\n",
            "docno: 2452691, rank: 366, score: 12.03546910951412\n",
            "docno: 2903941, rank: 367, score: 12.03546910951412\n",
            "docno: 3556006, rank: 368, score: 12.03546910951412\n",
            "docno: 3746100, rank: 369, score: 12.03546910951412\n",
            "docno: 4396475, rank: 370, score: 12.03546910951412\n",
            "docno: 4552569, rank: 371, score: 12.03546910951412\n",
            "docno: 4579133, rank: 372, score: 12.03546910951412\n",
            "docno: 4972511, rank: 373, score: 12.03546910951412\n",
            "docno: 5734297, rank: 374, score: 12.03546910951412\n",
            "docno: 5745878, rank: 375, score: 12.03546910951412\n",
            "docno: 7451612, rank: 376, score: 12.03546910951412\n",
            "docno: 8090634, rank: 377, score: 12.03546910951412\n",
            "docno: 8314252, rank: 378, score: 12.03546910951412\n",
            "docno: 8546198, rank: 379, score: 12.03546910951412\n",
            "docno: 8630426, rank: 380, score: 12.03546910951412\n",
            "docno: 8641517, rank: 381, score: 12.03546910951412\n",
            "docno: 8748486, rank: 382, score: 12.03546910951412\n",
            "docno: 262261, rank: 383, score: 12.026559696715154\n",
            "docno: 366485, rank: 384, score: 12.023570076180624\n",
            "docno: 668073, rank: 385, score: 12.023570076180624\n",
            "docno: 1916264, rank: 386, score: 12.023570076180624\n",
            "docno: 2067929, rank: 387, score: 12.023570076180624\n",
            "docno: 2275487, rank: 388, score: 12.023570076180624\n",
            "docno: 2588490, rank: 389, score: 12.023570076180624\n",
            "docno: 2915233, rank: 390, score: 12.023570076180624\n",
            "docno: 3330782, rank: 391, score: 12.023570076180624\n",
            "docno: 3462747, rank: 392, score: 12.023570076180624\n",
            "docno: 3732851, rank: 393, score: 12.023570076180624\n",
            "docno: 4323218, rank: 394, score: 12.023570076180624\n",
            "docno: 4971659, rank: 395, score: 12.023570076180624\n",
            "docno: 5070018, rank: 396, score: 12.023570076180624\n",
            "docno: 5740168, rank: 397, score: 12.023570076180624\n",
            "docno: 6351771, rank: 398, score: 12.023570076180624\n",
            "docno: 6549489, rank: 399, score: 12.023570076180624\n",
            "docno: 8307113, rank: 400, score: 12.023570076180624\n",
            "docno: 8568904, rank: 401, score: 12.019504395212369\n",
            "docno: 1480770, rank: 402, score: 12.012261699612644\n",
            "docno: 3930854, rank: 403, score: 12.010445447545479\n",
            "docno: 628906, rank: 404, score: 12.003790553031289\n",
            "docno: 865272, rank: 405, score: 12.003790553031289\n",
            "docno: 2119814, rank: 406, score: 12.003790553031289\n",
            "docno: 2926115, rank: 407, score: 12.003790553031289\n",
            "docno: 4544217, rank: 408, score: 12.003790553031289\n",
            "docno: 5143740, rank: 409, score: 12.003790553031289\n",
            "docno: 5707064, rank: 410, score: 12.003790553031289\n",
            "docno: 903449, rank: 411, score: 11.99838807079666\n",
            "docno: 1964748, rank: 412, score: 11.99838807079666\n",
            "docno: 5531476, rank: 413, score: 11.99838807079666\n",
            "docno: 5576597, rank: 414, score: 11.99838807079666\n",
            "docno: 6349381, rank: 415, score: 11.99838807079666\n",
            "docno: 7190100, rank: 416, score: 11.99838807079666\n",
            "docno: 6636474, rank: 417, score: 11.996588323874786\n",
            "docno: 7034674, rank: 418, score: 11.985836582368673\n",
            "docno: 8568903, rank: 419, score: 11.985836582368673\n",
            "docno: 976092, rank: 420, score: 11.981548357357742\n",
            "docno: 1041624, rank: 421, score: 11.981548357357742\n",
            "docno: 2154133, rank: 422, score: 11.981548357357742\n",
            "docno: 2512150, rank: 423, score: 11.981548357357742\n",
            "docno: 3121286, rank: 424, score: 11.981548357357742\n",
            "docno: 3206885, rank: 425, score: 11.981548357357742\n",
            "docno: 3578884, rank: 426, score: 11.981548357357742\n",
            "docno: 3707278, rank: 427, score: 11.981548357357742\n",
            "docno: 4396473, rank: 428, score: 11.981548357357742\n",
            "docno: 4503582, rank: 429, score: 11.981548357357742\n",
            "docno: 4840072, rank: 430, score: 11.981548357357742\n",
            "docno: 7127579, rank: 431, score: 11.981548357357742\n",
            "docno: 7158809, rank: 432, score: 11.981548357357742\n",
            "docno: 7898449, rank: 433, score: 11.981548357357742\n",
            "docno: 8413978, rank: 434, score: 11.981548357357742\n",
            "docno: 8546197, rank: 435, score: 11.981548357357742\n",
            "docno: 3444873, rank: 436, score: 11.9783182862874\n",
            "docno: 3459879, rank: 437, score: 11.966765962915987\n",
            "docno: 212024, rank: 438, score: 11.95637723039393\n",
            "docno: 683421, rank: 439, score: 11.95637723039393\n",
            "docno: 747834, rank: 440, score: 11.95637723039393\n",
            "docno: 1015985, rank: 441, score: 11.95637723039393\n",
            "docno: 1151118, rank: 442, score: 11.95637723039393\n",
            "docno: 1186706, rank: 443, score: 11.95637723039393\n",
            "docno: 1484157, rank: 444, score: 11.95637723039393\n",
            "docno: 1653159, rank: 445, score: 11.95637723039393\n",
            "docno: 1719634, rank: 446, score: 11.95637723039393\n",
            "docno: 2300663, rank: 447, score: 11.95637723039393\n",
            "docno: 2300664, rank: 448, score: 11.95637723039393\n",
            "docno: 2305493, rank: 449, score: 11.95637723039393\n",
            "docno: 2703403, rank: 450, score: 11.95637723039393\n",
            "docno: 2761478, rank: 451, score: 11.95637723039393\n",
            "docno: 2770474, rank: 452, score: 11.95637723039393\n",
            "docno: 4089983, rank: 453, score: 11.95637723039393\n",
            "docno: 4126320, rank: 454, score: 11.95637723039393\n",
            "docno: 4296232, rank: 455, score: 11.95637723039393\n",
            "docno: 4551700, rank: 456, score: 11.95637723039393\n",
            "docno: 4551702, rank: 457, score: 11.95637723039393\n",
            "docno: 4551704, rank: 458, score: 11.95637723039393\n",
            "docno: 4783963, rank: 459, score: 11.95637723039393\n",
            "docno: 4936397, rank: 460, score: 11.95637723039393\n",
            "docno: 5622226, rank: 461, score: 11.95637723039393\n",
            "docno: 6771822, rank: 462, score: 11.95637723039393\n",
            "docno: 7523167, rank: 463, score: 11.95637723039393\n",
            "docno: 8130817, rank: 464, score: 11.95637723039393\n",
            "docno: 8190589, rank: 465, score: 11.95637723039393\n",
            "docno: 8417000, rank: 466, score: 11.95637723039393\n",
            "docno: 340229, rank: 467, score: 11.953696680602633\n",
            "docno: 405496, rank: 468, score: 11.953696680602633\n",
            "docno: 2703396, rank: 469, score: 11.953696680602633\n",
            "docno: 4790050, rank: 470, score: 11.953696680602633\n",
            "docno: 6476098, rank: 471, score: 11.953696680602633\n",
            "docno: 6978550, rank: 472, score: 11.953696680602633\n",
            "docno: 6980047, rank: 473, score: 11.953696680602633\n",
            "docno: 7013603, rank: 474, score: 11.953696680602633\n",
            "docno: 7497153, rank: 475, score: 11.953696680602633\n",
            "docno: 8518969, rank: 476, score: 11.953696680602633\n",
            "docno: 8732368, rank: 477, score: 11.953696680602633\n",
            "docno: 6826467, rank: 478, score: 11.952356856379149\n",
            "docno: 8489502, rank: 479, score: 11.952356856379149\n",
            "docno: 1820570, rank: 480, score: 11.933881770947703\n",
            "docno: 3535475, rank: 481, score: 11.933881770947703\n",
            "docno: 4096831, rank: 482, score: 11.933881770947703\n",
            "docno: 946622, rank: 483, score: 11.928108596805803\n",
            "docno: 2976008, rank: 484, score: 11.928108596805803\n",
            "docno: 3631265, rank: 485, score: 11.928108596805803\n",
            "docno: 4248511, rank: 486, score: 11.928108596805803\n",
            "docno: 4511273, rank: 487, score: 11.928108596805803\n",
            "docno: 4691988, rank: 488, score: 11.928108596805803\n",
            "docno: 4972510, rank: 489, score: 11.928108596805803\n",
            "docno: 5217809, rank: 490, score: 11.928108596805803\n",
            "docno: 6156093, rank: 491, score: 11.928108596805803\n",
            "docno: 8307117, rank: 492, score: 11.928108596805803\n",
            "docno: 4248510, rank: 493, score: 11.924907270971831\n",
            "docno: 5406294, rank: 494, score: 11.924907270971831\n",
            "docno: 1192853, rank: 495, score: 11.919063645499728\n",
            "docno: 3054949, rank: 496, score: 11.919063645499728\n",
            "docno: 3409287, rank: 497, score: 11.919063645499728\n",
            "docno: 4522655, rank: 498, score: 11.919063645499728\n",
            "docno: 5335207, rank: 499, score: 11.919063645499728\n",
            "docno: 6340158, rank: 500, score: 11.919063645499728\n",
            "docno: 6453840, rank: 501, score: 11.919063645499728\n",
            "docno: 5584927, rank: 502, score: 11.914956837102535\n",
            "docno: 502172, rank: 503, score: 11.914659554814786\n",
            "docno: 714950, rank: 504, score: 11.914659554814786\n",
            "docno: 1023503, rank: 505, score: 11.914659554814786\n",
            "docno: 2626545, rank: 506, score: 11.914659554814786\n",
            "docno: 3281881, rank: 507, score: 11.914659554814786\n",
            "docno: 4381788, rank: 508, score: 11.914659554814786\n",
            "docno: 5153595, rank: 509, score: 11.914659554814786\n",
            "docno: 5990153, rank: 510, score: 11.914659554814786\n",
            "docno: 8386690, rank: 511, score: 11.914659554814786\n",
            "docno: 8650949, rank: 512, score: 11.914659554814786\n",
            "docno: 3535474, rank: 513, score: 11.909336986361284\n",
            "docno: 4116319, rank: 514, score: 11.909336986361284\n",
            "docno: 5036188, rank: 515, score: 11.909336986361284\n",
            "docno: 5797512, rank: 516, score: 11.909336986361284\n",
            "docno: 8709002, rank: 517, score: 11.909336986361284\n",
            "docno: 1352671, rank: 518, score: 11.895964825747177\n",
            "docno: 1711539, rank: 519, score: 11.895964825747177\n",
            "docno: 4197955, rank: 520, score: 11.895964825747177\n",
            "docno: 4273418, rank: 521, score: 11.895964825747177\n",
            "docno: 4360556, rank: 522, score: 11.895964825747177\n",
            "docno: 111390, rank: 523, score: 11.889931215647437\n",
            "docno: 776299, rank: 524, score: 11.889931215647437\n",
            "docno: 1217939, rank: 525, score: 11.889931215647437\n",
            "docno: 1231470, rank: 526, score: 11.889931215647437\n",
            "docno: 1269032, rank: 527, score: 11.889931215647437\n",
            "docno: 1286882, rank: 528, score: 11.889931215647437\n",
            "docno: 1512323, rank: 529, score: 11.889931215647437\n",
            "docno: 1870894, rank: 530, score: 11.889931215647437\n",
            "docno: 2047681, rank: 531, score: 11.889931215647437\n",
            "docno: 2250975, rank: 532, score: 11.889931215647437\n",
            "docno: 2304642, rank: 533, score: 11.889931215647437\n",
            "docno: 2351886, rank: 534, score: 11.889931215647437\n",
            "docno: 2903204, rank: 535, score: 11.889931215647437\n",
            "docno: 2966872, rank: 536, score: 11.889931215647437\n",
            "docno: 3462748, rank: 537, score: 11.889931215647437\n",
            "docno: 4000327, rank: 538, score: 11.889931215647437\n",
            "docno: 4188880, rank: 539, score: 11.889931215647437\n",
            "docno: 5007129, rank: 540, score: 11.889931215647437\n",
            "docno: 5011783, rank: 541, score: 11.889931215647437\n",
            "docno: 5175472, rank: 542, score: 11.889931215647437\n",
            "docno: 5180459, rank: 543, score: 11.889931215647437\n",
            "docno: 6191474, rank: 544, score: 11.889931215647437\n",
            "docno: 6382183, rank: 545, score: 11.889931215647437\n",
            "docno: 6464969, rank: 546, score: 11.889931215647437\n",
            "docno: 6569930, rank: 547, score: 11.889931215647437\n",
            "docno: 6581168, rank: 548, score: 11.889931215647437\n",
            "docno: 6623705, rank: 549, score: 11.889931215647437\n",
            "docno: 6642005, rank: 550, score: 11.889931215647437\n",
            "docno: 6961190, rank: 551, score: 11.889931215647437\n",
            "docno: 7102752, rank: 552, score: 11.889931215647437\n",
            "docno: 7139700, rank: 553, score: 11.889931215647437\n",
            "docno: 7755976, rank: 554, score: 11.889931215647437\n",
            "docno: 7791560, rank: 555, score: 11.889931215647437\n",
            "docno: 8095244, rank: 556, score: 11.889931215647437\n",
            "docno: 8376662, rank: 557, score: 11.889931215647437\n",
            "docno: 8467070, rank: 558, score: 11.889931215647437\n",
            "docno: 5792972, rank: 559, score: 11.885955395450042\n",
            "docno: 2139807, rank: 560, score: 11.875143420520976\n",
            "docno: 2549931, rank: 561, score: 11.875143420520976\n",
            "docno: 3076977, rank: 562, score: 11.875143420520976\n",
            "docno: 3464294, rank: 563, score: 11.875143420520976\n",
            "docno: 5634425, rank: 564, score: 11.875143420520976\n",
            "docno: 5806805, rank: 565, score: 11.875143420520976\n",
            "docno: 5882607, rank: 566, score: 11.875143420520976\n",
            "docno: 6238077, rank: 567, score: 11.875143420520976\n",
            "docno: 6425847, rank: 568, score: 11.875143420520976\n",
            "docno: 6593457, rank: 569, score: 11.875143420520976\n",
            "docno: 7184759, rank: 570, score: 11.875143420520976\n",
            "docno: 8250106, rank: 571, score: 11.875143420520976\n",
            "docno: 8593485, rank: 572, score: 11.875143420520976\n",
            "docno: 1750381, rank: 573, score: 11.865305308993952\n",
            "docno: 3070598, rank: 574, score: 11.865305308993952\n",
            "docno: 3707281, rank: 575, score: 11.865305308993952\n",
            "docno: 4168172, rank: 576, score: 11.865305308993952\n",
            "docno: 5604006, rank: 577, score: 11.865305308993952\n",
            "docno: 5911798, rank: 578, score: 11.865305308993952\n",
            "docno: 7497154, rank: 579, score: 11.865305308993952\n",
            "docno: 7802355, rank: 580, score: 11.865305308993952\n",
            "docno: 2431414, rank: 581, score: 11.858288060784794\n",
            "docno: 2970529, rank: 582, score: 11.858288060784794\n",
            "docno: 4124648, rank: 583, score: 11.858288060784794\n",
            "docno: 1076228, rank: 584, score: 11.853030569171521\n",
            "docno: 2042420, rank: 585, score: 11.853030569171521\n",
            "docno: 6446808, rank: 586, score: 11.853030569171521\n",
            "docno: 8570713, rank: 587, score: 11.848944630975296\n",
            "docno: 660031, rank: 588, score: 11.826842438410779\n",
            "docno: 785629, rank: 589, score: 11.826842438410779\n",
            "docno: 1377136, rank: 590, score: 11.826842438410779\n",
            "docno: 3116060, rank: 591, score: 11.826842438410779\n",
            "docno: 3152868, rank: 592, score: 11.826842438410779\n",
            "docno: 3528377, rank: 593, score: 11.826842438410779\n",
            "docno: 3893768, rank: 594, score: 11.826842438410779\n",
            "docno: 4432429, rank: 595, score: 11.826842438410779\n",
            "docno: 4785280, rank: 596, score: 11.826842438410779\n",
            "docno: 5586958, rank: 597, score: 11.826842438410779\n",
            "docno: 6487207, rank: 598, score: 11.826842438410779\n",
            "docno: 6772877, rank: 599, score: 11.826842438410779\n",
            "docno: 6854132, rank: 600, score: 11.826842438410779\n",
            "docno: 7663256, rank: 601, score: 11.826842438410779\n",
            "docno: 7762720, rank: 602, score: 11.826842438410779\n",
            "docno: 7787585, rank: 603, score: 11.826842438410779\n",
            "docno: 7831164, rank: 604, score: 11.826842438410779\n",
            "docno: 8491870, rank: 605, score: 11.826842438410779\n",
            "docno: 8636555, rank: 606, score: 11.826842438410779\n",
            "docno: 163748, rank: 607, score: 11.824219649505181\n",
            "docno: 378775, rank: 608, score: 11.824219649505181\n",
            "docno: 785634, rank: 609, score: 11.824219649505181\n",
            "docno: 896168, rank: 610, score: 11.824219649505181\n",
            "docno: 1151121, rank: 611, score: 11.824219649505181\n",
            "docno: 1290077, rank: 612, score: 11.824219649505181\n",
            "docno: 1290078, rank: 613, score: 11.824219649505181\n",
            "docno: 1293606, rank: 614, score: 11.824219649505181\n",
            "docno: 1373318, rank: 615, score: 11.824219649505181\n",
            "docno: 1512322, rank: 616, score: 11.824219649505181\n",
            "docno: 1600172, rank: 617, score: 11.824219649505181\n",
            "docno: 1610338, rank: 618, score: 11.824219649505181\n",
            "docno: 1695121, rank: 619, score: 11.824219649505181\n",
            "docno: 1917054, rank: 620, score: 11.824219649505181\n",
            "docno: 2237987, rank: 621, score: 11.824219649505181\n",
            "docno: 2380959, rank: 622, score: 11.824219649505181\n",
            "docno: 3024975, rank: 623, score: 11.824219649505181\n",
            "docno: 3207189, rank: 624, score: 11.824219649505181\n",
            "docno: 3328412, rank: 625, score: 11.824219649505181\n",
            "docno: 3897716, rank: 626, score: 11.824219649505181\n",
            "docno: 3927459, rank: 627, score: 11.824219649505181\n",
            "docno: 4063562, rank: 628, score: 11.824219649505181\n",
            "docno: 4078536, rank: 629, score: 11.824219649505181\n",
            "docno: 4127412, rank: 630, score: 11.824219649505181\n",
            "docno: 4172859, rank: 631, score: 11.824219649505181\n",
            "docno: 4633608, rank: 632, score: 11.824219649505181\n",
            "docno: 4715041, rank: 633, score: 11.824219649505181\n",
            "docno: 5041277, rank: 634, score: 11.824219649505181\n",
            "docno: 5041278, rank: 635, score: 11.824219649505181\n",
            "docno: 5180463, rank: 636, score: 11.824219649505181\n",
            "docno: 5219440, rank: 637, score: 11.824219649505181\n",
            "docno: 5249381, rank: 638, score: 11.824219649505181\n",
            "docno: 5561331, rank: 639, score: 11.824219649505181\n",
            "docno: 5624426, rank: 640, score: 11.824219649505181\n",
            "docno: 5995978, rank: 641, score: 11.824219649505181\n",
            "docno: 6401677, rank: 642, score: 11.824219649505181\n",
            "docno: 6623704, rank: 643, score: 11.824219649505181\n",
            "docno: 6697899, rank: 644, score: 11.824219649505181\n",
            "docno: 6801654, rank: 645, score: 11.824219649505181\n",
            "docno: 6948785, rank: 646, score: 11.824219649505181\n",
            "docno: 6961194, rank: 647, score: 11.824219649505181\n",
            "docno: 7655173, rank: 648, score: 11.824219649505181\n",
            "docno: 7957353, rank: 649, score: 11.824219649505181\n",
            "docno: 8300153, rank: 650, score: 11.824219649505181\n",
            "docno: 8333311, rank: 651, score: 11.824219649505181\n",
            "docno: 208409, rank: 652, score: 11.822646534466562\n",
            "docno: 1000046, rank: 653, score: 11.822646534466562\n",
            "docno: 1004261, rank: 654, score: 11.822646534466562\n",
            "docno: 1649129, rank: 655, score: 11.822646534466562\n",
            "docno: 5727947, rank: 656, score: 11.822646534466562\n",
            "docno: 6514558, rank: 657, score: 11.822646534466562\n",
            "docno: 7551104, rank: 658, score: 11.822646534466562\n",
            "docno: 8229565, rank: 659, score: 11.822646534466562\n",
            "docno: 8307111, rank: 660, score: 11.822646534466562\n",
            "docno: 8816415, rank: 661, score: 11.822646534466562\n",
            "docno: 2915234, rank: 662, score: 11.821598023631303\n",
            "docno: 5146261, rank: 663, score: 11.821598023631303\n",
            "docno: 5228545, rank: 664, score: 11.821598023631303\n",
            "docno: 5470163, rank: 665, score: 11.821598023631303\n",
            "docno: 8446537, rank: 666, score: 11.821598023631303\n",
            "docno: 721382, rank: 667, score: 11.82084920117716\n",
            "docno: 3535481, rank: 668, score: 11.82084920117716\n",
            "docno: 5310584, rank: 669, score: 11.82084920117716\n",
            "docno: 275762, rank: 670, score: 11.82028764658954\n",
            "docno: 1680813, rank: 671, score: 11.82028764658954\n",
            "docno: 1876071, rank: 672, score: 11.82028764658954\n",
            "docno: 2926206, rank: 673, score: 11.82028764658954\n",
            "docno: 2926208, rank: 674, score: 11.82028764658954\n",
            "docno: 5695789, rank: 675, score: 11.82028764658954\n",
            "docno: 6191476, rank: 676, score: 11.82028764658954\n",
            "docno: 6898985, rank: 677, score: 11.82028764658954\n",
            "docno: 4947308, rank: 678, score: 11.819850918795488\n",
            "docno: 6890315, rank: 679, score: 11.819850918795488\n",
            "docno: 7638125, rank: 680, score: 11.819215735973902\n",
            "docno: 147968, rank: 681, score: 11.790899729154154\n",
            "docno: 2926207, rank: 682, score: 11.787725124379474\n",
            "docno: 4866822, rank: 683, score: 11.787725124379474\n",
            "docno: 2431409, rank: 684, score: 11.783646000679404\n",
            "docno: 3284017, rank: 685, score: 11.783646000679404\n",
            "docno: 355220, rank: 686, score: 11.77821155861856\n",
            "docno: 2431406, rank: 687, score: 11.77821155861856\n",
            "docno: 3930853, rank: 688, score: 11.77821155861856\n",
            "docno: 3930855, rank: 689, score: 11.77821155861856\n",
            "docno: 4688585, rank: 690, score: 11.77821155861856\n",
            "docno: 5302693, rank: 691, score: 11.77821155861856\n",
            "docno: 5310580, rank: 692, score: 11.77821155861856\n",
            "docno: 5549867, rank: 693, score: 11.77821155861856\n",
            "docno: 7318334, rank: 694, score: 11.77821155861856\n",
            "docno: 7482399, rank: 695, score: 11.77821155861856\n",
            "docno: 667137, rank: 696, score: 11.770611755413125\n",
            "docno: 737151, rank: 697, score: 11.770611755413125\n",
            "docno: 3009527, rank: 698, score: 11.770611755413125\n",
            "docno: 3459875, rank: 699, score: 11.770611755413125\n",
            "docno: 3844835, rank: 700, score: 11.770611755413125\n",
            "docno: 5089931, rank: 701, score: 11.770611755413125\n",
            "docno: 5101182, rank: 702, score: 11.770611755413125\n",
            "docno: 6980049, rank: 703, score: 11.770611755413125\n",
            "docno: 7054685, rank: 704, score: 11.770611755413125\n",
            "docno: 7548579, rank: 705, score: 11.770611755413125\n",
            "docno: 424380, rank: 706, score: 11.759230421760563\n",
            "docno: 537464, rank: 707, score: 11.759230421760563\n",
            "docno: 681721, rank: 708, score: 11.759230421760563\n",
            "docno: 793939, rank: 709, score: 11.759230421760563\n",
            "docno: 989956, rank: 710, score: 11.759230421760563\n",
            "docno: 1274471, rank: 711, score: 11.759230421760563\n",
            "docno: 1808246, rank: 712, score: 11.759230421760563\n",
            "docno: 2119810, rank: 713, score: 11.759230421760563\n",
            "docno: 2691083, rank: 714, score: 11.759230421760563\n",
            "docno: 2766976, rank: 715, score: 11.759230421760563\n",
            "docno: 3076976, rank: 716, score: 11.759230421760563\n",
            "docno: 3207190, rank: 717, score: 11.759230421760563\n",
            "docno: 3340346, rank: 718, score: 11.759230421760563\n",
            "docno: 3372713, rank: 719, score: 11.759230421760563\n",
            "docno: 3387903, rank: 720, score: 11.759230421760563\n",
            "docno: 3622926, rank: 721, score: 11.759230421760563\n",
            "docno: 3797017, rank: 722, score: 11.759230421760563\n",
            "docno: 4000329, rank: 723, score: 11.759230421760563\n",
            "docno: 4514044, rank: 724, score: 11.759230421760563\n",
            "docno: 4899178, rank: 725, score: 11.759230421760563\n",
            "docno: 5330519, rank: 726, score: 11.759230421760563\n",
            "docno: 5522932, rank: 727, score: 11.759230421760563\n",
            "docno: 5587420, rank: 728, score: 11.759230421760563\n",
            "docno: 6035218, rank: 729, score: 11.759230421760563\n",
            "docno: 6612098, rank: 730, score: 11.759230421760563\n",
            "docno: 6705876, rank: 731, score: 11.759230421760563\n",
            "docno: 6917189, rank: 732, score: 11.759230421760563\n",
            "docno: 7055685, rank: 733, score: 11.759230421760563\n",
            "docno: 7074102, rank: 734, score: 11.759230421760563\n",
            "docno: 7168364, rank: 735, score: 11.759230421760563\n",
            "docno: 7308320, rank: 736, score: 11.759230421760563\n",
            "docno: 7327560, rank: 737, score: 11.759230421760563\n",
            "docno: 7332946, rank: 738, score: 11.759230421760563\n",
            "docno: 7383741, rank: 739, score: 11.759230421760563\n",
            "docno: 7392920, rank: 740, score: 11.759230421760563\n",
            "docno: 7439288, rank: 741, score: 11.759230421760563\n",
            "docno: 7464408, rank: 742, score: 11.759230421760563\n",
            "docno: 7548585, rank: 743, score: 11.759230421760563\n",
            "docno: 8001349, rank: 744, score: 11.759230421760563\n",
            "docno: 8229563, rank: 745, score: 11.759230421760563\n",
            "docno: 8300149, rank: 746, score: 11.759230421760563\n",
            "docno: 8753989, rank: 747, score: 11.759230421760563\n",
            "docno: 3054951, rank: 748, score: 11.755341515736623\n",
            "docno: 3414621, rank: 749, score: 11.755341515736623\n",
            "docno: 6020795, rank: 750, score: 11.755341515736623\n",
            "docno: 878579, rank: 751, score: 11.746676241235946\n",
            "docno: 3145830, rank: 752, score: 11.746676241235946\n",
            "docno: 5695788, rank: 753, score: 11.746676241235946\n",
            "docno: 6394072, rank: 754, score: 11.746676241235946\n",
            "docno: 137047, rank: 755, score: 11.740310364443392\n",
            "docno: 598592, rank: 756, score: 11.740310364443392\n",
            "docno: 747103, rank: 757, score: 11.740310364443392\n",
            "docno: 1015987, rank: 758, score: 11.740310364443392\n",
            "docno: 1367904, rank: 759, score: 11.740310364443392\n",
            "docno: 1563355, rank: 760, score: 11.740310364443392\n",
            "docno: 1619982, rank: 761, score: 11.740310364443392\n",
            "docno: 1771166, rank: 762, score: 11.740310364443392\n",
            "docno: 3013287, rank: 763, score: 11.740310364443392\n",
            "docno: 3600271, rank: 764, score: 11.740310364443392\n",
            "docno: 3684471, rank: 765, score: 11.740310364443392\n",
            "docno: 4078543, rank: 766, score: 11.740310364443392\n",
            "docno: 4246253, rank: 767, score: 11.740310364443392\n",
            "docno: 4493735, rank: 768, score: 11.740310364443392\n",
            "docno: 5601476, rank: 769, score: 11.740310364443392\n",
            "docno: 6122582, rank: 770, score: 11.740310364443392\n",
            "docno: 6209606, rank: 771, score: 11.740310364443392\n",
            "docno: 7102753, rank: 772, score: 11.740310364443392\n",
            "docno: 7184219, rank: 773, score: 11.740310364443392\n",
            "docno: 7522511, rank: 774, score: 11.740310364443392\n",
            "docno: 7609779, rank: 775, score: 11.740310364443392\n",
            "docno: 8640181, rank: 776, score: 11.740310364443392\n",
            "docno: 8779637, rank: 777, score: 11.740310364443392\n",
            "docno: 134385, rank: 778, score: 11.735142394542555\n",
            "docno: 1615199, rank: 779, score: 11.735142394542555\n",
            "docno: 3054953, rank: 780, score: 11.735142394542555\n",
            "docno: 6020796, rank: 781, score: 11.735142394542555\n",
            "docno: 7067383, rank: 782, score: 11.735142394542555\n",
            "docno: 7527481, rank: 783, score: 11.735142394542555\n",
            "docno: 7729543, rank: 784, score: 11.735142394542555\n",
            "docno: 570750, rank: 785, score: 11.733420748822766\n",
            "docno: 7391331, rank: 786, score: 11.733420748822766\n",
            "docno: 3054948, rank: 787, score: 11.72313535014991\n",
            "docno: 3414619, rank: 788, score: 11.72313535014991\n",
            "docno: 5792976, rank: 789, score: 11.72313535014991\n",
            "docno: 8420725, rank: 790, score: 11.72313535014991\n",
            "docno: 1061480, rank: 791, score: 11.719033008510726\n",
            "docno: 1274469, rank: 792, score: 11.719033008510726\n",
            "docno: 1274476, rank: 793, score: 11.719033008510726\n",
            "docno: 1350315, rank: 794, score: 11.719033008510726\n",
            "docno: 1670390, rank: 795, score: 11.719033008510726\n",
            "docno: 2852103, rank: 796, score: 11.719033008510726\n",
            "docno: 5604008, rank: 797, score: 11.719033008510726\n",
            "docno: 6238079, rank: 798, score: 11.719033008510726\n",
            "docno: 6435106, rank: 799, score: 11.719033008510726\n",
            "docno: 5470166, rank: 800, score: 11.709937732539666\n",
            "docno: 5792968, rank: 801, score: 11.709937732539666\n",
            "docno: 8443, rank: 802, score: 11.694951686996003\n",
            "docno: 13843, rank: 803, score: 11.694951686996003\n",
            "docno: 874921, rank: 804, score: 11.694951686996003\n",
            "docno: 1067750, rank: 805, score: 11.694951686996003\n",
            "docno: 1148009, rank: 806, score: 11.694951686996003\n",
            "docno: 1656476, rank: 807, score: 11.694951686996003\n",
            "docno: 1743315, rank: 808, score: 11.694951686996003\n",
            "docno: 2067924, rank: 809, score: 11.694951686996003\n",
            "docno: 2088984, rank: 810, score: 11.694951686996003\n",
            "docno: 2121685, rank: 811, score: 11.694951686996003\n",
            "docno: 2218522, rank: 812, score: 11.694951686996003\n",
            "docno: 2620078, rank: 813, score: 11.694951686996003\n",
            "docno: 2761477, rank: 814, score: 11.694951686996003\n",
            "docno: 2933937, rank: 815, score: 11.694951686996003\n",
            "docno: 3024973, rank: 816, score: 11.694951686996003\n",
            "docno: 3096455, rank: 817, score: 11.694951686996003\n",
            "docno: 3142876, rank: 818, score: 11.694951686996003\n",
            "docno: 3249914, rank: 819, score: 11.694951686996003\n",
            "docno: 3568082, rank: 820, score: 11.694951686996003\n",
            "docno: 4167208, rank: 821, score: 11.694951686996003\n",
            "docno: 4342736, rank: 822, score: 11.694951686996003\n",
            "docno: 4368104, rank: 823, score: 11.694951686996003\n",
            "docno: 4514045, rank: 824, score: 11.694951686996003\n",
            "docno: 4579137, rank: 825, score: 11.694951686996003\n",
            "docno: 4788317, rank: 826, score: 11.694951686996003\n",
            "docno: 4814476, rank: 827, score: 11.694951686996003\n",
            "docno: 4856738, rank: 828, score: 11.694951686996003\n",
            "docno: 4900250, rank: 829, score: 11.694951686996003\n",
            "docno: 5137897, rank: 830, score: 11.694951686996003\n",
            "docno: 5227688, rank: 831, score: 11.694951686996003\n",
            "docno: 5253048, rank: 832, score: 11.694951686996003\n",
            "docno: 5523219, rank: 833, score: 11.694951686996003\n",
            "docno: 5601800, rank: 834, score: 11.694951686996003\n",
            "docno: 5727949, rank: 835, score: 11.694951686996003\n",
            "docno: 5844842, rank: 836, score: 11.694951686996003\n",
            "docno: 5855512, rank: 837, score: 11.694951686996003\n",
            "docno: 6160933, rank: 838, score: 11.694951686996003\n",
            "docno: 6191475, rank: 839, score: 11.694951686996003\n",
            "docno: 6509763, rank: 840, score: 11.694951686996003\n",
            "docno: 6708157, rank: 841, score: 11.694951686996003\n",
            "docno: 6901245, rank: 842, score: 11.694951686996003\n",
            "docno: 7074106, rank: 843, score: 11.694951686996003\n",
            "docno: 7077869, rank: 844, score: 11.694951686996003\n",
            "docno: 7190093, rank: 845, score: 11.694951686996003\n",
            "docno: 7482512, rank: 846, score: 11.694951686996003\n",
            "docno: 7610536, rank: 847, score: 11.694951686996003\n",
            "docno: 8277922, rank: 848, score: 11.694951686996003\n",
            "docno: 8337907, rank: 849, score: 11.694951686996003\n",
            "docno: 8376664, rank: 850, score: 11.694951686996003\n",
            "docno: 8481210, rank: 851, score: 11.694951686996003\n",
            "docno: 8578082, rank: 852, score: 11.694951686996003\n",
            "docno: 221873, rank: 853, score: 11.692387063280048\n",
            "docno: 1964753, rank: 854, score: 11.692387063280048\n",
            "docno: 5305625, rank: 855, score: 11.692387063280048\n",
            "docno: 5536801, rank: 856, score: 11.692387063280048\n",
            "docno: 5584935, rank: 857, score: 11.692387063280048\n",
            "docno: 6424854, rank: 858, score: 11.692387063280048\n",
            "docno: 7064933, rank: 859, score: 11.692387063280048\n",
            "docno: 3535480, rank: 860, score: 11.691105173179292\n",
            "docno: 5783018, rank: 861, score: 11.691105173179292\n",
            "docno: 2661568, rank: 862, score: 11.673428311599329\n",
            "docno: 4246249, rank: 863, score: 11.673428311599329\n",
            "docno: 5560959, rank: 864, score: 11.673428311599329\n",
            "docno: 6020794, rank: 865, score: 11.673428311599329\n",
            "docno: 6249077, rank: 866, score: 11.673428311599329\n",
            "docno: 7077291, rank: 867, score: 11.673428311599329\n",
            "docno: 7919272, rank: 868, score: 11.673428311599329\n",
            "docno: 353453, rank: 869, score: 11.667904324924681\n",
            "docno: 537460, rank: 870, score: 11.667904324924681\n",
            "docno: 3479307, rank: 871, score: 11.667904324924681\n",
            "docno: 4481320, rank: 872, score: 11.667904324924681\n",
            "docno: 4936403, rank: 873, score: 11.667904324924681\n",
            "docno: 5734298, rank: 874, score: 11.667904324924681\n",
            "docno: 7961448, rank: 875, score: 11.667904324924681\n",
            "docno: 8480047, rank: 876, score: 11.667904324924681\n",
            "docno: 1033127, rank: 877, score: 11.664841127615958\n",
            "docno: 889189, rank: 878, score: 11.659249546236813\n",
            "docno: 30445, rank: 879, score: 11.655035331428978\n",
            "docno: 564228, rank: 880, score: 11.655035331428978\n",
            "docno: 668076, rank: 881, score: 11.655035331428978\n",
            "docno: 745638, rank: 882, score: 11.655035331428978\n",
            "docno: 783781, rank: 883, score: 11.655035331428978\n",
            "docno: 1061247, rank: 884, score: 11.655035331428978\n",
            "docno: 1940483, rank: 885, score: 11.655035331428978\n",
            "docno: 1951183, rank: 886, score: 11.655035331428978\n",
            "docno: 2019494, rank: 887, score: 11.655035331428978\n",
            "docno: 2108661, rank: 888, score: 11.655035331428978\n",
            "docno: 2676506, rank: 889, score: 11.655035331428978\n",
            "docno: 2733832, rank: 890, score: 11.655035331428978\n",
            "docno: 3101335, rank: 891, score: 11.655035331428978\n",
            "docno: 3320392, rank: 892, score: 11.655035331428978\n",
            "docno: 3387902, rank: 893, score: 11.655035331428978\n",
            "docno: 3649009, rank: 894, score: 11.655035331428978\n",
            "docno: 4192455, rank: 895, score: 11.655035331428978\n",
            "docno: 4296540, rank: 896, score: 11.655035331428978\n",
            "docno: 5224460, rank: 897, score: 11.655035331428978\n",
            "docno: 5456025, rank: 898, score: 11.655035331428978\n",
            "docno: 5707061, rank: 899, score: 11.655035331428978\n",
            "docno: 5745879, rank: 900, score: 11.655035331428978\n",
            "docno: 5762547, rank: 901, score: 11.655035331428978\n",
            "docno: 5870082, rank: 902, score: 11.655035331428978\n",
            "docno: 6113513, rank: 903, score: 11.655035331428978\n",
            "docno: 6192010, rank: 904, score: 11.655035331428978\n",
            "docno: 7109559, rank: 905, score: 11.655035331428978\n",
            "docno: 7125134, rank: 906, score: 11.655035331428978\n",
            "docno: 7132959, rank: 907, score: 11.655035331428978\n",
            "docno: 7685450, rank: 908, score: 11.655035331428978\n",
            "docno: 7707057, rank: 909, score: 11.655035331428978\n",
            "docno: 7857986, rank: 910, score: 11.655035331428978\n",
            "docno: 7865573, rank: 911, score: 11.655035331428978\n",
            "docno: 8313996, rank: 912, score: 11.655035331428978\n",
            "docno: 8567221, rank: 913, score: 11.655035331428978\n",
            "docno: 2292175, rank: 914, score: 11.649942147066806\n",
            "docno: 3707284, rank: 915, score: 11.649942147066806\n",
            "docno: 3802264, rank: 916, score: 11.649942147066806\n",
            "docno: 4522658, rank: 917, score: 11.649942147066806\n",
            "docno: 5228544, rank: 918, score: 11.649942147066806\n",
            "docno: 6513329, rank: 919, score: 11.649942147066806\n",
            "docno: 7077292, rank: 920, score: 11.649942147066806\n",
            "docno: 7077297, rank: 921, score: 11.649942147066806\n",
            "docno: 7648904, rank: 922, score: 11.649942147066806\n",
            "docno: 903447, rank: 923, score: 11.6371458423151\n",
            "docno: 1818466, rank: 924, score: 11.6371458423151\n",
            "docno: 2200679, rank: 925, score: 11.6371458423151\n",
            "docno: 394313, rank: 926, score: 11.63137185738527\n",
            "docno: 472209, rank: 927, score: 11.63137185738527\n",
            "docno: 493402, rank: 928, score: 11.63137185738527\n",
            "docno: 638680, rank: 929, score: 11.63137185738527\n",
            "docno: 972034, rank: 930, score: 11.63137185738527\n",
            "docno: 976097, rank: 931, score: 11.63137185738527\n",
            "docno: 990209, rank: 932, score: 11.63137185738527\n",
            "docno: 1015986, rank: 933, score: 11.63137185738527\n",
            "docno: 1160147, rank: 934, score: 11.63137185738527\n",
            "docno: 1259049, rank: 935, score: 11.63137185738527\n",
            "docno: 1274475, rank: 936, score: 11.63137185738527\n",
            "docno: 1363633, rank: 937, score: 11.63137185738527\n",
            "docno: 1603949, rank: 938, score: 11.63137185738527\n",
            "docno: 1613751, rank: 939, score: 11.63137185738527\n",
            "docno: 3529368, rank: 940, score: 11.63137185738527\n",
            "docno: 3972155, rank: 941, score: 11.63137185738527\n",
            "docno: 4487714, rank: 942, score: 11.63137185738527\n",
            "docno: 4787285, rank: 943, score: 11.63137185738527\n",
            "docno: 4888677, rank: 944, score: 11.63137185738527\n",
            "docno: 4938782, rank: 945, score: 11.63137185738527\n",
            "docno: 5556272, rank: 946, score: 11.63137185738527\n",
            "docno: 5601799, rank: 947, score: 11.63137185738527\n",
            "docno: 5689573, rank: 948, score: 11.63137185738527\n",
            "docno: 5852871, rank: 949, score: 11.63137185738527\n",
            "docno: 5899037, rank: 950, score: 11.63137185738527\n",
            "docno: 5940223, rank: 951, score: 11.63137185738527\n",
            "docno: 6613553, rank: 952, score: 11.63137185738527\n",
            "docno: 6634319, rank: 953, score: 11.63137185738527\n",
            "docno: 6753195, rank: 954, score: 11.63137185738527\n",
            "docno: 6765557, rank: 955, score: 11.63137185738527\n",
            "docno: 6961192, rank: 956, score: 11.63137185738527\n",
            "docno: 7033780, rank: 957, score: 11.63137185738527\n",
            "docno: 7125086, rank: 958, score: 11.63137185738527\n",
            "docno: 7158803, rank: 959, score: 11.63137185738527\n",
            "docno: 7207803, rank: 960, score: 11.63137185738527\n",
            "docno: 7381859, rank: 961, score: 11.63137185738527\n",
            "docno: 7388394, rank: 962, score: 11.63137185738527\n",
            "docno: 7549486, rank: 963, score: 11.63137185738527\n",
            "docno: 7551106, rank: 964, score: 11.63137185738527\n",
            "docno: 7552886, rank: 965, score: 11.63137185738527\n",
            "docno: 7552887, rank: 966, score: 11.63137185738527\n",
            "docno: 7586154, rank: 967, score: 11.63137185738527\n",
            "docno: 7747383, rank: 968, score: 11.63137185738527\n",
            "docno: 8011290, rank: 969, score: 11.63137185738527\n",
            "docno: 8171151, rank: 970, score: 11.63137185738527\n",
            "docno: 8241936, rank: 971, score: 11.63137185738527\n",
            "docno: 8307116, rank: 972, score: 11.63137185738527\n",
            "docno: 8376567, rank: 973, score: 11.63137185738527\n",
            "docno: 8398473, rank: 974, score: 11.63137185738527\n",
            "docno: 8574629, rank: 975, score: 11.63137185738527\n",
            "docno: 8587743, rank: 976, score: 11.63137185738527\n",
            "docno: 8677944, rank: 977, score: 11.63137185738527\n",
            "docno: 6890316, rank: 978, score: 11.627567046371222\n",
            "docno: 511761, rank: 979, score: 11.617219839532956\n",
            "docno: 2510857, rank: 980, score: 11.617219839532956\n",
            "docno: 3035431, rank: 981, score: 11.617219839532956\n",
            "docno: 3245004, rank: 982, score: 11.617219839532956\n",
            "docno: 3501746, rank: 983, score: 11.617219839532956\n",
            "docno: 3568085, rank: 984, score: 11.617219839532956\n",
            "docno: 3746098, rank: 985, score: 11.617219839532956\n",
            "docno: 4679234, rank: 986, score: 11.617219839532956\n",
            "docno: 4821123, rank: 987, score: 11.617219839532956\n",
            "docno: 4938783, rank: 988, score: 11.617219839532956\n",
            "docno: 5246902, rank: 989, score: 11.617219839532956\n",
            "docno: 5884163, rank: 990, score: 11.617219839532956\n",
            "docno: 6878046, rank: 991, score: 11.617219839532956\n",
            "docno: 8489498, rank: 992, score: 11.617219839532956\n",
            "docno: 355219, rank: 993, score: 11.607804277586826\n",
            "docno: 584839, rank: 994, score: 11.607804277586826\n",
            "docno: 1750374, rank: 995, score: 11.607804277586826\n",
            "docno: 3041193, rank: 996, score: 11.607804277586826\n",
            "docno: 4899181, rank: 997, score: 11.607804277586826\n",
            "docno: 4959991, rank: 998, score: 11.607804277586826\n",
            "docno: 5376302, rank: 999, score: 11.607804277586826\n"
          ]
        }
      ],
      "source": [
        "# Load the index object from the reference.\n",
        "index = pt.IndexFactory.of(indexref)\n",
        "\n",
        "# Display collection statistics (e.g., number of documents, average length).\n",
        "print(index.getCollectionStatistics())\n",
        "\n",
        "# Initialize a Retriever with the BM25 weighting model.\n",
        "br = pt.terrier.Retriever(index, wmodel=\"BM25\")\n",
        "\n",
        "# Perform a search for the query \"document\".\n",
        "k = br.search(\"document\")\n",
        "\n",
        "# Print details of the top-ranked document:\n",
        "print(k[\"docno\"][0])   # Document ID of the first result\n",
        "print(k[\"rank\"][0])    # Rank position of the first result\n",
        "print(k[\"score\"][0])   # BM25 score of the first result\n",
        "\n",
        "\n",
        "# Use itertuples to iterate over the search results DataFrame.\n",
        "# Each row contains (docno, rank, score) for a retrieved document.\n",
        "for row in k.itertuples(index=True, name=\"Result\"):\n",
        "    docno, rank, score = row.docno, row.rank, row.score\n",
        "    print(f\"docno: {docno}, rank: {rank}, score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-iQAJzBmHoV"
      },
      "source": [
        "### Creating PyTerrier Run File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4t1sU16vwfR"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9IH6pN968_B"
      },
      "source": [
        "These are the same helper functions we used earlier, included here again to avoid having to scroll back and forth.\n",
        "The second function has been slightly adapted to use a PyTerrier retriever instead of the custom InvertedIndex class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW2FeN0Hr-jn"
      },
      "outputs": [],
      "source": [
        "# TODO: queste funzioni sono ridefiniteeeee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZh3SPb0vjRg"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def extract_queries(\n",
        "    filename: str\n",
        ") -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Reads a TSV file containing query IDs and query texts,\n",
        "        and returns them as a list of (query_id, query) tuples.\n",
        "\n",
        "    Arguments:\n",
        "        filename (str): Path to the TSV file.\n",
        "          Each line should contain 'query_id<TAB>query_text'.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list where each element is a tuple\n",
        "          containing (query_id, query_text).\n",
        "    \"\"\"\n",
        "    queries: List[Tuple[str, str]] = []\n",
        "\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "\n",
        "            # Skipping malformed lines\n",
        "            try:\n",
        "                query_id, query = line.strip().split(\"\\t\")\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            # Appending query_id and query text\n",
        "            queries.append((query_id, query))\n",
        "\n",
        "    return queries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnDnRLL9v3Fd"
      },
      "outputs": [],
      "source": [
        "def write_run_file(\n",
        "    queries: list[tuple[str, str]],\n",
        "    retriever: pt.terrier.Retriever,\n",
        "    output_path: str,\n",
        "    run_name: str = \"my_run\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Generates a TREC-formatted run file from a set of queries and the inverted index.\n",
        "\n",
        "    Arguments:\n",
        "        queries (Dict[int, str]): Mapping from query IDs to query strings.\n",
        "        index (InvertedIndex): The inverted index used for retrieval.\n",
        "        output_path (str): Path to save the output run file.\n",
        "        run_name (str): Identifier for the run (appears in the last column).\n",
        "    \"\"\"\n",
        "\n",
        "    with open(output_path, \"w\") as f:\n",
        "        for qid, query in queries:\n",
        "\n",
        "            # List of scores and docids ordered by score\n",
        "            try:\n",
        "                results: list[tuple[np.float64, np.int32]] = retriever.search(query)\n",
        "            except:\n",
        "                print(query)\n",
        "\n",
        "\n",
        "            # Iterating over results and adding line\n",
        "            for row in results.itertuples(index=True):\n",
        "                docno, rank, score = row.docno, row.rank, row.score\n",
        "                f.write(f\"{qid} Q0 {docno} {rank} {score:.6f} {run_name}\\n\")\n",
        "\n",
        "    print(f\"Run file saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE3cA00Bz-Zo"
      },
      "source": [
        "#### Creating Run File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySnufY5b8G42"
      },
      "source": [
        "This code reads the MS MARCO 2020 test queries from a TSV file, then uses a PyTerrier BM25 retriever to process each query. For each query, it retrieves documents, computes their scores, and writes the results in a TREC-formatted run file. The run file includes the query ID, document ID, rank, score, and run name, making it ready for evaluation with standard IR tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6nva_7mz5tu",
        "outputId": "6ee3833d-0d39-456b-885e-e3c9268b213f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "define: geon\n",
            "Run file saved to: pyterrier_bm25_run.txt\n",
            "Run file 'pyterrier_bm25_run.txt' successfully created using PyTerrier BM25 retriever.\n"
          ]
        }
      ],
      "source": [
        "# Path to the MS MARCO 2020 test queries file (TSV format: query_id<TAB>query_text)\n",
        "queries_file = \"msmarco-test2020-queries.tsv\"\n",
        "\n",
        "# Name of this retrieval run (appears in the TREC run file)\n",
        "run_name = \"pyterrier_bm25_run\"\n",
        "\n",
        "# Output filename for the TREC-formatted run\n",
        "run_file = run_name + \".txt\"\n",
        "\n",
        "# Read queries from the TSV file and store as a list of tuples: (query_id, query_text)\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "# Using the PyTerrier BM25 retriever (`br`) to process each query,\n",
        "# compute scores for retrieved documents, and write results to a run file\n",
        "write_run_file(\n",
        "    queries,    # list of (query_id, query_text) tuples\n",
        "    br,         # PyTerrier retrieval object (BM25)\n",
        "    run_file,   # output filename for the run file\n",
        "    run_name    # run identifier to appear in the last column of the run file\n",
        ")\n",
        "\n",
        "print(f\"Run file '{run_file}' successfully created using PyTerrier BM25 retriever.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SixHNf2jmKJZ"
      },
      "source": [
        "### Statistical Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sa_NZl_9T5J"
      },
      "source": [
        "These two code blocks perform a comparative evaluation between a PyTerrier BM25 run and a custom BM25 run. First, the TREC-formatted run files and ground truth relevance judgments are read, and per-query evaluation metrics Mean Average Precision (MAP), nDCG@10, and MRR@10 are computed for both runs. Then, paired t-tests are applied to these per-query scores to determine whether there are statistically significant differences between the two systems for each metric. The resulting t-statistics indicate the direction of the difference, while the p-values indicate the significance of the observed differences, allowing a quantitative comparison of retrieval effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIcpD_ou1eWe"
      },
      "outputs": [],
      "source": [
        "# Qrels (ground truth relevance judgments)\n",
        "qrels_file = '2020qrels-pass.txt'\n",
        "\n",
        "# TREC-formatted run file generated by PyTerrier BM25\n",
        "pt_run_file = 'pyterrier_bm25_run.txt'\n",
        "\n",
        "# Custom run file generated using our own BM25 implementation\n",
        "my_run_file = 'bm25_test_run'\n",
        "\n",
        "# Read qrels into a list of relevance judgments and read the runs into\n",
        "# lists of run entries\n",
        "qrel = list(ir_measures.read_trec_qrels(qrels_file))\n",
        "pt_run_data = list(ir_measures.read_trec_run(pt_run_file))\n",
        "my_run_data = list(ir_measures.read_trec_run(my_run_file))\n",
        "\n",
        "# Mean Average Precision (MAP), nDCG and MRR for PyTerrier Run\n",
        "pt_MAP = tuple(m.value for m in ir_measures.iter_calc([AP], qrel, pt_run_data))\n",
        "pt_nDCG = tuple(m.value for m in ir_measures.iter_calc([nDCG@10], qrel, pt_run_data))\n",
        "pt_MRR = tuple(m.value for m in ir_measures.iter_calc([MRR@10], qrel, pt_run_data))\n",
        "\n",
        "# Mean Average Precision (MAP), nDCG and MRR for Custom Run\n",
        "my_MAP = tuple(m.value for m in ir_measures.iter_calc([AP], qrel, my_run_data))\n",
        "my_nDCG = tuple(m.value for m in ir_measures.iter_calc([nDCG@10], qrel, my_run_data))\n",
        "my_MRR = tuple(m.value for m in ir_measures.iter_calc([MRR@10], qrel, my_run_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WLPqokY4w6i",
        "outputId": "414b374a-415a-4720-e453-e8caaee9cbeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: t_stat = -1.761199, p_value = 0.083973\n",
            "nDCG@10: t_stat = -1.925950, p_value = 0.059482\n",
            "MRR@10: t_stat = -0.897236, p_value = 0.373651\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# ---------------------- Paired t-tests Between PyTerrier and Custom Runs ---------------------- #\n",
        "\n",
        "# Paired t-test for Mean Average Precision (MAP)\n",
        "# Compares per-query MAP scores between the two runs\n",
        "t_stat, p_val = ttest_rel(pt_MAP, my_MAP)\n",
        "print(f\"MAP: t_stat = {t_stat:.6f}, p_value = {p_val:.6f}\")\n",
        "\n",
        "# Paired t-test for nDCG@10\n",
        "# Compares per-query nDCG@10 scores between the two runs\n",
        "t_stat, p_val = ttest_rel(pt_nDCG, my_nDCG)\n",
        "print(f\"nDCG@10: t_stat = {t_stat:.6f}, p_value = {p_val:.6f}\")\n",
        "\n",
        "# Paired t-test for MRR@10\n",
        "# Compares per-query MRR@10 scores between the two runs\n",
        "t_stat, p_val = ttest_rel(pt_MRR, my_MRR)\n",
        "print(f\"MRR@10: t_stat = {t_stat:.6f}, p_value = {p_val:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2zGirQAaVNR"
      },
      "source": [
        "| Metric   | t-stat     | p-value   |\n",
        "|----------|------------|-----------|\n",
        "| MAP      | -1.761199  | 0.083973  |\n",
        "| nDCG@10  | -1.925950  | 0.059482  |\n",
        "| MRR@10   | -0.897236  | 0.373651  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuTuB0gdZpjp"
      },
      "source": [
        "Our BM25 model shows slightly higher performance across the three evaluation metrics. However, the p-values indicate that these improvements are not statistically significant. This outcome is expected, since our BM25 model was tuned on a separate evaluation set, which naturally leads to marginally better scores. Nevertheless, the default parameters provided by PyTerrier do not yield results that are statistically inferior, highlighting that the observed differences are not meaningful in a rigorous statistical sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baNUKhGj9Z8f"
      },
      "source": [
        "## Space and Time Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JamvLs__9tVT"
      },
      "source": [
        "### Pre-Computed Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX96IcAEiTQC"
      },
      "source": [
        "#### Pre-Computing Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpF4SHsWlMEi"
      },
      "source": [
        "This block of code precomputes BM25 weights for every term–document pair in the inverted index, replacing raw term frequencies with their BM25-weighted equivalents. For each term, it retrieves key statistics such as document frequency, total number of documents, and document length, then applies the BM25 formula that combines an inverse document frequency (IDF) component and a term frequency (TF) component normalized by document length. The constants k₁ and b control term frequency saturation and document length normalization, respectively. By storing the computed BM25 weights directly into the posting lists (inv_f), the retrieval process becomes more efficient since scoring computations are effectively done in advance.\n",
        "\n",
        "We multiply the scores by 1000 because their absolute values are quite small, and ranking decisions often depend on the digits immediately after the decimal point. By scaling the scores, we preserve the first three decimal places, ensuring that subtle differences between documents are retained. At the same time, multiplying by 1000 avoids the risk of numerical overflow, making the ranking process both precise and safe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iddspiiNBgCa"
      },
      "outputs": [],
      "source": [
        "# Creating a mapping from termid to term, implemented with a list\n",
        "termid_to_term = [ term for term, _ in lexicon.items() ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHHlXHL1_61Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# This block modifies the posting list frequencies (inv_f) by replacing\n",
        "# raw term frequencies (TF) with their precomputed BM25-weighted values.\n",
        "# Doing this in advance can save computation time at query time.\n",
        "\n",
        "# BM25 hyperparameters (standard values)\n",
        "b = 0.65\n",
        "k1 = 1\n",
        "\n",
        "# Computing scaling factor on the basis of how many decimal places we\n",
        "# want to keep in our precomputed weights\n",
        "decimal_place = 3\n",
        "scaling_factor = 10 ** decimal_place\n",
        "# TODO: vuol dire che facciamo anche quantizzazione? non c'è scritto sul commento sopra\n",
        "\n",
        "# Iterate over each term in the inverted index\n",
        "for termid in inv_f:\n",
        "\n",
        "    # For each occurrence of the term, get its term frequency (tf) and document ID (docid)\n",
        "    for i, (tf, docid) in enumerate(zip(inv_f[termid], inv_d[termid])):\n",
        "\n",
        "        #  Retrieving Required Statistics\n",
        "        N = stats['num_docs']\n",
        "        term = termid_to_term[termid]  # TODO: perchè non lo facciamo normalmente con il lexicon? se teniamo questo portare la lista dentro la cella\n",
        "        df = lexicon[term][1]\n",
        "\n",
        "        # Computing BM1 component\n",
        "        bm1 = np.log((N - df + 0.5) / (df + 0.5))\n",
        "\n",
        "        # Get the document length and the average document length\n",
        "        dl = doc_index[docid - 1][1]\n",
        "        avg_dl = stats['average_document_length']\n",
        "\n",
        "        # Compute the normalization factor for document length\n",
        "        # This adjusts TF based on how long the document is compared to the average.\n",
        "        norm_factor = (1 - b) + b * (dl / avg_dl)\n",
        "\n",
        "        # Apply document length normalization to TF\n",
        "        tf_tilde = tf / norm_factor\n",
        "\n",
        "        # Compute the BM25 TF scaling: (tf_tilde) / (k1 + tf_tilde)\n",
        "        tf_approx = tf_tilde / (k1 + tf_tilde)\n",
        "\n",
        "        # Combine IDF and TF components to get the full BM25 weight\n",
        "        bm25 = bm1 * tf_approx\n",
        "\n",
        "        # Replace the original term frequency with the BM25 weight\n",
        "        # This stores the weighted value directly in the inverted index for efficiency.\n",
        "        inv_f[termid][i] = scaling_factor * bm25\n",
        "        # TODO: ma non è quantizzato? a che serve scalarlo? è perchè l'np.array è già int32?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knBYDPILzwWC"
      },
      "source": [
        "#### Optimized DAAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAZYOS7v3gIE"
      },
      "source": [
        "The main optimization made are:\n",
        "1. **Efficient min_docid Computation**: The min_docid function uses a list comprehension combined with Python's built-in min() to quickly identify the smallest document ID among active posting lists. This avoids unnecessary loops and provides a modest performance boost by leveraging optimized native operations.\n",
        "2. **An efficient pruning mechanism** that identifies exhausted posting lists using a boolean flag. Once flagged, it employs a Python list comprehension to swiftly remove these inactive iterators, ensuring that subsequent iterations only process active postings and thereby improving performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi931GHmz1GI"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List, Set, Tuple\n",
        "import numba\n",
        "import heapq\n",
        "\n",
        "\n",
        "# TODO: stai dicendo che computare il min_docid in questo modo è meglio rispetto a prima?\n",
        "def min_docid(\n",
        "    postings: List['InvertedIndex.PostingListIterator']\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Returns the smallest current docid among all posting list iterators.\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "    Returns:\n",
        "        int: Minimum current docid, or math.inf if all postings are exhausted.\n",
        "    \"\"\"\n",
        "\n",
        "    # I am simply compressing the operation using list comprehension\n",
        "    return min([p.docid() for p in postings if not p._is_end_list()])\n",
        "\n",
        "\n",
        "@profile\n",
        "def daat(\n",
        "    postings: List['InvertedIndex.PostingListIterator'],\n",
        "    k: int = 10\n",
        ") -> List[Tuple[float, int]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Computes document-at-a-time (DAAT) scoring for a list of posting lists.\n",
        "        Scores each document across all postings simultaneously and returns\n",
        "        the top-k documents.\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "        k (int): Number of top-scoring documents to return. Default is 10.\n",
        "    Returns:\n",
        "        List[Tuple[float, int]]: List of (score, docid) tuples, sorted in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    top = TopQueue(k)\n",
        "\n",
        "    # Initialize current_docid as the smallest docid among all postings\n",
        "    current_docid = min_docid(postings)\n",
        "\n",
        "    # Until you have finished all the posting lists you compute the score\n",
        "    # for the next document\n",
        "    while current_docid != math.inf:\n",
        "\n",
        "        # I have only added the updated variable as it will be used to remove\n",
        "        # useless posting lists (posting lists that have been completed)\n",
        "        score = 0.0                 # Score of the Document\n",
        "        next_docid = math.inf       # Docid that will be evaluated on the next iter\n",
        "        update = False              # It's set to true when some posting have been finished\n",
        "\n",
        "        # Iterate over each posting head\n",
        "        for posting in postings:\n",
        "\n",
        "            # Extract docid\n",
        "            docid = posting.docid()\n",
        "\n",
        "            # If it matches current doc then update the score and advance on the\n",
        "            # posting list\n",
        "            if docid == current_docid:\n",
        "                score += posting.score()\n",
        "                posting.next()\n",
        "                docid = posting.docid()  # update after advancing\n",
        "\n",
        "            # If the posting list is not ended then consider the docid head as\n",
        "            # a candidate for the next docid\n",
        "            if not posting._is_end_list():\n",
        "                next_docid = min(next_docid, docid)\n",
        "\n",
        "            # Otherwise set update to true so it will be pruned\n",
        "            else:\n",
        "                update = True\n",
        "\n",
        "        # Pruning useless Posting lists\n",
        "        if update:\n",
        "            postings = [p for p in postings if not p._is_end_list()]\n",
        "\n",
        "        # Inserting in top queue and updating current docid\n",
        "        top.insert(current_docid, score) # type: ignore\n",
        "        current_docid = next_docid\n",
        "\n",
        "    # Return top-k results sorted by score descending\n",
        "    return sorted(top.queue, reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Djk6zUz5uA4"
      },
      "source": [
        "Converting NumPy arrays to native Python lists improves the performance of the daat function in this context because the function relies heavily on control flow, dynamic indexing, and method calls on custom iterator objects. While NumPy excels at vectorized numerical operations, it introduces overhead when used for frequent element-wise access or conditional logic inside Python loops. By switching to Python lists, we reduce the cost of array conversion and gain faster iteration and indexing, making the DAAT traversal more efficient for this workload.\n",
        "\n",
        "I attempted to optimize the daat function using NumPy vectorized operations, but the performance gains were limited."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K0xwzID6OTq"
      },
      "outputs": [],
      "source": [
        "# TODO: cosa migliora esattamente? list comprehension? identificare le istruzioni esatte\n",
        "\n",
        "for term_id in inv_f:\n",
        "  inv_f[term_id] = inv_f[term_id].tolist()\n",
        "\n",
        "for term_id in inv_d:\n",
        "  inv_d[term_id] = inv_d[term_id].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPPvnBihPemf"
      },
      "source": [
        "I copied the TopQueue class so that all required classes are located together for easier access. In addition, I made a small adjustment to the inverted index scoring function: the check for reaching the end of the posting list has been removed. This simplification is safe because we can assume that the method will only be called when the posting list is not yet exhausted, as the daat method already performs that validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAebKkaWPemf"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "from typing import List, Tuple\n",
        "\n",
        "# TODO io toglierei se è duplicato\n",
        "\n",
        "class TopQueue:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Maintains the top-k scored items in a min-heap with a dynamic threshold.\n",
        "    Arguments:\n",
        "        k (int): Maximum number of items to keep. Default is 10.\n",
        "        threshold (float): Minimum score required for an item to enter. Default is 0.0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k: int = 10, threshold: float = 0.0):\n",
        "        self.queue: List[Tuple[float, int]] = []  # heap of (score, docid)\n",
        "        self.k: int = k\n",
        "        self.threshold: float = threshold\n",
        "\n",
        "    def size(self) -> int:\n",
        "        \"\"\"Returns the number of items currently in the queue.\"\"\"\n",
        "        return len(self.queue)\n",
        "\n",
        "    def would_enter(self, score: float) -> bool:\n",
        "        \"\"\"\n",
        "        Checks if a given score is high enough to enter the queue.\n",
        "        Arguments:\n",
        "            score (float): Score to test.\n",
        "        Returns:\n",
        "            bool: True if score exceeds current threshold.\n",
        "        \"\"\"\n",
        "        return score > self.threshold\n",
        "\n",
        "    def clear(self, new_threshold: float = None):\n",
        "        \"\"\"\n",
        "        Clears the queue.\n",
        "        Arguments:\n",
        "            new_threshold (float, optional): If provided, updates the threshold.\n",
        "        \"\"\"\n",
        "        self.queue = []\n",
        "        if new_threshold is not None:\n",
        "            self.threshold = new_threshold\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f'<TopQueue: {self.size()} items, th={self.threshold}, {self.queue}>'\n",
        "\n",
        "    def insert(self, docid: int, score: float) -> bool:\n",
        "        \"\"\"\n",
        "        Inserts a document with its score into the top-k queue if it exceeds the threshold.\n",
        "        Arguments:\n",
        "            docid (int): Document ID.\n",
        "            score (float): Score of the document.\n",
        "        Returns:\n",
        "            bool: True if the item was inserted, False otherwise.\n",
        "        \"\"\"\n",
        "        if score > self.threshold:\n",
        "            if self.size() >= self.k:\n",
        "                # Replace the smallest element if heap is full\n",
        "                heapq.heapreplace(self.queue, (score, docid))\n",
        "            else:\n",
        "                heapq.heappush(self.queue, (score, docid))\n",
        "\n",
        "            # Update threshold to the smallest score in the heap if full\n",
        "            if self.size() >= self.k:\n",
        "                self.threshold = max(self.threshold, self.queue[0][0])\n",
        "            return True\n",
        "\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4aBPgM5Pemf"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Callable, Optional\n",
        "\n",
        "# TODO: toglierei pure questo\n",
        "\n",
        "class InvertedIndex:\n",
        "\n",
        "    class PostingListIterator:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Iterator over a posting list for a single term in the inverted index.\n",
        "        Arguments:\n",
        "            docids (np.ndarray): Array of document IDs containing the term.\n",
        "            freqs (np.ndarray): Array of term frequencies corresponding to docids.\n",
        "            doc (Dict[int, Tuple]): Dictionary storing document statistics (e.g., length).\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(\n",
        "            self,\n",
        "            docids: np.ndarray,\n",
        "            freqs: np.ndarray,\n",
        "            termid: int,\n",
        "            token: str,\n",
        "            lexicon: Dict[str, Tuple],\n",
        "            doc: Dict[int, Tuple],\n",
        "            stats: Dict[str, int],\n",
        "            scorer: Callable[['InvertedIndex.PostingListIterator'], float]\n",
        "        ):\n",
        "            self.docids = docids\n",
        "            self.freqs = freqs\n",
        "            self.pos = 0\n",
        "            self.termid = termid\n",
        "            self.token = token\n",
        "            self.lexicon = lexicon\n",
        "            self.doc = doc\n",
        "            self.stats = stats\n",
        "            self._scorer = scorer\n",
        "\n",
        "        def docid(self) -> int:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the current document ID.\n",
        "            Returns:\n",
        "                int: Current document ID, or math.inf if iterator is at the end.\n",
        "            \"\"\"\n",
        "            return math.inf if self._is_end_list() else self.docids[self.pos]\n",
        "\n",
        "        def score(self) -> float:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Computes the score for the current document, which is constant\n",
        "                for every document in the same posting\n",
        "            Returns:\n",
        "                float: Score for the current document, or math.inf if iterator is at the end.\n",
        "            \"\"\"\n",
        "            return self._scorer(self)\n",
        "\n",
        "        def next(self, target: Optional[int] = None):\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Advances the iterator. If target is provided, jump to the first document\n",
        "                with ID >= target.\n",
        "            Arguments:\n",
        "                target (Optional[int]): Target document ID to skip to. Default is None.\n",
        "            \"\"\"\n",
        "            if target is None:\n",
        "                if not self._is_end_list():\n",
        "                    self.pos += 1\n",
        "            elif target > self.docid():\n",
        "                self.pos = np.searchsorted(self.docids, target, side='left')\n",
        "\n",
        "        def len(self) -> int:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the number of documents in the posting list.\n",
        "            Returns:\n",
        "                int: Length of the posting list.\n",
        "            \"\"\"\n",
        "            return len(self.docids)\n",
        "\n",
        "        def _is_end_list(self) -> bool:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Checks whether the iterator has reached the end of the posting list.\n",
        "            Returns:\n",
        "                bool: True if at end, False otherwise.\n",
        "            \"\"\"\n",
        "            return self.pos >= len(self.docids)\n",
        "\n",
        "    # ----------------- InvertedIndex main ----------------- #\n",
        "\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Inverted index storing the mapping from terms to posting lists, along with\n",
        "        document statistics.\n",
        "    Arguments:\n",
        "        lexicon (Dict[str, Tuple[int, ...]]): Maps token to (termid, ...).\n",
        "        inv_d (List[np.ndarray]): List of arrays of document IDs per term.\n",
        "        inv_f (List[np.ndarray]): List of arrays of term frequencies per term.\n",
        "        doc (Dict[int, Tuple]): Document statistics dictionary.\n",
        "        stats (Dict[str, int]): Global statistics like number of documents.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        lexicon: Dict[str, Tuple[int, ...]],\n",
        "        inv_d: List[np.ndarray],\n",
        "        inv_f: List[np.ndarray],\n",
        "        doc: Dict[int, Tuple],\n",
        "        stats: Dict[str, int],\n",
        "        scorer: Callable[['InvertedIndex.PostingListIterator'], float]\n",
        "    ):\n",
        "        self.lexicon = lexicon\n",
        "        self.inv_d = inv_d\n",
        "        self.inv_f = inv_f\n",
        "        self.doc = doc\n",
        "        self.stats = stats\n",
        "        self.scorer = scorer\n",
        "\n",
        "    def num_docs(self) -> int:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns the total number of documents in the index.\n",
        "        Returns:\n",
        "            int: Number of documents.\n",
        "        \"\"\"\n",
        "        return self.stats['num_docs']\n",
        "\n",
        "    def get_posting(self, termid: int, term: str) -> 'PostingListIterator':\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a PostingListIterator for a given term ID.\n",
        "        Arguments:\n",
        "            termid (int): The term ID to retrieve the posting list for.\n",
        "        Returns:\n",
        "            PostingListIterator: Iterator over the posting list.\n",
        "        \"\"\"\n",
        "        return InvertedIndex.PostingListIterator(\n",
        "            self.inv_d[termid],\n",
        "            self.inv_f[termid],\n",
        "            termid,\n",
        "            term,\n",
        "            self.lexicon,\n",
        "            self.doc,\n",
        "            self.stats,\n",
        "            self.scorer\n",
        "        )\n",
        "\n",
        "    def get_termids(self, tokens: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of term IDs for the tokens that exist in the lexicon.\n",
        "        Arguments:\n",
        "            tokens (List[str]): List of tokens to look up.\n",
        "        Returns:\n",
        "            List[int]: List of corresponding term IDs.\n",
        "        \"\"\"\n",
        "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
        "\n",
        "    def get_postings(\n",
        "        self,\n",
        "        termids: List[int],\n",
        "        terms: List[str]\n",
        "    ) -> List['PostingListIterator']:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of PostingListIterators for a list of term IDs.\n",
        "        Arguments:\n",
        "            termids (List[int]): List of term IDs.\n",
        "        Returns:\n",
        "            List[PostingListIterator]: List of posting list iterators.\n",
        "        \"\"\"\n",
        "        return [self.get_posting(termid, term) for termid, term in zip(termids, terms)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdz61Dw7iV-A"
      },
      "source": [
        "#### Creating the Run File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLl3KUoZlywU"
      },
      "source": [
        "This block of code runs an information retrieval experiment using precomputed BM25 weights. It first loads the test queries from the MS MARCO 2019 dataset and initializes an InvertedIndex object with a special PreComputedScorer, which retrieves document scores directly from pre-stored BM25 weights rather than recalculating them at query time. This makes retrieval faster and more efficient. Finally, it processes all queries, ranks documents using the precomputed scores, and writes the results into a TREC-formatted run file named precomputed_bm25_run.txt, which can be later used for evaluation and comparison against other retrieval runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL-MKf3BWRek"
      },
      "outputs": [],
      "source": [
        "class PreComputedScorer:\n",
        "    \"\"\"\n",
        "    Using Precomputed Score\n",
        "    Arguments:\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        posting: 'InvertedIndex.PostingListIterator'\n",
        "    ) -> int:\n",
        "\n",
        "        # Returning precomputed score\n",
        "        return posting.freqs[posting.pos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwolIlRTYBbi",
        "outputId": "d2e0e9ed-9d86-4cfb-fd3f-c98e93752811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "daat (0.867 ms)\n",
            "daat (15.580 ms)\n",
            "daat (151.159 ms)\n",
            "daat (43.116 ms)\n",
            "daat (2480.398 ms)\n",
            "daat (103.583 ms)\n",
            "daat (497.643 ms)\n",
            "daat (47.770 ms)\n",
            "daat (515.802 ms)\n",
            "daat (84.577 ms)\n",
            "daat (16.465 ms)\n",
            "daat (164.247 ms)\n",
            "daat (899.553 ms)\n",
            "daat (78.706 ms)\n",
            "daat (306.279 ms)\n",
            "daat (520.885 ms)\n",
            "daat (231.866 ms)\n",
            "daat (959.585 ms)\n",
            "daat (1401.083 ms)\n",
            "daat (79.005 ms)\n",
            "daat (119.663 ms)\n",
            "daat (1130.219 ms)\n",
            "daat (1664.289 ms)\n",
            "daat (301.268 ms)\n",
            "daat (59.358 ms)\n",
            "daat (236.207 ms)\n",
            "daat (148.535 ms)\n",
            "daat (8.348 ms)\n",
            "daat (247.914 ms)\n",
            "daat (429.762 ms)\n",
            "daat (106.480 ms)\n",
            "daat (990.716 ms)\n",
            "daat (190.345 ms)\n",
            "daat (163.360 ms)\n",
            "daat (4.572 ms)\n",
            "daat (137.046 ms)\n",
            "daat (679.724 ms)\n",
            "daat (514.930 ms)\n",
            "daat (307.326 ms)\n",
            "daat (417.087 ms)\n",
            "daat (277.322 ms)\n",
            "daat (350.286 ms)\n",
            "daat (363.892 ms)\n",
            "daat (303.242 ms)\n",
            "daat (1258.284 ms)\n",
            "daat (165.884 ms)\n",
            "daat (210.074 ms)\n",
            "daat (1546.358 ms)\n",
            "daat (508.432 ms)\n",
            "daat (358.212 ms)\n",
            "daat (936.248 ms)\n",
            "daat (161.600 ms)\n",
            "daat (154.066 ms)\n",
            "daat (755.840 ms)\n",
            "daat (143.595 ms)\n",
            "daat (291.538 ms)\n",
            "daat (284.208 ms)\n",
            "daat (69.447 ms)\n",
            "daat (97.191 ms)\n",
            "daat (224.509 ms)\n",
            "daat (865.867 ms)\n",
            "daat (2679.097 ms)\n",
            "daat (624.237 ms)\n",
            "daat (953.362 ms)\n",
            "daat (676.051 ms)\n",
            "daat (842.747 ms)\n",
            "daat (429.784 ms)\n",
            "daat (366.565 ms)\n",
            "daat (647.274 ms)\n",
            "daat (508.452 ms)\n",
            "daat (359.095 ms)\n",
            "daat (98.119 ms)\n",
            "daat (179.823 ms)\n",
            "daat (223.030 ms)\n",
            "daat (440.633 ms)\n",
            "daat (155.951 ms)\n",
            "daat (1687.693 ms)\n",
            "daat (225.615 ms)\n",
            "daat (282.358 ms)\n",
            "daat (239.728 ms)\n",
            "daat (214.942 ms)\n",
            "daat (407.710 ms)\n",
            "daat (1142.347 ms)\n",
            "daat (6.920 ms)\n",
            "daat (1024.024 ms)\n",
            "daat (308.337 ms)\n",
            "daat (79.657 ms)\n",
            "daat (81.193 ms)\n",
            "daat (201.115 ms)\n",
            "daat (154.176 ms)\n",
            "daat (1796.971 ms)\n",
            "daat (226.457 ms)\n",
            "daat (184.953 ms)\n",
            "daat (342.602 ms)\n",
            "daat (205.348 ms)\n",
            "daat (1083.942 ms)\n",
            "daat (232.897 ms)\n",
            "daat (622.168 ms)\n",
            "daat (285.203 ms)\n",
            "daat (310.338 ms)\n",
            "daat (470.310 ms)\n",
            "daat (474.958 ms)\n",
            "daat (860.784 ms)\n",
            "daat (440.655 ms)\n",
            "daat (1279.048 ms)\n",
            "daat (707.312 ms)\n",
            "daat (1204.256 ms)\n",
            "daat (2285.894 ms)\n",
            "daat (1559.219 ms)\n",
            "daat (1142.586 ms)\n",
            "daat (246.344 ms)\n",
            "daat (815.252 ms)\n",
            "daat (536.860 ms)\n",
            "daat (2443.770 ms)\n",
            "daat (1286.490 ms)\n",
            "daat (524.133 ms)\n",
            "daat (1415.699 ms)\n",
            "daat (549.060 ms)\n",
            "daat (166.443 ms)\n",
            "daat (369.320 ms)\n",
            "daat (2306.452 ms)\n",
            "daat (569.499 ms)\n",
            "daat (371.176 ms)\n",
            "daat (14.038 ms)\n",
            "daat (539.940 ms)\n",
            "daat (6.294 ms)\n",
            "daat (90.499 ms)\n",
            "daat (503.979 ms)\n",
            "daat (204.096 ms)\n",
            "daat (400.253 ms)\n",
            "daat (225.351 ms)\n",
            "daat (859.362 ms)\n",
            "daat (587.030 ms)\n",
            "daat (137.555 ms)\n",
            "daat (397.883 ms)\n",
            "daat (808.753 ms)\n",
            "daat (227.924 ms)\n",
            "daat (352.543 ms)\n",
            "daat (182.688 ms)\n",
            "daat (245.401 ms)\n",
            "daat (138.717 ms)\n",
            "daat (64.156 ms)\n",
            "daat (21.607 ms)\n",
            "daat (203.448 ms)\n",
            "daat (131.310 ms)\n",
            "daat (90.775 ms)\n",
            "daat (804.491 ms)\n",
            "daat (1039.400 ms)\n",
            "daat (471.407 ms)\n",
            "daat (446.026 ms)\n",
            "daat (172.697 ms)\n",
            "daat (671.873 ms)\n",
            "daat (199.215 ms)\n",
            "daat (528.430 ms)\n",
            "daat (17.817 ms)\n",
            "daat (578.964 ms)\n",
            "daat (86.514 ms)\n",
            "daat (80.877 ms)\n",
            "daat (659.427 ms)\n",
            "daat (231.380 ms)\n",
            "daat (0.301 ms)\n",
            "daat (10.912 ms)\n",
            "daat (17.552 ms)\n",
            "daat (40.841 ms)\n",
            "daat (0.017 ms)\n",
            "daat (18.402 ms)\n",
            "daat (22.654 ms)\n",
            "daat (81.689 ms)\n",
            "daat (23.197 ms)\n",
            "daat (0.038 ms)\n",
            "daat (135.286 ms)\n",
            "daat (0.031 ms)\n",
            "daat (233.049 ms)\n",
            "daat (165.931 ms)\n",
            "daat (1838.989 ms)\n",
            "daat (128.625 ms)\n",
            "daat (371.495 ms)\n",
            "daat (374.340 ms)\n",
            "daat (378.662 ms)\n",
            "daat (129.829 ms)\n",
            "daat (135.764 ms)\n",
            "daat (567.928 ms)\n",
            "daat (159.492 ms)\n",
            "daat (730.844 ms)\n",
            "daat (482.382 ms)\n",
            "daat (592.770 ms)\n",
            "daat (274.765 ms)\n",
            "daat (932.790 ms)\n",
            "daat (455.417 ms)\n",
            "daat (284.578 ms)\n",
            "daat (157.516 ms)\n",
            "daat (429.340 ms)\n",
            "daat (352.020 ms)\n",
            "daat (209.821 ms)\n",
            "daat (118.662 ms)\n",
            "daat (0.054 ms)\n",
            "daat (230.848 ms)\n",
            "daat (299.629 ms)\n",
            "daat (0.017 ms)\n",
            "daat (230.584 ms)\n",
            "Run file saved to: precomputed_bm25_run.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# File where the test queries are stored\n",
        "queries_file = \"msmarco-test2020-queries.tsv\"\n",
        "\n",
        "# Name of the run with the precomputed bm25 weights\n",
        "run_name = \"precomputed_bm25_run\"\n",
        "\n",
        "# Name of the file where the run will be stored\n",
        "run_file = run_name + \".txt\"\n",
        "\n",
        "# Scorer Leveraging PreComputed Weights\n",
        "scorer = PreComputedScorer()\n",
        "\n",
        "# Extracting queries from test queries file\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "# Initialize the inverted index with the current scoring function\n",
        "# This allows different retrieval models (e.g., TF, TF-IDF, BM25)\n",
        "inv_ind = InvertedIndex(\n",
        "    lexicon,       # term -> (termid, ...) mapping\n",
        "    inv_d,         # list of numpy arrays: doc IDs per term\n",
        "    inv_f,         # list of numpy arrays: term frequencies per term\n",
        "    doc_index,     # document statistics\n",
        "    stats,         # global statistics (e.g., total # of documents)\n",
        "    scorer=scorer  # scoring function to use for this run\n",
        ")\n",
        "\n",
        "# Generate and write a TREC-formatted run file for the current query set\n",
        "# The filename combines the run name and the run suffix\n",
        "write_run_file(\n",
        "    queries,              # queries to process\n",
        "    inv_ind,              # inverted index with current scoring function\n",
        "    run_file,             # output filename for this run\n",
        "    run_name              # run identifier (appears in run file)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsE2yvcDiaqs"
      },
      "source": [
        "#### Measuring Time Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAPouEonmAyY"
      },
      "source": [
        "I extracted and cleaned the execution logs from both this run and the previous BM25 run, keeping only the integer part of the execution times in milliseconds (using grep), and saved them into two separate text files. The analysis shows that the optimized version is approximately an order of magnitude faster than the standard BM25 implementation, and the performance improvement is also statistically significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGnDJSscpHmt"
      },
      "source": [
        "This code compares the execution times of two retrieval methods. It begins by reading the recorded execution times (in milliseconds) from two text files, where each line represents the duration of a single query run. Using a paired t-test from the scipy.stats library, it tests whether the difference in execution times between the two methods is significant. The script then prints the t-statistic and p-value from the test, along with the average execution time for each method, providing a clear indication of both the magnitude and statistical reliability of the optimization's performance gain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWfSOtSOdKk3",
        "outputId": "d9f488a5-a2a6-424b-cd9b-bd5bea014e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T-statistic: 7.7834, P-value: 3.772940e-13\n",
            "Average DAAT BM25 time: 3883.40 ms\n",
            "Average Optimized DAAT BM25 time: 452.01 ms\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Paths to files containing execution times (in ms)\n",
        "daat_times_file = \"daat_bm25_time.txt\"        # baseline DAAT BM25 times\n",
        "opt_daat_times_file = \"opt_daat_bm25_time.txt\"  # optimized DAAT BM25 times\n",
        "\n",
        "# Each file contains one time measurement per line (integer milliseconds)\n",
        "with open(daat_times_file, \"r\") as f:\n",
        "    daat_times = [float(line.strip()) for line in f]\n",
        "\n",
        "with open(opt_daat_times_file, \"r\") as f:\n",
        "    opt_daat_times = [float(line.strip()) for line in f]\n",
        "\n",
        "# Perform a paired t-test to determine if the optimization led to a significant difference\n",
        "t_stat, p_val = ttest_rel(daat_times, opt_daat_times)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_val:.6e}\")\n",
        "\n",
        "# Compute and print average execution times for both methods\n",
        "avg_daat = sum(daat_times) / len(daat_times)\n",
        "avg_opt_daat = sum(opt_daat_times) / len(opt_daat_times)\n",
        "\n",
        "print(f\"Average DAAT BM25 time: {avg_daat:.2f} ms\")\n",
        "print(f\"Average Optimized DAAT BM25 time: {avg_opt_daat:.2f} ms\")\n",
        "\n",
        "#TODO: che è Average DAAT BM25 time: 3883.40 ms???? prima non stava sul secondo/secondo e mezzo?\n",
        "# sei sicuro che il tempo sia migliorato anche per le due cose (min docid e pruning) e non solo per il precomputing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYKsOSRh_Gru"
      },
      "source": [
        "The geometric mean and also the median are good alternatives.\n",
        "In our case study, the average (arithmetic mean) response time is not a particularly insightful metric, as it is highly sensitive to outliers. For example, if we have 20 queries, one taking 20 seconds and the rest completing in just a few milliseconds, the average would misleadingly suggest a response time of over one second. In contrast, the geometric mean and the median offer more robust alternatives, as they are less influenced by extreme values and provide a more representative view of typical performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc8KRwnyPemg"
      },
      "source": [
        "This code reads a file containing execution times, computes their geometric mean and median, and prints the results. It begins by opening the file opt_daat_bm25_time.txt, which stores one timing value per line, and converts each line into a floating‑point number stored in a list. The geometric mean is then calculated using SciPy’s gmean function, which is particularly useful for averaging values that vary multiplicatively, such as performance times or ratios. To compute the median, the list of times is sorted and its length determined; if the number of elements is odd, the middle value is selected, while for an even number of elements, the average of the two central values is taken. Finally, both the geometric mean and the median are printed, providing two complementary measures of central tendency for the execution time data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA-6gjolPemg",
        "outputId": "6a6ff51b-b576-4717-c1b4-da02394ffa55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Geometric Mean: 196.40473532397888\n",
            "Median: 283.1355\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import gmean\n",
        "\n",
        "\n",
        "# Declaring path to the file containing execution times (one per line)\n",
        "# and the list that will hold execution times\n",
        "time_filename = \"opt_daat_bm25_time.txt\"\n",
        "times = []\n",
        "\n",
        "# Open the file, read all lines and convert them into a list\n",
        "with open(time_filename, \"r\") as f:\n",
        "    lines = f.readlines()                   # Reading Lines\n",
        "    times = [float(line) for line in lines] # Converting using list comprehension\n",
        "\n",
        "\n",
        "# Geometric mean is useful for averaging ratios or times when values\n",
        "# vary multiplicatively, it's computed with scipy package to avoid overflow\n",
        "# TODO: non essendo questo il caso (valori si combinano con moltiplicazione), siamo sicuri abbia senso usarlo?\n",
        "geo_mean = gmean(times)\n",
        "\n",
        "# Sort the list of times to prepare for median calculation and extract\n",
        "# length as it will avoid lengthy expression\n",
        "sorted_times = sorted(times)\n",
        "l = len(sorted_times)\n",
        "\n",
        "# If the number of elements is odd, take the middle element\n",
        "if l % 2 == 1:\n",
        "    median = sorted_times[l // 2]\n",
        "# If even, take the average of the two middle elements\n",
        "else:\n",
        "    median = (sorted_times[l // 2] + sorted_times[(l // 2) - 1]) / 2\n",
        "\n",
        "# Print results\n",
        "print(\"Geometric Mean:\", geo_mean)\n",
        "print(\"Median:\", median)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQYmdzHnChrS"
      },
      "source": [
        "**Geometric Mean Time**: 196ms\n",
        "\n",
        "**Median Time**: 283ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXnf_EMrifZd"
      },
      "source": [
        "#### Measuring Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zSu8C6eiIqV"
      },
      "source": [
        "Since the BM25 weights were truncated to reduce memory usage, it is important to verify that this approximation does not significantly degrade retrieval performance. Upon evaluation, the truncated-weight model shows a slight decrease in effectiveness compared to the original version; however, statistical testing confirms that this difference is not significant, meaning the optimization achieves faster or more memory-efficient retrieval without a meaningful loss in accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl6il1-XsTf8"
      },
      "source": [
        "This block of code performs a statistical comparison between the optimized BM25 retrieval system (using precomputed and truncated weights) and the standard BM25 implementation. It first loads the ground truth relevance judgments (qrels) and the two run files containing the ranked retrieval results. Using the ir_measures library, it computes three standard information retrieval metrics Mean Average Precision (MAP), nDCG@10, and MRR@10 for both runs on a per-query basis. Finally, it applies paired t-tests to each metric, comparing the optimized and unoptimized systems to check whether performance differences are statistically significant. The printed t-statistics and p-values indicate whether the observed variations are meaningful or likely due to random chance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyOVb1jagr_M"
      },
      "outputs": [],
      "source": [
        "# TODO: da pensare assieme, stiamo facendo model selection sul test? mhh, non so se sia giusto\n",
        "#si può giustificare dicendo che non è model selection ma solo performance check\n",
        "\n",
        "# Qrels (ground truth relevance judgments)\n",
        "qrels_file = '2020qrels-pass.txt'\n",
        "\n",
        "# Custom run file generated using optimized BM25\n",
        "opt_bm25_run_file = 'precomputed_bm25_run.txt'\n",
        "\n",
        "# Custom run file generated using BM25\n",
        "bm25_run_file = 'bm25_test_run'\n",
        "\n",
        "\n",
        "# Read qrels into a list of relevance judgments and read the runs into\n",
        "# lists of run entries\n",
        "qrel = list(ir_measures.read_trec_qrels(qrels_file))\n",
        "opt_bm25_run_data = list(ir_measures.read_trec_run(opt_bm25_run_file))\n",
        "bm25_run_data = list(ir_measures.read_trec_run(bm25_run_file))\n",
        "\n",
        "\n",
        "# Mean Average Precision (MAP), nDCG and MRR for Optimized Run\n",
        "opt_MAP = tuple(m.value for m in ir_measures.iter_calc([AP], qrel, opt_bm25_run_data))\n",
        "opt_nDCG = tuple(m.value for m in ir_measures.iter_calc([nDCG@10], qrel, opt_bm25_run_data))\n",
        "opt_MRR = tuple(m.value for m in ir_measures.iter_calc([MRR@10], qrel, opt_bm25_run_data))\n",
        "\n",
        "\n",
        "# Mean Average Precision (MAP), nDCG and MRR for Unoptimized Run\n",
        "MAP = tuple(m.value for m in ir_measures.iter_calc([AP], qrel, bm25_run_data))\n",
        "nDCG = tuple(m.value for m in ir_measures.iter_calc([nDCG@10], qrel, bm25_run_data))\n",
        "MRR = tuple(m.value for m in ir_measures.iter_calc([MRR@10], qrel, bm25_run_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OEZn1gyrWS9",
        "outputId": "108ac422-7f37-489a-9cc8-32eedb067abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: t_stat = -0.222298, p_value = 0.824937\n",
            "nDCG@10: t_stat = nan, p_value = nan\n",
            "MRR@10: t_stat = nan, p_value = nan\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Paired t-test for Mean Average Precision (MAP)\n",
        "# Compares per-query MAP scores between the two runs\n",
        "t_stat, p_val = ttest_rel(opt_MAP, MAP)\n",
        "print(f\"MAP: t_stat = {t_stat:.6f}, p_value = {p_val:.6f}\")\n",
        "\n",
        "# Paired t-test for nDCG@10\n",
        "# Compares per-query nDCG@10 scores between the two runs\n",
        "t_stat, p_val = ttest_rel(opt_nDCG, nDCG)\n",
        "print(f\"nDCG@10: t_stat = {t_stat:.6f}, p_value = {p_val:.6f}\")\n",
        "\n",
        "# Paired t-test for MRR@10\n",
        "# Compares per-query MRR@10 scores between the two runs\n",
        "t_stat, p_val = ttest_rel(opt_MRR, MRR)\n",
        "print(f\"MRR@10: t_stat = {t_stat:.6f}, p_value = {p_val:.6f}\")\n",
        "\n",
        "\n",
        "# TODO: piccolo check personale, nan vuol dire che non cambia il valore tra i due? in caso scriverlo sul commento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Yrc9pO9xI7"
      },
      "source": [
        "### Dynamic Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5am5J0u2wsg"
      },
      "source": [
        "#### Helper Functions and Data Structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZHdFJPi5WAK"
      },
      "source": [
        "This piece of code precomputes the maximum possible contribution of each term to any document score, which is essential for implementing MaxScore or other dynamic pruning techniques. Here, N represents the total number of documents in the collection. For each term in the lexicon, the code retrieves the document frequency df (the number of documents containing that term) and computes the logarithm of the inverse document frequency, np.log(N / df). This value corresponds to the upper bound of the term's contribution to a document's score, assuming the highest possible term frequency. Storing these upper bounds in termid_to_upperbound allows the retrieval algorithm to quickly estimate whether a document could potentially enter the top-k results, enabling efficient pruning of documents that cannot surpass the current top scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JMOFqxBwBV9"
      },
      "outputs": [],
      "source": [
        "# TODO: scrivere che è l'upper bound con tf -> +inf\n",
        "# Termid is mapped to the upperbound using a list\n",
        "N = stats['num_docs']\n",
        "termid_to_upperbound = [\n",
        "    np.log(N / df) for _term, (_term_id, df, _tf) in lexicon.items()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vq70FF5xt8"
      },
      "source": [
        "The dynamic_pruning_daat function implements a document-at-a-time (DAAT) retrieval algorithm with MaxScore dynamic pruning. It iterates over multiple posting lists simultaneously, computing scores for each document across all terms. Using precomputed upper bounds for each term, the function estimates the maximum possible score a document could achieve and skips any document that cannot enter the current top-k results, significantly improving efficiency. For documents that are not skipped, the actual score is computed by summing the contributions from all relevant terms, and the document is inserted into a top-k priority queue. The function returns the top-k documents sorted by descending score, providing an optimized retrieval mechanism that improves speed while not affecting accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5j4ZjdVtL9E"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "# TODO: prima hai detto che scritto come prima funge meglio!!!\n",
        "\n",
        "def min_docid(\n",
        "    postings: List['InvertedIndex.PostingListIterator']\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Returns the smallest current docid among all posting list iterators.\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "    Returns:\n",
        "        int: Minimum current docid, or math.inf if all postings are exhausted.\n",
        "    \"\"\"\n",
        "\n",
        "    # I am iterating over the heads of the postings and returning the min\n",
        "    min_docid_value = math.inf\n",
        "    for p in postings:\n",
        "        if not p._is_end_list():\n",
        "            min_docid_value = min(p.docid(), min_docid_value)\n",
        "    return min_docid_value\n",
        "\n",
        "@profile\n",
        "def dynamic_pruning_daat(\n",
        "    postings: List['InvertedIndex.PostingListIterator'],\n",
        "    termid_to_upperbound: List[float],\n",
        "    k: int = 10\n",
        ") -> List[Tuple[float, int]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Computes document-at-a-time (DAAT) scoring for a list of posting lists.\n",
        "        Scores each document across all postings simultaneously and returns\n",
        "        the top-k documents. It uses MaxScore optimization for dynamic pruning\n",
        "    Arguments:\n",
        "        postings (List[PostingListIterator]): List of posting list iterators.\n",
        "        termid_to_upperbound (List[float]): List of upper bounds for each term.\n",
        "        k (int): Number of top-scoring documents to return. Default is 10.\n",
        "    Returns:\n",
        "        List[Tuple[float, int]]: List of (score, docid) tuples, sorted in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    top = TopQueue(k)\n",
        "\n",
        "    # Initialize the first document ID to process\n",
        "    current_docid = min_docid(postings)  # Find the smallest docid among all postings\n",
        "\n",
        "    while current_docid != math.inf:\n",
        "        # Estimate the maximum possible score for this document\n",
        "        max_possible_score = sum(termid_to_upperbound[p.termid] for p in postings)\n",
        "\n",
        "        # Skip this document if its maximum possible score cannot beat the current top-k\n",
        "        if not top.would_enter(max_possible_score):\n",
        "            next_docid = math.inf\n",
        "            for p in postings:\n",
        "                if p.docid() == current_docid:\n",
        "                    p.next()\n",
        "                if not p._is_end_list():\n",
        "                    next_docid = min(next_docid, p.docid())\n",
        "            current_docid = next_docid\n",
        "            continue\n",
        "\n",
        "        # Compute the actual score for the current document\n",
        "        score = 0.0\n",
        "        next_docid = math.inf\n",
        "        for p in postings:\n",
        "            if p.docid() == current_docid:\n",
        "                score += p.score()\n",
        "                p.next()\n",
        "            if not p._is_end_list():\n",
        "                next_docid = min(next_docid, p.docid())\n",
        "\n",
        "        # Insert document into the top-k queue\n",
        "        top.insert(current_docid, score) # type: ignore\n",
        "\n",
        "        # Move to the next document\n",
        "        current_docid = next_docid\n",
        "\n",
        "    # Return top-k results sorted by descending score\n",
        "    return sorted(top.queue, reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZbRChFp6k-2"
      },
      "source": [
        "I have updated the query processing function to leverage the dynamic pruning DAAT algorithm, allowing it to efficiently skip documents that cannot reach the top-k results based on term upper bounds. This modification integrates MaxScore-style optimization directly into the query evaluation, improving retrieval speed while maintaining ranking accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onUhEbor0bPo"
      },
      "outputs": [],
      "source": [
        "def query_process(\n",
        "    query: str,\n",
        "    index: 'InvertedIndex',\n",
        "    termid_to_upperbound: List[float],\n",
        "    k: int = 10,\n",
        ") -> List[Tuple[float, int]]:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Processes a query using TAAT or DAAT retrieval on an inverted index.\n",
        "    Arguments:\n",
        "        query (str): Input query string.\n",
        "        index (InvertedIndex): Inverted index containing terms and postings.\n",
        "        k (int): Number of top-scoring documents to return. Default is 10.\n",
        "    Returns:\n",
        "        List[Tuple[float, int]]: List of top-k (score, docid) results.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess query into tokens\n",
        "    qtokens: List[str] = preprocess(query)   # NOTE: cambiato tipo\n",
        "\n",
        "    # Map tokens to term IDs\n",
        "    qtermids: List[int] = index.get_termids(qtokens)\n",
        "\n",
        "    # Retrieve posting lists for the term IDs\n",
        "    postings: List['InvertedIndex.PostingListIterator'] = index.get_postings(\n",
        "        qtermids,\n",
        "        qtokens\n",
        "    )\n",
        "\n",
        "    return dynamic_pruning_daat(postings, termid_to_upperbound, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr1Nm6Py7GP3"
      },
      "source": [
        "I have updated the run file generation function to pass the precomputed term upper-bound data structure and to use the dynamic pruning DAAT algorithm. This change ensures that the retrieval process applies MaxScore-style optimizations when computing document scores, resulting in faster query evaluation while producing the same top-k results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siOV9Tv_03sX"
      },
      "outputs": [],
      "source": [
        "def write_run_file(\n",
        "    queries: list[tuple[str, str]],\n",
        "    index: InvertedIndex,\n",
        "    output_path: str,\n",
        "    termid_to_upperbound: List[float],\n",
        "    run_name: str = \"my_run\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Generates a TREC-formatted run file from a set of queries and the inverted index.\n",
        "\n",
        "    Arguments:\n",
        "        queries (Dict[int, str]): Mapping from query IDs to query strings.\n",
        "        index (InvertedIndex): The inverted index used for retrieval.\n",
        "        output_path (str): Path to save the output run file.\n",
        "        run_name (str): Identifier for the run (appears in the last column).\n",
        "    \"\"\"\n",
        "\n",
        "    with open(output_path, \"w\") as f:\n",
        "        for qid, query in queries:\n",
        "\n",
        "            # List of scores and docids ordered by score\n",
        "            results: list[tuple[np.float64, np.int32]] = query_process(\n",
        "                query,\n",
        "                index,\n",
        "                termid_to_upperbound\n",
        "            )\n",
        "            # TODO: ma questi non sono computati come listeee! perchè ora np.array\n",
        "\n",
        "            # Iterating over results, converting docid into docno while\n",
        "            # removing DOC and storing the line in the run file\n",
        "            for rank, (score, docid) in enumerate(results, start=1):\n",
        "                docno: str = doc_index[docid - 1][0]\n",
        "                docno: str = docno.replace(\"DOC\", \"\")\n",
        "                f.write(f\"{qid} Q0 {docno} {rank} {score:.6f} {run_name}\\n\")\n",
        "\n",
        "    print(f\"Run file saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyBlvgew22iA"
      },
      "source": [
        "#### Creating Run File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVvvRg6V7j9C"
      },
      "source": [
        "Generating the run file while simultaneously using time profiling to measure and compare the execution speed against the baseline retrieval model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgMaCze5zEE9",
        "outputId": "f8e57df4-ee1d-4fa0-8cf2-6e2822b6ea41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dynamic_pruning_daat (6341.734 ms)\n",
            "dynamic_pruning_daat (3366.907 ms)\n",
            "dynamic_pruning_daat (0.191 ms)\n",
            "dynamic_pruning_daat (454.333 ms)\n",
            "dynamic_pruning_daat (9188.710 ms)\n",
            "dynamic_pruning_daat (5449.454 ms)\n",
            "dynamic_pruning_daat (3771.396 ms)\n",
            "dynamic_pruning_daat (9771.373 ms)\n",
            "dynamic_pruning_daat (2913.263 ms)\n",
            "dynamic_pruning_daat (1117.760 ms)\n",
            "dynamic_pruning_daat (5010.983 ms)\n",
            "dynamic_pruning_daat (7213.560 ms)\n",
            "dynamic_pruning_daat (1398.828 ms)\n",
            "dynamic_pruning_daat (12639.566 ms)\n",
            "dynamic_pruning_daat (7500.100 ms)\n",
            "dynamic_pruning_daat (8397.099 ms)\n",
            "dynamic_pruning_daat (3908.665 ms)\n",
            "dynamic_pruning_daat (32191.107 ms)\n",
            "dynamic_pruning_daat (2100.518 ms)\n",
            "dynamic_pruning_daat (598.621 ms)\n",
            "dynamic_pruning_daat (1369.017 ms)\n",
            "dynamic_pruning_daat (5667.355 ms)\n",
            "dynamic_pruning_daat (468.459 ms)\n",
            "dynamic_pruning_daat (10859.470 ms)\n",
            "dynamic_pruning_daat (25408.711 ms)\n",
            "dynamic_pruning_daat (2462.128 ms)\n",
            "dynamic_pruning_daat (7362.287 ms)\n",
            "dynamic_pruning_daat (27075.357 ms)\n",
            "dynamic_pruning_daat (1416.910 ms)\n",
            "dynamic_pruning_daat (10656.480 ms)\n",
            "dynamic_pruning_daat (3994.347 ms)\n",
            "dynamic_pruning_daat (2159.219 ms)\n",
            "dynamic_pruning_daat (375.255 ms)\n",
            "dynamic_pruning_daat (11423.747 ms)\n",
            "dynamic_pruning_daat (2696.598 ms)\n",
            "dynamic_pruning_daat (1806.769 ms)\n",
            "dynamic_pruning_daat (7477.628 ms)\n",
            "dynamic_pruning_daat (10149.444 ms)\n",
            "dynamic_pruning_daat (1645.474 ms)\n",
            "dynamic_pruning_daat (2773.407 ms)\n",
            "dynamic_pruning_daat (6761.326 ms)\n",
            "dynamic_pruning_daat (7438.236 ms)\n",
            "dynamic_pruning_daat (10680.165 ms)\n",
            "dynamic_pruning_daat (7573.651 ms)\n",
            "dynamic_pruning_daat (6687.440 ms)\n",
            "dynamic_pruning_daat (24697.668 ms)\n",
            "dynamic_pruning_daat (2191.821 ms)\n",
            "dynamic_pruning_daat (6771.881 ms)\n",
            "dynamic_pruning_daat (12791.992 ms)\n",
            "dynamic_pruning_daat (2357.974 ms)\n",
            "dynamic_pruning_daat (1717.478 ms)\n",
            "dynamic_pruning_daat (111.222 ms)\n",
            "dynamic_pruning_daat (4466.286 ms)\n",
            "dynamic_pruning_daat (8604.845 ms)\n",
            "dynamic_pruning_daat (933.928 ms)\n",
            "dynamic_pruning_daat (1638.637 ms)\n",
            "dynamic_pruning_daat (1137.207 ms)\n",
            "dynamic_pruning_daat (1920.373 ms)\n",
            "dynamic_pruning_daat (21852.813 ms)\n",
            "dynamic_pruning_daat (18371.559 ms)\n",
            "dynamic_pruning_daat (2517.939 ms)\n",
            "dynamic_pruning_daat (11098.733 ms)\n",
            "dynamic_pruning_daat (5431.315 ms)\n",
            "dynamic_pruning_daat (6737.057 ms)\n",
            "dynamic_pruning_daat (9467.039 ms)\n",
            "dynamic_pruning_daat (1831.702 ms)\n",
            "dynamic_pruning_daat (2864.417 ms)\n",
            "dynamic_pruning_daat (2680.010 ms)\n",
            "dynamic_pruning_daat (7308.701 ms)\n",
            "dynamic_pruning_daat (748.097 ms)\n",
            "dynamic_pruning_daat (3237.966 ms)\n",
            "dynamic_pruning_daat (10763.496 ms)\n",
            "dynamic_pruning_daat (455.370 ms)\n",
            "dynamic_pruning_daat (11431.482 ms)\n",
            "dynamic_pruning_daat (8312.581 ms)\n",
            "dynamic_pruning_daat (1434.857 ms)\n",
            "dynamic_pruning_daat (4944.714 ms)\n",
            "dynamic_pruning_daat (2360.965 ms)\n",
            "dynamic_pruning_daat (1.348 ms)\n",
            "dynamic_pruning_daat (7555.322 ms)\n",
            "dynamic_pruning_daat (1900.909 ms)\n",
            "dynamic_pruning_daat (8278.950 ms)\n",
            "dynamic_pruning_daat (2093.984 ms)\n",
            "dynamic_pruning_daat (8179.303 ms)\n",
            "dynamic_pruning_daat (5030.174 ms)\n",
            "dynamic_pruning_daat (13895.963 ms)\n",
            "dynamic_pruning_daat (3935.055 ms)\n",
            "dynamic_pruning_daat (4436.390 ms)\n",
            "dynamic_pruning_daat (169.452 ms)\n",
            "dynamic_pruning_daat (4752.104 ms)\n",
            "dynamic_pruning_daat (15136.708 ms)\n",
            "dynamic_pruning_daat (11240.493 ms)\n",
            "dynamic_pruning_daat (11783.135 ms)\n",
            "dynamic_pruning_daat (1379.521 ms)\n",
            "dynamic_pruning_daat (1188.927 ms)\n",
            "dynamic_pruning_daat (1872.204 ms)\n",
            "dynamic_pruning_daat (476.930 ms)\n",
            "dynamic_pruning_daat (245.721 ms)\n",
            "dynamic_pruning_daat (3869.286 ms)\n",
            "dynamic_pruning_daat (4425.602 ms)\n",
            "dynamic_pruning_daat (5709.469 ms)\n",
            "dynamic_pruning_daat (8929.615 ms)\n",
            "dynamic_pruning_daat (5623.103 ms)\n",
            "dynamic_pruning_daat (2913.023 ms)\n",
            "dynamic_pruning_daat (4589.584 ms)\n",
            "dynamic_pruning_daat (5805.946 ms)\n",
            "dynamic_pruning_daat (3600.768 ms)\n",
            "dynamic_pruning_daat (699.355 ms)\n",
            "dynamic_pruning_daat (0.261 ms)\n",
            "dynamic_pruning_daat (6496.420 ms)\n",
            "dynamic_pruning_daat (2045.020 ms)\n",
            "dynamic_pruning_daat (4695.742 ms)\n",
            "dynamic_pruning_daat (3288.744 ms)\n",
            "dynamic_pruning_daat (9648.668 ms)\n",
            "dynamic_pruning_daat (4592.964 ms)\n",
            "dynamic_pruning_daat (4906.044 ms)\n",
            "dynamic_pruning_daat (5358.453 ms)\n",
            "dynamic_pruning_daat (3758.488 ms)\n",
            "dynamic_pruning_daat (0.272 ms)\n",
            "dynamic_pruning_daat (10560.457 ms)\n",
            "dynamic_pruning_daat (2897.088 ms)\n",
            "dynamic_pruning_daat (543.889 ms)\n",
            "dynamic_pruning_daat (6178.948 ms)\n",
            "dynamic_pruning_daat (495.483 ms)\n",
            "dynamic_pruning_daat (45.086 ms)\n",
            "dynamic_pruning_daat (1211.258 ms)\n",
            "dynamic_pruning_daat (1800.145 ms)\n",
            "dynamic_pruning_daat (10340.213 ms)\n",
            "dynamic_pruning_daat (285.251 ms)\n",
            "dynamic_pruning_daat (5212.715 ms)\n",
            "dynamic_pruning_daat (8253.729 ms)\n",
            "dynamic_pruning_daat (4901.312 ms)\n",
            "dynamic_pruning_daat (12119.336 ms)\n",
            "dynamic_pruning_daat (0.157 ms)\n",
            "dynamic_pruning_daat (14117.151 ms)\n",
            "dynamic_pruning_daat (1939.385 ms)\n",
            "dynamic_pruning_daat (2670.614 ms)\n",
            "dynamic_pruning_daat (4646.281 ms)\n",
            "dynamic_pruning_daat (9336.047 ms)\n",
            "dynamic_pruning_daat (5927.538 ms)\n",
            "dynamic_pruning_daat (409.293 ms)\n",
            "dynamic_pruning_daat (592.321 ms)\n",
            "dynamic_pruning_daat (5530.917 ms)\n",
            "dynamic_pruning_daat (14180.735 ms)\n",
            "dynamic_pruning_daat (2732.203 ms)\n",
            "dynamic_pruning_daat (5328.134 ms)\n",
            "dynamic_pruning_daat (9826.968 ms)\n",
            "dynamic_pruning_daat (3106.939 ms)\n",
            "dynamic_pruning_daat (4171.058 ms)\n",
            "dynamic_pruning_daat (6024.972 ms)\n",
            "dynamic_pruning_daat (4800.806 ms)\n",
            "dynamic_pruning_daat (8199.115 ms)\n",
            "dynamic_pruning_daat (2412.374 ms)\n",
            "dynamic_pruning_daat (4529.149 ms)\n",
            "dynamic_pruning_daat (3938.332 ms)\n",
            "dynamic_pruning_daat (17908.599 ms)\n",
            "dynamic_pruning_daat (4585.738 ms)\n",
            "dynamic_pruning_daat (274.891 ms)\n",
            "dynamic_pruning_daat (3232.073 ms)\n",
            "dynamic_pruning_daat (0.615 ms)\n",
            "dynamic_pruning_daat (4679.454 ms)\n",
            "dynamic_pruning_daat (21635.166 ms)\n",
            "dynamic_pruning_daat (2411.240 ms)\n",
            "dynamic_pruning_daat (2710.789 ms)\n",
            "dynamic_pruning_daat (2702.365 ms)\n",
            "dynamic_pruning_daat (879.540 ms)\n",
            "dynamic_pruning_daat (3074.342 ms)\n",
            "dynamic_pruning_daat (4829.560 ms)\n",
            "dynamic_pruning_daat (2808.246 ms)\n",
            "dynamic_pruning_daat (4224.879 ms)\n",
            "dynamic_pruning_daat (21703.722 ms)\n",
            "dynamic_pruning_daat (19245.739 ms)\n",
            "dynamic_pruning_daat (5412.056 ms)\n",
            "dynamic_pruning_daat (5530.105 ms)\n",
            "dynamic_pruning_daat (1821.874 ms)\n",
            "dynamic_pruning_daat (7109.648 ms)\n",
            "dynamic_pruning_daat (10836.906 ms)\n",
            "dynamic_pruning_daat (56963.549 ms)\n",
            "dynamic_pruning_daat (10538.842 ms)\n",
            "dynamic_pruning_daat (2993.132 ms)\n",
            "dynamic_pruning_daat (4601.603 ms)\n",
            "dynamic_pruning_daat (6540.046 ms)\n",
            "dynamic_pruning_daat (5304.592 ms)\n",
            "dynamic_pruning_daat (155.101 ms)\n",
            "dynamic_pruning_daat (11890.698 ms)\n",
            "dynamic_pruning_daat (0.379 ms)\n",
            "dynamic_pruning_daat (1820.496 ms)\n",
            "dynamic_pruning_daat (142.306 ms)\n",
            "dynamic_pruning_daat (8690.085 ms)\n",
            "dynamic_pruning_daat (2820.885 ms)\n",
            "dynamic_pruning_daat (5507.778 ms)\n",
            "dynamic_pruning_daat (19274.133 ms)\n",
            "dynamic_pruning_daat (5840.087 ms)\n",
            "dynamic_pruning_daat (15340.890 ms)\n",
            "dynamic_pruning_daat (5116.960 ms)\n",
            "dynamic_pruning_daat (6054.417 ms)\n",
            "dynamic_pruning_daat (918.175 ms)\n",
            "dynamic_pruning_daat (10049.469 ms)\n",
            "dynamic_pruning_daat (13979.213 ms)\n",
            "dynamic_pruning_daat (2553.225 ms)\n",
            "Run file saved to: dp_bm25_run.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# File where the test queries are stored\n",
        "queries_file = \"msmarco-test2020-queries.tsv\"\n",
        "\n",
        "# Name of the run with the precomputed bm25 weights\n",
        "run_name = \"dp_bm25_run\"\n",
        "\n",
        "# Name of the file where the run will be stored\n",
        "run_file = run_name + \".txt\"\n",
        "\n",
        "# Scorer Leveraging PreComputed Weights\n",
        "scorer = BM25Scorer()\n",
        "# TODO: quindi qua non uso più gli score precomputati, ma l'inv_f non contiene ora il pesi per quello fatto sopra\n",
        "\n",
        "# Extracting queries from test queries file\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "\n",
        "# Initialize the inverted index with the current scoring function\n",
        "# This allows different retrieval models (e.g., TF, TF-IDF, BM25)\n",
        "inv_ind = InvertedIndex(\n",
        "    lexicon,       # term -> (termid, ...) mapping\n",
        "    inv_d,         # list of numpy arrays: doc IDs per term\n",
        "    inv_f,         # list of numpy arrays: term frequencies per term\n",
        "    doc_index,     # document statistics\n",
        "    stats,         # global statistics (e.g., total # of documents)\n",
        "    scorer=scorer  # scoring function to use for this run\n",
        ")\n",
        "\n",
        "# Generate and write a TREC-formatted run file for the current query set\n",
        "# The filename combines the run name and the run suffix\n",
        "write_run_file(\n",
        "    queries,              # queries to process\n",
        "    inv_ind,              # inverted index with current scoring function\n",
        "    run_file,             # output filename for this run\n",
        "    termid_to_upperbound, # upper bounds for each term\n",
        "    run_name              # run identifier (appears in run file)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ-znj-S8Asn"
      },
      "source": [
        "#### Evaluating Time Efficiency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnK3jbvY8Ppa"
      },
      "source": [
        "The results show that this approach is statistically superior to the baseline model; however, it does not achieve the same order-of-magnitude speedup observed with the precomputed weight version."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIb-Zqaa8OGT"
      },
      "source": [
        "This code compares the execution times of two retrieval methods. It begins by reading the recorded execution times (in milliseconds) from two text files, where each line represents the duration of a single query run. Using a paired t-test from the scipy.stats library, it tests whether the difference in execution times between the two methods is significant. The script then prints the t-statistic and p-value from the test, along with the average execution time for each method, providing a clear indication of both the magnitude and statistical reliability of the optimization's performance gain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN4gIeko7iS0",
        "outputId": "9bc723a7-8672-41b9-bd23-053c75344ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T-statistic: 9.0811, P-value: 5.028490e-18\n",
            "Average DAAT BM25 time: 3901.10 ms\n",
            "Average DP DAAT BM25 time: 3297.26 ms\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Paths to files containing execution times (in ms)\n",
        "daat_times_file = \"daat_bm25_time.txt\"        # baseline DAAT BM25 times\n",
        "opt_daat_times_file = \"dp_daat_bm25_time.txt\"  # optimized DAAT BM25 times\n",
        "\n",
        "# Each file contains one time measurement per line (integer milliseconds)\n",
        "with open(daat_times_file, \"r\") as f:\n",
        "    daat_times = [int(line.strip()) for line in f]\n",
        "\n",
        "with open(opt_daat_times_file, \"r\") as f:\n",
        "    opt_daat_times = [int(line.strip()) for line in f]\n",
        "\n",
        "# Perform a paired t-test to determine if the optimization led to a significant difference\n",
        "t_stat, p_val = ttest_rel(daat_times, opt_daat_times)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_val:.6e}\")\n",
        "\n",
        "# Compute and print average execution times for both methods\n",
        "avg_daat = sum(daat_times) / len(daat_times)\n",
        "avg_opt_daat = sum(opt_daat_times) / len(opt_daat_times)\n",
        "\n",
        "print(f\"Average DAAT BM25 time: {avg_daat:.2f} ms\")\n",
        "print(f\"Average DP DAAT BM25 time: {avg_opt_daat:.2f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDA8A4Jw6bsI"
      },
      "source": [
        "The combination of dynamic pruning and precomputed weights did not yield a performance improvement. This was primarily because retrieving the upper bound scores was not significantly faster than accessing the actual precomputed scores. Moreover, the additional logic required to manage upper bound lookups introduced overhead that ultimately offset any potential gains from pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtMB-ywE90Cn"
      },
      "source": [
        "### Compressed Posting Lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7dJyyY07Ycn"
      },
      "source": [
        "I plan to implement in-memory posting list compression to evaluate the tradeoff between memory usage and execution speed. While I consider runtime performance to be critical and have already applied several optimizations to minimize execution time I'm unlikely to adopt compression in the final implementation. Nonetheless, I will explore and analyze a range of in-memory compression techniques to better understand their impact and potential applicability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFunqllP9S5e"
      },
      "source": [
        "#### VB Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSz1cvk3ZasY"
      },
      "source": [
        "I am implementing in-memory posting list compression using Variable-Byte (VB) encoding, and I have modified the Inverted Index so that posting lists are decoded on-the-fly before creating the iterator. This ensures that the iterators operate on standard integer arrays while benefiting from the reduced memory footprint of VB encoding during storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSeG9ZaDLQeX",
        "outputId": "c30184dc-b212-4def-dcdc-a161ef6a7ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "delta_vb_encode_inv_d (227062.805 ms)\n"
          ]
        }
      ],
      "source": [
        "vb_encode_inv_f(inv_f)\n",
        "delta_vb_encode_inv_d(inv_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9d1RqhlMvTa"
      },
      "outputs": [],
      "source": [
        "class VBInvertedIndex(InvertedIndex):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Inverted Index variant using VB encoded posting lists\n",
        "    \"\"\"\n",
        "\n",
        "    def get_posting(self, termid: int, term: str) -> InvertedIndex.PostingListIterator: #NOTE: cambiato tipo di ritorno che era sbagliato\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Decode the posting list and Returns a PostingListIterator\n",
        "            for a given term ID.\n",
        "        Arguments:\n",
        "            termid (int): The term ID to retrieve the posting list for.\n",
        "        Returns:\n",
        "            PostingListIterator: Iterator over the posting list.\n",
        "        \"\"\"\n",
        "        return InvertedIndex.PostingListIterator(\n",
        "            delta_decode(vb_decode(self.inv_d[termid])),\n",
        "            vb_decode(self.inv_f[termid]),\n",
        "            termid,\n",
        "            term,\n",
        "            self.lexicon,\n",
        "            self.doc,\n",
        "            self.stats,\n",
        "            self.scorer\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-TS3UVoaJaQ"
      },
      "source": [
        "I am building the index and generating a run file to measure the time overhead caused by decoding the Variable-Byte encoded posting lists during query processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xuNTwwyPfdL"
      },
      "outputs": [],
      "source": [
        "# Using BM25 Scoring\n",
        "scorer = BM25Scorer()\n",
        "\n",
        "# Initialize an inverted index that uses Variable-Byte (VB) encoded posting lists.\n",
        "# This index will decode the postings on-the-fly when iterators are created.\n",
        "inv_ind = VBInvertedIndex(\n",
        "  lexicon,      # dictionary mapping terms to (termid, document frequency, etc.)\n",
        "  inv_d,        # list of VB-encoded document ID arrays for each term\n",
        "  inv_f,        # list of VB-encoded term frequency arrays for each term\n",
        "  doc_index,    # document statistics (e.g., lengths, IDs)\n",
        "  stats,        # global index statistics (e.g., total number of documents)\n",
        "  scorer,       # scoring function or object used to compute document scores\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "82s4z92LO2DE",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8f5a35ec-d42a-4685-e7d4-113a4ff52127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "daat (5163.551 ms)\n",
            "daat (3685.802 ms)\n",
            "daat (0.323 ms)\n",
            "daat (391.442 ms)\n",
            "daat (7271.406 ms)\n",
            "daat (4768.119 ms)\n",
            "daat (3755.634 ms)\n",
            "daat (12063.397 ms)\n",
            "daat (2379.610 ms)\n",
            "daat (1403.468 ms)\n",
            "daat (6303.511 ms)\n",
            "daat (7622.447 ms)\n",
            "daat (920.003 ms)\n",
            "daat (18329.643 ms)\n",
            "daat (8329.398 ms)\n",
            "daat (9257.011 ms)\n",
            "daat (4901.444 ms)\n",
            "daat (44958.728 ms)\n",
            "daat (3051.523 ms)\n",
            "daat (1198.196 ms)\n",
            "daat (2778.988 ms)\n",
            "daat (7828.075 ms)\n",
            "daat (568.110 ms)\n",
            "daat (12685.814 ms)\n",
            "daat (42667.037 ms)\n",
            "daat (2871.069 ms)\n",
            "daat (7405.569 ms)\n",
            "daat (35970.658 ms)\n",
            "daat (1450.215 ms)\n",
            "daat (22114.109 ms)\n",
            "daat (3348.764 ms)\n",
            "daat (2517.113 ms)\n",
            "daat (454.056 ms)\n",
            "daat (12643.918 ms)\n",
            "daat (3323.396 ms)\n",
            "daat (3239.571 ms)\n",
            "daat (13157.421 ms)\n",
            "daat (14487.130 ms)\n",
            "daat (4307.601 ms)\n",
            "daat (6331.963 ms)\n",
            "daat (20367.587 ms)\n",
            "daat (20713.626 ms)\n",
            "daat (33574.625 ms)\n",
            "daat (15669.034 ms)\n",
            "daat (16945.583 ms)\n",
            "daat (47630.548 ms)\n",
            "daat (2815.055 ms)\n",
            "daat (7235.986 ms)\n",
            "daat (35942.822 ms)\n",
            "daat (4672.345 ms)\n",
            "daat (2999.860 ms)\n",
            "daat (387.389 ms)\n",
            "daat (4584.628 ms)\n",
            "daat (27048.441 ms)\n",
            "daat (1372.323 ms)\n",
            "daat (2935.483 ms)\n",
            "daat (2074.089 ms)\n",
            "daat (6124.810 ms)\n",
            "daat (40270.921 ms)\n",
            "daat (41344.572 ms)\n",
            "daat (4375.637 ms)\n",
            "daat (32979.549 ms)\n",
            "daat (8267.714 ms)\n",
            "daat (17605.873 ms)\n",
            "daat (15139.024 ms)\n",
            "daat (2092.567 ms)\n",
            "daat (6823.822 ms)\n",
            "daat (3715.533 ms)\n",
            "daat (13068.357 ms)\n",
            "daat (887.260 ms)\n",
            "daat (4297.853 ms)\n",
            "daat (11904.123 ms)\n",
            "daat (558.364 ms)\n",
            "daat (17059.509 ms)\n",
            "daat (10932.919 ms)\n",
            "daat (1880.814 ms)\n",
            "daat (4817.696 ms)\n",
            "daat (3617.499 ms)\n",
            "daat (2.570 ms)\n",
            "daat (28940.482 ms)\n",
            "daat (2389.304 ms)\n",
            "daat (12945.987 ms)\n",
            "daat (1734.242 ms)\n",
            "daat (12428.509 ms)\n",
            "daat (7386.901 ms)\n",
            "daat (18021.731 ms)\n",
            "daat (6101.872 ms)\n",
            "daat (7929.460 ms)\n",
            "daat (592.448 ms)\n",
            "daat (16400.326 ms)\n",
            "daat (35481.733 ms)\n",
            "daat (20683.283 ms)\n",
            "daat (28935.538 ms)\n",
            "daat (1302.111 ms)\n",
            "daat (4198.083 ms)\n",
            "daat (4360.347 ms)\n",
            "daat (724.691 ms)\n",
            "daat (813.470 ms)\n",
            "daat (14218.632 ms)\n",
            "daat (5397.902 ms)\n",
            "daat (7432.142 ms)\n",
            "daat (10638.427 ms)\n",
            "daat (8563.291 ms)\n",
            "daat (4751.422 ms)\n",
            "daat (9071.660 ms)\n",
            "daat (5557.950 ms)\n",
            "daat (4401.137 ms)\n",
            "daat (827.887 ms)\n",
            "daat (0.420 ms)\n",
            "daat (6813.655 ms)\n",
            "daat (2344.617 ms)\n",
            "daat (5531.118 ms)\n",
            "daat (9513.937 ms)\n",
            "daat (16373.062 ms)\n",
            "daat (7322.850 ms)\n",
            "daat (8479.154 ms)\n",
            "daat (12732.030 ms)\n",
            "daat (5586.732 ms)\n",
            "daat (0.441 ms)\n",
            "daat (14188.060 ms)\n",
            "daat (5903.851 ms)\n",
            "daat (653.864 ms)\n",
            "daat (17698.510 ms)\n",
            "daat (619.197 ms)\n",
            "daat (53.254 ms)\n",
            "daat (1468.725 ms)\n",
            "daat (2167.746 ms)\n",
            "daat (11667.066 ms)\n",
            "daat (345.071 ms)\n",
            "daat (4847.826 ms)\n",
            "daat (15597.394 ms)\n",
            "daat (4882.965 ms)\n",
            "daat (13498.307 ms)\n",
            "daat (0.253 ms)\n",
            "daat (20973.912 ms)\n",
            "daat (2831.384 ms)\n",
            "daat (2356.903 ms)\n",
            "daat (4971.592 ms)\n",
            "daat (9872.143 ms)\n",
            "daat (7826.999 ms)\n",
            "daat (493.634 ms)\n",
            "daat (751.023 ms)\n",
            "daat (8726.606 ms)\n",
            "daat (19495.129 ms)\n",
            "daat (3502.501 ms)\n",
            "daat (5334.339 ms)\n",
            "daat (15282.535 ms)\n",
            "daat (3866.486 ms)\n",
            "daat (4921.964 ms)\n",
            "daat (6256.504 ms)\n",
            "daat (5986.812 ms)\n",
            "daat (11439.217 ms)\n",
            "daat (4868.940 ms)\n",
            "daat (5076.764 ms)\n",
            "daat (4885.088 ms)\n",
            "daat (17355.196 ms)\n",
            "daat (7153.970 ms)\n",
            "daat (561.150 ms)\n",
            "daat (7036.358 ms)\n",
            "daat (0.823 ms)\n",
            "daat (4590.526 ms)\n",
            "daat (24904.505 ms)\n",
            "daat (5515.496 ms)\n",
            "daat (5327.816 ms)\n",
            "daat (3036.816 ms)\n",
            "daat (640.867 ms)\n",
            "daat (2568.870 ms)\n",
            "daat (6464.344 ms)\n",
            "daat (3127.238 ms)\n",
            "daat (4072.339 ms)\n",
            "daat (31383.785 ms)\n",
            "daat (29982.998 ms)\n",
            "daat (5131.897 ms)\n",
            "daat (6738.769 ms)\n",
            "daat (1496.359 ms)\n",
            "daat (8548.855 ms)\n",
            "daat (16778.242 ms)\n",
            "daat (80086.959 ms)\n",
            "daat (12771.579 ms)\n",
            "daat (2578.485 ms)\n",
            "daat (3870.696 ms)\n",
            "daat (7899.141 ms)\n",
            "daat (8232.072 ms)\n",
            "daat (326.659 ms)\n",
            "daat (16527.935 ms)\n",
            "daat (0.564 ms)\n",
            "daat (2234.104 ms)\n",
            "daat (178.057 ms)\n",
            "daat (9684.327 ms)\n",
            "daat (3479.736 ms)\n",
            "daat (8993.837 ms)\n",
            "daat (25555.615 ms)\n",
            "daat (5445.573 ms)\n",
            "daat (24109.520 ms)\n",
            "daat (5819.765 ms)\n",
            "daat (7459.544 ms)\n",
            "daat (1093.931 ms)\n",
            "daat (16811.291 ms)\n",
            "daat (17594.469 ms)\n",
            "daat (2246.603 ms)\n",
            "Run file saved to: vb_bm25_run.txt\n",
            "Run file 'vb_bm25_run.txt' successfully created.\n"
          ]
        }
      ],
      "source": [
        "# Path to the MS MARCO 2019 test queries file (TSV format: query_id<TAB>query_text)\n",
        "queries_file = \"msmarco-test2019-queries.tsv\"\n",
        "\n",
        "# Name of this retrieval run (appears in the TREC run file)\n",
        "run_name = \"vb_bm25_run\"\n",
        "\n",
        "# Output filename for the TREC-formatted run\n",
        "run_file = run_name + \".txt\"\n",
        "\n",
        "# Read queries from the TSV file and store as a list of tuples: (query_id, query_text)\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "# Using the PyTerrier BM25 retriever (`br`) to process each query,\n",
        "# compute scores for retrieved documents, and write results to a run file\n",
        "write_run_file(\n",
        "    queries,    # list of (query_id, query_text) tuples\n",
        "    inv_ind,    # modified inverted index\n",
        "    run_file,   # output filename for the run file\n",
        "    run_name    # run identifier to appear in the last column of the run file\n",
        ")\n",
        "\n",
        "print(f\"Run file '{run_file}' successfully created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YLvZb0HbGwC"
      },
      "source": [
        "Variable-Byte compression introduces a noticeable time overhead, as evidenced by the higher mean execution times. This increase in processing time is also statistically significant, as confirmed by the paired t-test results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln-e7aclTmdt",
        "outputId": "3cb9adfe-c5e0-445c-ccf0-03ebe1ee3b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T-statistic: -6.3671, P-value: 5.302682e-10\n",
            "Average DAAT BM25 time: 3901.10 ms\n",
            "Average VB DAAT BM25 time: 4997.68 ms\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Paths to files containing execution times (in ms)\n",
        "daat_times_file = \"daat_bm25_time.txt\"        # baseline DAAT BM25 times\n",
        "opt_daat_times_file = \"vb_bm25_time.txt\"  # optimized DAAT BM25 times\n",
        "\n",
        "# Each file contains one time measurement per line (integer milliseconds)\n",
        "with open(daat_times_file, \"r\") as f:\n",
        "    daat_times = [int(line.strip()) for line in f]\n",
        "\n",
        "with open(opt_daat_times_file, \"r\") as f:\n",
        "    opt_daat_times = [int(line.strip()) for line in f]\n",
        "\n",
        "# Perform a paired t-test to determine if the optimization led to a significant difference\n",
        "t_stat, p_val = ttest_rel(daat_times, opt_daat_times)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_val:.6e}\")\n",
        "\n",
        "# Compute and print average execution times for both methods\n",
        "avg_daat = sum(daat_times) / len(daat_times)\n",
        "avg_opt_daat = sum(opt_daat_times) / len(opt_daat_times)\n",
        "\n",
        "print(f\"Average DAAT BM25 time: {avg_daat:.2f} ms\")\n",
        "print(f\"Average VB DAAT BM25 time: {avg_opt_daat:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX6OkThFb9sa"
      },
      "source": [
        "The compressed posting lists show a dramatic reduction in memory usage: the frequency and docID lists occupy approximately 300 MB and 400 MB, respectively, compared to roughly 2 GB for their uncompressed counterparts. This represents a substantial memory savings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZjoHv60V3_y"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def get_size(\n",
        "    inv: Dict[int, Tuple[Any, ...]]\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Computes the approximate memory size of an inverted index stored as a dictionary.\n",
        "\n",
        "    Each entry in the dictionary maps a term ID (int) to a posting list stored as a tuple.\n",
        "\n",
        "    Arguments:\n",
        "        inv (Dict[int, Tuple[Any, ...]]): Inverted index mapping term IDs to posting lists.\n",
        "\n",
        "    Returns:\n",
        "        int: Total memory size in bytes occupied by all posting lists in the index.\n",
        "    \"\"\"\n",
        "    total_bytes: int = 0\n",
        "\n",
        "    # Iterate over each term in the inverted index\n",
        "    for _term_id, posting_list in inv.items():\n",
        "\n",
        "        # Add the size of the tuple object itself\n",
        "        total_bytes += sys.getsizeof(posting_list)\n",
        "\n",
        "    return total_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VTwRDg2QGck",
        "outputId": "550a0f1a-9105-4ff9-cc72-e357fff996f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inv_f size in bytes: 349814331\n",
            "inv_d size in bytes: 446766333\n"
          ]
        }
      ],
      "source": [
        "# Printing Sizes in Bytes of frequency and docid\n",
        "# compressed posting lists\n",
        "print(f\"inv_f size in bytes: {get_size(inv_f)}\")\n",
        "print(f\"inv_d size in bytes: {get_size(inv_d)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVmBaKqKWk0K",
        "outputId": "44a9b3df-76ed-41fd-d78f-a825cafcdd9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uncompressed inv_f size in bytes: 2110350208\n"
          ]
        }
      ],
      "source": [
        "# Loading uncompressed frequency posting lists into\n",
        "# memory and printing size in bytes\n",
        "inv_f = load_object(\"inv_f\")\n",
        "print(f\"uncompressed inv_f size in bytes: {get_size(inv_f)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88uQ8_KuWzvv",
        "outputId": "e8e3f64e-945a-4796-ea28-b8d46e147fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uncompressed inv_d size in bytes: 2110350208\n"
          ]
        }
      ],
      "source": [
        "# Loading uncompressed docids posting lists into\n",
        "# memory and printing size in bytes\n",
        "inv_d = load_object(\"inv_d\")\n",
        "print(f\"uncompressed inv_d size in bytes: {get_size(inv_d)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmGWBA7-ck3I"
      },
      "source": [
        "However, given that a four-second delay is significant in this type of application and that 2 GB of memory is still manageable within RAM without requiring disk offloading, we conclude that the benefits of variable-byte compression do not outweigh its costs in this context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAtHTFM5hhO_"
      },
      "source": [
        "#### PForDelta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OJBd0x6yiiv"
      },
      "source": [
        "FastPFor is a C++ high-performance integer compression library designed to efficiently compress large arrays of integers—such as posting lists in search engines—while maintaining fast decompression speeds. It uses PForDelta (Patched Frame of Reference) techniques combined with SIMD (Single Instruction, Multiple Data) optimizations to compress integer sequences by exploiting their small value ranges and patterns, such as gaps between sorted document IDs. The result is a highly space-efficient representation that can be decoded extremely quickly, making FastPFor ideal for large-scale information retrieval systems, inverted indexes, and analytics applications where both memory efficiency and query speed are critical.\n",
        "PyFastPFor is simply a python wrapper to the C++ library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anZ8tbt0lUVf",
        "outputId": "20e57819-06c3-4011-a3f8-74bb7f67fa65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyfastpfor\n",
            "  Using cached pyfastpfor-1.4.0-cp312-cp312-linux_x86_64.whl\n",
            "Collecting pybind11>=2.4 (from pyfastpfor)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: numpy in ./mircv-venv/lib/python3.12/site-packages (from pyfastpfor) (2.3.4)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Installing collected packages: pybind11, pyfastpfor\n",
            "Successfully installed pybind11-3.0.1 pyfastpfor-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyfastpfor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6atsFoamybY9"
      },
      "source": [
        "This code performs PForDelta compression on the document ID posting lists in an inverted index using the PyFastPFor library. Each posting list is first converted into a NumPy array of 32-bit unsigned integers, then delta-encoded to store the differences between consecutive document IDs—reducing the magnitude of stored numbers and improving compressibility. The SIMD FastPFor codec is then applied to efficiently encode these arrays using vectorized operations. For each posting list, both its original and compressed lengths are recorded to analyze compression performance. By the end of the process, the inv_d structure contains compact, PForDelta-encoded posting lists that use significantly less memory while preserving the ability to be decompressed quickly for retrieval operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jicr9J9DhjDm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pyfastpfor as pfor\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Compressing Document ID Posting Lists Using PyFastPFor (PForDelta)\n",
        "# -------------------------------------------------------------\n",
        "# This code applies PForDelta compression to each posting list of document IDs\n",
        "# in an inverted index. It uses differential encoding (delta4) to store\n",
        "# differences between consecutive docIDs and compresses the result\n",
        "# using SIMD FastPFor codec.\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# Load uncompressed posting lists (term_id -> list of docIDs)\n",
        "inv_d = load_object(\"inv_d\")\n",
        "\n",
        "# Lists to store statistics for analysis\n",
        "inv_d_len = []         # original posting list lengths\n",
        "inv_d_comp_len = []    # compressed lengths (after PForDelta)\n",
        "\n",
        "# Convert each posting list to a contiguous NumPy array of 32-bit unsigned ints\n",
        "for term_id in inv_d:\n",
        "    inv_d[term_id] = np.array(inv_d[term_id], dtype=np.uint32, order=\"C\")  # TODO: che vuol dire order=C?\n",
        "    inv_d_len.append(len(inv_d[term_id]))\n",
        "\n",
        "# Initialize the SIMD FastPFor codec (fast, vectorized compression)\n",
        "codec = pfor.getCodec(\"simdfastpfor128\")\n",
        "\n",
        "# Apply PForDelta compression to each posting list\n",
        "for term_id in inv_d:\n",
        "\n",
        "    # Allocate a temporary buffer to hold the compressed data.\n",
        "    # Adding +64 ensures enough space to accommodate encoded data.\n",
        "    tmp = np.zeros(inv_d_len[term_id] + 64, dtype=np.uint32, order=\"C\")\n",
        "\n",
        "    # Step 1: Apply delta encoding (store gaps between consecutive docIDs)\n",
        "    # This improves compression efficiency since gaps are smaller than raw IDs.\n",
        "    pfor.delta4(inv_d[term_id], inv_d_len[term_id])\n",
        "\n",
        "    # Step 2: Encode the delta-encoded array with SIMD FastPFor\n",
        "    n_len = codec.encodeArray(\n",
        "        inv_d[term_id],               # input array\n",
        "        inv_d_len[term_id],           # number of elements to encode\n",
        "        tmp,                          # output buffer\n",
        "        inv_d_len[term_id] + 64       # buffer size\n",
        "    )\n",
        "\n",
        "    # Save the compressed size for statistics\n",
        "    inv_d_comp_len.append(n_len)\n",
        "\n",
        "    # Replace original posting list with the compressed representation\n",
        "    inv_d[term_id] = tmp[:n_len]     # truncate to actual compressed size\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# After this step:\n",
        "#   - inv_d contains compressed posting lists (PForDelta-encoded)\n",
        "#   - inv_d_len holds original list sizes\n",
        "#   - inv_d_comp_len holds compressed sizes (useful for compression ratio)\n",
        "# -------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab0FEkM5zNQi"
      },
      "source": [
        "This code block calculates and reports how effective the PForDelta compression was on the posting lists. It sums up the total size of all posting lists before and after compression and computes the compression ratio, defined as the compressed size divided by the original size. A ratio below 1.0 indicates successful compression, with lower values reflecting greater space savings. Finally, it prints the result in a readable format, allowing for quick evaluation of how much memory storage was reduced through compression.\n",
        "We achieved a compression ratio similar to VB, now we need to control decoding time overhead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_VmU48Hv2MX",
        "outputId": "44e07793-db7c-4466-b11d-7c40885c615f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compression Ratio: 0.38\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------------------\n",
        "# Compute Compression Statistics for Posting Lists\n",
        "# -------------------------------------------------------------\n",
        "# This block computes how effective the compression was by comparing\n",
        "# the total number of integers before and after compression.\n",
        "# A ratio < 1.0 indicates that compression reduced storage requirements.\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "uncompressed_space = 0   # total number of integers before compression\n",
        "compressed_space = 0     # total number of integers after compression\n",
        "\n",
        "# Iterate through all posting lists in the inverted index\n",
        "for term_id in inv_d:\n",
        "    # Add up the original and compressed sizes for this term\n",
        "    uncompressed_space += inv_d_len[term_id]\n",
        "    compressed_space += inv_d_comp_len[term_id]\n",
        "\n",
        "# Compute the compression ratio\n",
        "# Ratio = (compressed size) / (uncompressed size)\n",
        "ratio = compressed_space / uncompressed_space\n",
        "\n",
        "# Display results with two decimal precision\n",
        "print(f\"Compression Ratio: {ratio:.2f}\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Example interpretation:\n",
        "#   Compression Ratio = 0.35  →  the compressed index uses ~35% of the space\n",
        "#   Compression Ratio = 1.00  →  no compression benefit\n",
        "# -------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHHk806J0DNl"
      },
      "source": [
        "This function, decode_pfor, decompresses a posting list that was previously encoded using the PForDelta (SIMD FastPFor) algorithm. It takes a term ID and retrieves its compressed data from the inverted index (inv_d), along with the corresponding original and compressed lengths. The function then allocates a NumPy array to hold the decoded integers and calls the codec's decodeArray method to reconstruct the original posting list. Finally, it replaces the compressed array in inv_d with the fully decompressed version, restoring the posting list to its original state in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8K6J8bKr6cV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pyfastpfor as pfor\n",
        "from typing import Dict\n",
        "\n",
        "@profile\n",
        "def decode_pfor(\n",
        "    term_id: int,\n",
        "    inv_d: Dict[int, np.ndarray],\n",
        "    inv_d_len: Dict[int, int],\n",
        "    inv_d_comp_len: Dict[int, int],\n",
        "    codec: 'pfor.Codec'\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Decodes a posting list that was previously compressed using\n",
        "        PForDelta (SIMD FastPFor). The function replaces the compressed\n",
        "        posting list with its decompressed version in-place.\n",
        "\n",
        "    Arguments:\n",
        "        term_id (int): The term ID whose posting list will be decoded.\n",
        "        inv_d (Dict[int, np.ndarray]): Dictionary mapping each term ID\n",
        "            to its compressed posting list.\n",
        "        inv_d_len (Dict[int, int]): Dictionary containing the original\n",
        "            (uncompressed) length of each posting list.\n",
        "        inv_d_comp_len (Dict[int, int]): Dictionary containing the\n",
        "            compressed length of each posting list.\n",
        "        codec (pfor.Codec): The PForDelta codec instance used to\n",
        "            encode/decode posting lists.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "        (The function modifies `inv_d` in-place by replacing the compressed\n",
        "        array with its decompressed version.)\n",
        "    \"\"\"\n",
        "\n",
        "    # Allocate a temporary NumPy array to store the decompressed integers\n",
        "    tmp = np.zeros(\n",
        "        inv_d_len[term_id],\n",
        "        dtype=np.uint32,\n",
        "        order=\"C\"\n",
        "    )  # TODO: scrivere order=C meaning\n",
        "\n",
        "    # Perform the actual PForDelta decoding\n",
        "    # decodeArray(src, src_len, dest, dest_len)\n",
        "    codec.decodeArray(\n",
        "        inv_d[term_id],           # compressed data\n",
        "        inv_d_comp_len[term_id],  # number of compressed integers\n",
        "        tmp,                      # destination buffer\n",
        "        inv_d_len[term_id]        # expected number of decoded integers\n",
        "    )\n",
        "\n",
        "    # Replace the compressed posting list with the decompressed one\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz5V7PW7za2I"
      },
      "source": [
        "The total time to decode all posting lists is approximately 9 seconds, which means the decoding time for each individual posting list is well under one millisecond. So the overhead is basicaly non-existant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61N3OsYWsaN-",
        "outputId": "144e64ec-f541-4dbb-ef91-2bea0ff04b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decode_pfor (0.081 ms)\n",
            "decode_pfor (0.415 ms)\n",
            "decode_pfor (0.059 ms)\n",
            "decode_pfor (0.122 ms)\n",
            "decode_pfor (0.594 ms)\n",
            "decode_pfor (0.085 ms)\n",
            "decode_pfor (0.161 ms)\n",
            "decode_pfor (0.210 ms)\n",
            "decode_pfor (0.082 ms)\n",
            "decode_pfor (0.040 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (1.566 ms)\n",
            "decode_pfor (0.114 ms)\n",
            "decode_pfor (0.101 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.103 ms)\n",
            "decode_pfor (0.056 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.306 ms)\n",
            "decode_pfor (0.450 ms)\n",
            "decode_pfor (0.113 ms)\n",
            "decode_pfor (0.075 ms)\n",
            "decode_pfor (0.209 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.198 ms)\n",
            "decode_pfor (0.208 ms)\n",
            "decode_pfor (0.113 ms)\n",
            "decode_pfor (0.147 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.286 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.167 ms)\n",
            "decode_pfor (0.493 ms)\n",
            "decode_pfor (0.163 ms)\n",
            "decode_pfor (0.118 ms)\n",
            "decode_pfor (0.128 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.088 ms)\n",
            "decode_pfor (1.475 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.153 ms)\n",
            "decode_pfor (0.376 ms)\n",
            "decode_pfor (0.054 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.096 ms)\n",
            "decode_pfor (0.066 ms)\n",
            "decode_pfor (0.295 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.262 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.147 ms)\n",
            "decode_pfor (0.144 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.068 ms)\n",
            "decode_pfor (0.176 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.158 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.109 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.105 ms)\n",
            "decode_pfor (0.094 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.175 ms)\n",
            "decode_pfor (0.061 ms)\n",
            "decode_pfor (0.077 ms)\n",
            "decode_pfor (0.108 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.497 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.083 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.167 ms)\n",
            "decode_pfor (0.083 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.133 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.242 ms)\n",
            "decode_pfor (0.447 ms)\n",
            "decode_pfor (0.113 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.089 ms)\n",
            "decode_pfor (0.103 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.205 ms)\n",
            "decode_pfor (0.140 ms)\n",
            "decode_pfor (0.082 ms)\n",
            "decode_pfor (0.103 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.053 ms)\n",
            "decode_pfor (0.795 ms)\n",
            "decode_pfor (0.086 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.090 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.069 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.085 ms)\n",
            "decode_pfor (0.130 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.107 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.081 ms)\n",
            "decode_pfor (0.040 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.171 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.598 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.054 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.103 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.076 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.207 ms)\n",
            "decode_pfor (0.054 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.120 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.318 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.245 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.153 ms)\n",
            "decode_pfor (0.354 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.267 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (1.184 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.272 ms)\n",
            "decode_pfor (0.073 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "decode_pfor (0.601 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.064 ms)\n",
            "decode_pfor (0.104 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.077 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.077 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.213 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.056 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.040 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "decode_pfor (0.229 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.162 ms)\n",
            "decode_pfor (0.068 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.059 ms)\n",
            "decode_pfor (0.098 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.079 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.196 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.085 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.182 ms)\n",
            "decode_pfor (0.173 ms)\n",
            "decode_pfor (0.082 ms)\n",
            "decode_pfor (0.064 ms)\n",
            "decode_pfor (0.132 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.079 ms)\n",
            "decode_pfor (0.109 ms)\n",
            "decode_pfor (0.115 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.135 ms)\n",
            "decode_pfor (0.075 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.075 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.232 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.126 ms)\n",
            "decode_pfor (0.131 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.063 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.092 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.089 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.065 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.131 ms)\n",
            "decode_pfor (0.077 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.147 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.194 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.152 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.209 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.080 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.120 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.180 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.200 ms)\n",
            "decode_pfor (0.117 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.105 ms)\n",
            "decode_pfor (0.085 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.126 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.144 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.052 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.095 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.082 ms)\n",
            "decode_pfor (0.073 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.080 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.064 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.276 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.361 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.076 ms)\n",
            "decode_pfor (0.126 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.109 ms)\n",
            "decode_pfor (0.084 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.108 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.070 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.118 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "decode_pfor (0.124 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.122 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.089 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "decode_pfor (0.160 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.223 ms)\n",
            "decode_pfor (0.489 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.040 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.059 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.081 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.068 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.052 ms)\n",
            "decode_pfor (0.101 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.069 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.069 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "decode_pfor (0.126 ms)\n",
            "decode_pfor (0.091 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.087 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.099 ms)\n",
            "decode_pfor (0.063 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.084 ms)\n",
            "decode_pfor (0.053 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.160 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "decode_pfor (0.144 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.073 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "decode_pfor (0.078 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.065 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.066 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.115 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.136 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.091 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.112 ms)\n",
            "decode_pfor (0.063 ms)\n",
            "decode_pfor (0.103 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.059 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.142 ms)\n",
            "decode_pfor (0.090 ms)\n",
            "decode_pfor (0.089 ms)\n",
            "decode_pfor (0.149 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.126 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.103 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.061 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "decode_pfor (0.340 ms)\n",
            "decode_pfor (0.144 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.061 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.071 ms)\n",
            "decode_pfor (0.371 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.135 ms)\n",
            "decode_pfor (0.096 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.162 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "decode_pfor (0.094 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.121 ms)\n",
            "decode_pfor (0.108 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.059 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.211 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.162 ms)\n",
            "decode_pfor (0.093 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.080 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.056 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.161 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.092 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.061 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.068 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.064 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.154 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.073 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.076 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.065 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.003 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.002 ms)\n",
            "decode_pfor (0.003 ms)\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------- #\n",
        "# Decode all posting lists using PForDelta (SIMD FastPFor codec)\n",
        "# ------------------------------------------------------------- #\n",
        "\n",
        "# Setting a limit to the number of posting lists decoded because otherwise\n",
        "# the output console will explode, (simply handled with a counter)\n",
        "max_postings = 1000\n",
        "cnt = 0\n",
        "\n",
        "# Iterate over each term ID in the inverted index dictionary\n",
        "for term_id in inv_d:\n",
        "\n",
        "    # Updating Counter and evaluating Exit Conditions\n",
        "    cnt += 1\n",
        "    if cnt >= max_postings:\n",
        "        break\n",
        "\n",
        "    # Decode the posting list for this term ID\n",
        "    # This function replaces the compressed NumPy array stored in inv_d[term_id]\n",
        "    # with its decompressed version, restoring the original document IDs.\n",
        "    decode_pfor(\n",
        "        term_id,           # term identifier\n",
        "        inv_d,             # dictionary containing compressed posting lists\n",
        "        inv_d_len,         # dictionary of original posting list lengths\n",
        "        inv_d_comp_len,    # dictionary of compressed posting list lengths\n",
        "        codec              # PForDelta codec used for decoding\n",
        "    )\n",
        "\n",
        "# At the end of this loop, all posting lists in inv_d are fully decoded\n",
        "# and can be directly used for scoring or query evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jHZrX4EuenQ"
      },
      "source": [
        "The mean value is 0.0096 ms, that applied to the above mentioned method is negligible with respect to the execution time which is 4 orders of magnitude above.\n",
        "The limitation with this approach is that it relies on NumPy arrays, which are incompatible with the previously optimized method that depends on native Python lists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0fCMiH2Pemm"
      },
      "source": [
        "#### Testing DecodePFor + Precomputed Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4znNv33Pemm"
      },
      "source": [
        "I modified the inverted index class so that it not only decodes the posting list with document IDs but also converts it directly into a Python list. Afterward, I ran the usual procedure to extract execution times and printed summary statistics. Remarkably, we achieved a compression ratio of about one third of the original inv_d size without incurring any noticeable time overhead.\n",
        "\n",
        "This efficiency stems from two factors: the use of an optimized algorithm and the fact that decompression is handled internally by C++ compiled code, which is far faster than equivalent Python operations. If the entire search engine were implemented in C++, we would likely observe a non‑negligible overhead, but in this hybrid setup the performance remains virtually unaffected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRDT9V_Rr-j2"
      },
      "outputs": [],
      "source": [
        "# TODO: fare sta cosa è meglio rispetto a runnare con np.array?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MkVtMnDPemm"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Callable, Optional\n",
        "\n",
        "\n",
        "class InvertedIndex:\n",
        "\n",
        "    class PostingListIterator:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Iterator over a posting list for a single term in the inverted index.\n",
        "        Arguments:\n",
        "            docids (np.ndarray): Array of document IDs containing the term.\n",
        "            freqs (np.ndarray): Array of term frequencies corresponding to docids.\n",
        "            doc (Dict[int, Tuple]): Dictionary storing document statistics (e.g., length).\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(\n",
        "            self,\n",
        "            docids: np.ndarray,\n",
        "            freqs: np.ndarray,\n",
        "            termid: int,\n",
        "            token: str,\n",
        "            lexicon: Dict[str, Tuple],\n",
        "            doc: Dict[int, Tuple],\n",
        "            stats: Dict[str, int],\n",
        "            scorer: Callable[['InvertedIndex.PostingListIterator'], float]\n",
        "        ):\n",
        "            self.docids = docids\n",
        "            self.freqs = freqs\n",
        "            self.pos = 0\n",
        "            self.termid = termid\n",
        "            self.token = token\n",
        "            self.lexicon = lexicon\n",
        "            self.doc = doc\n",
        "            self.stats = stats\n",
        "            self._scorer = scorer\n",
        "\n",
        "        def docid(self) -> int | float:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the current document ID.\n",
        "            Returns:\n",
        "                int: Current document ID, or math.inf if iterator is at the end.\n",
        "            \"\"\"\n",
        "            return math.inf if self._is_end_list() else self.docids[self.pos]\n",
        "\n",
        "        def score(self) -> float:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Computes the score for the current document, which is constant\n",
        "                for every document in the same posting\n",
        "            Returns:\n",
        "                float: Score for the current document, or math.inf if iterator is at the end.\n",
        "            \"\"\"\n",
        "            return self._scorer(self)\n",
        "\n",
        "        def next(self, target: Optional[int] = None):\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Advances the iterator. If target is provided, jump to the first document\n",
        "                with ID >= target.\n",
        "            Arguments:\n",
        "                target (Optional[int]): Target document ID to skip to. Default is None.\n",
        "            \"\"\"\n",
        "            if target is None:\n",
        "                if not self._is_end_list():\n",
        "                    self.pos += 1\n",
        "            elif target > self.docid():\n",
        "                self.pos = np.searchsorted(self.docids, target, side='left')\n",
        "\n",
        "        def len(self) -> int:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Returns the number of documents in the posting list.\n",
        "            Returns:\n",
        "                int: Length of the posting list.\n",
        "            \"\"\"\n",
        "            return len(self.docids)\n",
        "\n",
        "        def _is_end_list(self) -> bool:\n",
        "            \"\"\"\n",
        "            Description:\n",
        "                Checks whether the iterator has reached the end of the posting list.\n",
        "            Returns:\n",
        "                bool: True if at end, False otherwise.\n",
        "            \"\"\"\n",
        "            return self.pos >= len(self.docids)\n",
        "\n",
        "    # ----------------- InvertedIndex main ----------------- #\n",
        "\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Inverted index storing the mapping from terms to posting lists, along with\n",
        "        document statistics.\n",
        "    Arguments:\n",
        "        lexicon (Dict[str, Tuple[int, ...]]): Maps token to (termid, ...).\n",
        "        inv_d (List[np.ndarray]): List of arrays of document IDs per term.\n",
        "        inv_f (List[np.ndarray]): List of arrays of term frequencies per term.\n",
        "        doc (Dict[int, Tuple]): Document statistics dictionary.\n",
        "        stats (Dict[str, int]): Global statistics like number of documents.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        lexicon: Dict[str, Tuple[int, ...]],\n",
        "        inv_d: List[np.ndarray],\n",
        "        inv_f: List[np.ndarray],\n",
        "        doc: Dict[int, Tuple],\n",
        "        stats: Dict[str, int],\n",
        "        scorer: Callable[['InvertedIndex.PostingListIterator'], float]\n",
        "    ):\n",
        "        self.lexicon = lexicon\n",
        "        self.inv_d = inv_d\n",
        "        self.inv_f = inv_f\n",
        "        self.doc = doc\n",
        "        self.stats = stats\n",
        "        self.scorer = scorer\n",
        "\n",
        "    def num_docs(self) -> int:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns the total number of documents in the index.\n",
        "        Returns:\n",
        "            int: Number of documents.\n",
        "        \"\"\"\n",
        "        return self.stats['num_docs']\n",
        "\n",
        "    def get_posting(self, termid: int, term: str) -> 'PostingListIterator':\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a PostingListIterator for a given term ID.\n",
        "        Arguments:\n",
        "            termid (int): The term ID to retrieve the posting list for.\n",
        "        Returns:\n",
        "            PostingListIterator: Iterator over the posting list.\n",
        "        \"\"\"\n",
        "\n",
        "        # Decoding inv_d\n",
        "        decoded_inv_d = decode_pfor(\n",
        "            termid,           # term identifier\n",
        "            inv_d,             # dictionary containing compressed posting lists\n",
        "            inv_d_len,         # dictionary of original posting list lengths\n",
        "            inv_d_comp_len,    # dictionary of compressed posting list lengths\n",
        "            codec              # PForDelta codec used for decoding\n",
        "        )\n",
        "\n",
        "        # Converting inv_d to python list\n",
        "        decoded_inv_d = decoded_inv_d.tolist()\n",
        "\n",
        "        return InvertedIndex.PostingListIterator(\n",
        "            decoded_inv_d,\n",
        "            self.inv_f[termid],\n",
        "            termid,\n",
        "            term,\n",
        "            self.lexicon,\n",
        "            self.doc,\n",
        "            self.stats,\n",
        "            self.scorer\n",
        "        )\n",
        "\n",
        "    def get_termids(self, tokens: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of term IDs for the tokens that exist in the lexicon.\n",
        "        Arguments:\n",
        "            tokens (List[str]): List of tokens to look up.\n",
        "        Returns:\n",
        "            List[int]: List of corresponding term IDs.\n",
        "        \"\"\"\n",
        "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
        "\n",
        "    def get_postings(\n",
        "        self,\n",
        "        termids: List[int],\n",
        "        terms: List[str]\n",
        "    ) -> List['PostingListIterator']:\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Returns a list of PostingListIterators for a list of term IDs.\n",
        "        Arguments:\n",
        "            termids (List[int]): List of term IDs.\n",
        "        Returns:\n",
        "            List[PostingListIterator]: List of posting list iterators.\n",
        "        \"\"\"\n",
        "        return [self.get_posting(termid, term) for termid, term in zip(termids, terms)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cangmKMKPemm",
        "outputId": "d2e0e9ed-9d86-4cfb-fd3f-c98e93752811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (0.580 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (9.568 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "daat (117.372 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "daat (42.174 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "decode_pfor (0.065 ms)\n",
            "decode_pfor (0.535 ms)\n",
            "decode_pfor (0.256 ms)\n",
            "daat (2300.110 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "daat (100.725 ms)\n",
            "decode_pfor (0.054 ms)\n",
            "decode_pfor (0.109 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "daat (478.214 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (47.374 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.053 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.129 ms)\n",
            "daat (475.394 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (77.520 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (16.774 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.087 ms)\n",
            "daat (163.239 ms)\n",
            "decode_pfor (0.063 ms)\n",
            "decode_pfor (0.100 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.069 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "daat (894.880 ms)\n",
            "decode_pfor (0.069 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "daat (82.430 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.138 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "daat (317.416 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "daat (494.234 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.081 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "daat (211.012 ms)\n",
            "decode_pfor (0.381 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.132 ms)\n",
            "daat (929.358 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.106 ms)\n",
            "decode_pfor (0.322 ms)\n",
            "daat (1402.452 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "daat (83.628 ms)\n",
            "decode_pfor (0.069 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "daat (119.217 ms)\n",
            "decode_pfor (0.339 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "daat (1118.985 ms)\n",
            "decode_pfor (0.147 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.138 ms)\n",
            "decode_pfor (0.232 ms)\n",
            "daat (1505.999 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "daat (305.317 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "daat (55.517 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "daat (219.114 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "daat (137.073 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "daat (8.410 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "daat (215.263 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.183 ms)\n",
            "daat (428.043 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "daat (130.663 ms)\n",
            "decode_pfor (0.094 ms)\n",
            "decode_pfor (0.112 ms)\n",
            "decode_pfor (0.202 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "daat (893.835 ms)\n",
            "decode_pfor (0.070 ms)\n",
            "decode_pfor (0.098 ms)\n",
            "daat (183.235 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "decode_pfor (0.103 ms)\n",
            "daat (170.108 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (4.664 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "daat (132.987 ms)\n",
            "decode_pfor (0.193 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "daat (664.106 ms)\n",
            "decode_pfor (0.175 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.066 ms)\n",
            "daat (502.373 ms)\n",
            "decode_pfor (0.143 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "daat (292.214 ms)\n",
            "decode_pfor (0.197 ms)\n",
            "decode_pfor (0.163 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "daat (405.709 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.177 ms)\n",
            "daat (301.281 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.194 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "daat (299.611 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.235 ms)\n",
            "decode_pfor (0.163 ms)\n",
            "daat (360.143 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.107 ms)\n",
            "daat (306.047 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.218 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.066 ms)\n",
            "daat (1080.991 ms)\n",
            "decode_pfor (0.101 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "daat (161.336 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "daat (224.431 ms)\n",
            "decode_pfor (0.059 ms)\n",
            "decode_pfor (0.206 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.064 ms)\n",
            "daat (1410.688 ms)\n",
            "decode_pfor (0.066 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.168 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "daat (513.978 ms)\n",
            "decode_pfor (0.070 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "daat (340.273 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.040 ms)\n",
            "decode_pfor (0.175 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.052 ms)\n",
            "daat (852.240 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.079 ms)\n",
            "daat (161.947 ms)\n",
            "decode_pfor (0.102 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "daat (162.045 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.152 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "daat (708.050 ms)\n",
            "decode_pfor (0.249 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "daat (143.869 ms)\n",
            "decode_pfor (0.144 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "daat (292.785 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.165 ms)\n",
            "daat (285.492 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "daat (70.628 ms)\n",
            "decode_pfor (0.053 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "daat (91.518 ms)\n",
            "decode_pfor (0.124 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "daat (225.736 ms)\n",
            "decode_pfor (0.281 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.202 ms)\n",
            "daat (828.418 ms)\n",
            "decode_pfor (0.295 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.206 ms)\n",
            "decode_pfor (0.085 ms)\n",
            "decode_pfor (0.375 ms)\n",
            "decode_pfor (0.080 ms)\n",
            "daat (2405.544 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.174 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "daat (587.488 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.129 ms)\n",
            "decode_pfor (0.199 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "daat (849.557 ms)\n",
            "decode_pfor (0.152 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.042 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (651.441 ms)\n",
            "decode_pfor (0.171 ms)\n",
            "decode_pfor (0.037 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.150 ms)\n",
            "daat (817.981 ms)\n",
            "decode_pfor (0.156 ms)\n",
            "decode_pfor (0.115 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "daat (409.796 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.112 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "daat (356.208 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.120 ms)\n",
            "decode_pfor (0.079 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "daat (612.561 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "decode_pfor (0.146 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "daat (473.364 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "decode_pfor (0.118 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "daat (342.112 ms)\n",
            "decode_pfor (0.178 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (104.834 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.118 ms)\n",
            "daat (181.233 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "daat (200.127 ms)\n",
            "decode_pfor (0.437 ms)\n",
            "decode_pfor (0.180 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "daat (424.676 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.091 ms)\n",
            "daat (156.593 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.169 ms)\n",
            "decode_pfor (0.054 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.274 ms)\n",
            "daat (1645.904 ms)\n",
            "decode_pfor (0.301 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "daat (213.445 ms)\n",
            "decode_pfor (0.237 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.115 ms)\n",
            "daat (259.349 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.052 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (231.072 ms)\n",
            "decode_pfor (0.259 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "daat (211.627 ms)\n",
            "decode_pfor (0.214 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.160 ms)\n",
            "daat (400.022 ms)\n",
            "decode_pfor (0.199 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.088 ms)\n",
            "decode_pfor (0.175 ms)\n",
            "daat (1065.742 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (6.736 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.184 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "daat (953.186 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.089 ms)\n",
            "daat (293.170 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.213 ms)\n",
            "daat (82.865 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "daat (82.972 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (183.465 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.227 ms)\n",
            "daat (155.909 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.078 ms)\n",
            "decode_pfor (0.183 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "daat (1673.667 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.228 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "daat (221.460 ms)\n",
            "decode_pfor (0.071 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "daat (171.297 ms)\n",
            "decode_pfor (0.060 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "daat (324.839 ms)\n",
            "decode_pfor (0.064 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "daat (219.667 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.200 ms)\n",
            "decode_pfor (0.156 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "daat (1017.171 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "daat (231.010 ms)\n",
            "decode_pfor (0.210 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.068 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "daat (577.139 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.150 ms)\n",
            "daat (282.770 ms)\n",
            "decode_pfor (0.052 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.080 ms)\n",
            "daat (278.958 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "daat (450.950 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.142 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "daat (446.246 ms)\n",
            "decode_pfor (0.159 ms)\n",
            "decode_pfor (0.068 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "daat (767.946 ms)\n",
            "decode_pfor (0.138 ms)\n",
            "decode_pfor (0.043 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (420.957 ms)\n",
            "decode_pfor (0.161 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.123 ms)\n",
            "decode_pfor (0.061 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "decode_pfor (0.053 ms)\n",
            "daat (1134.213 ms)\n",
            "decode_pfor (0.133 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "daat (676.777 ms)\n",
            "decode_pfor (0.170 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "decode_pfor (0.118 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "daat (1150.930 ms)\n",
            "decode_pfor (0.194 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.123 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.082 ms)\n",
            "decode_pfor (0.253 ms)\n",
            "daat (2148.257 ms)\n",
            "decode_pfor (0.244 ms)\n",
            "decode_pfor (0.122 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.214 ms)\n",
            "daat (1519.138 ms)\n",
            "decode_pfor (0.208 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "decode_pfor (0.126 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "daat (1055.368 ms)\n",
            "decode_pfor (0.054 ms)\n",
            "decode_pfor (0.056 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "daat (231.907 ms)\n",
            "decode_pfor (0.279 ms)\n",
            "decode_pfor (0.040 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.148 ms)\n",
            "daat (779.683 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.185 ms)\n",
            "decode_pfor (0.040 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.118 ms)\n",
            "daat (538.271 ms)\n",
            "decode_pfor (0.054 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.116 ms)\n",
            "decode_pfor (0.336 ms)\n",
            "decode_pfor (0.159 ms)\n",
            "daat (2363.264 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.117 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.272 ms)\n",
            "daat (1286.289 ms)\n",
            "decode_pfor (0.323 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "daat (500.529 ms)\n",
            "decode_pfor (0.137 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.087 ms)\n",
            "decode_pfor (0.035 ms)\n",
            "decode_pfor (0.127 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (1385.679 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.105 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "daat (545.681 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (174.499 ms)\n",
            "decode_pfor (0.088 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "daat (343.171 ms)\n",
            "decode_pfor (0.513 ms)\n",
            "decode_pfor (0.089 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.216 ms)\n",
            "daat (2200.625 ms)\n",
            "decode_pfor (0.312 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "daat (578.690 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.143 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (369.802 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (13.011 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.129 ms)\n",
            "daat (604.547 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (6.744 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "daat (92.389 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "daat (522.165 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.113 ms)\n",
            "daat (230.554 ms)\n",
            "decode_pfor (0.252 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "daat (409.843 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.218 ms)\n",
            "daat (228.126 ms)\n",
            "decode_pfor (0.062 ms)\n",
            "decode_pfor (0.454 ms)\n",
            "decode_pfor (0.095 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "daat (793.840 ms)\n",
            "decode_pfor (0.218 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "daat (623.201 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "daat (137.589 ms)\n",
            "decode_pfor (0.041 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "daat (415.778 ms)\n",
            "decode_pfor (0.154 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.087 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (827.878 ms)\n",
            "decode_pfor (0.187 ms)\n",
            "decode_pfor (0.101 ms)\n",
            "daat (226.693 ms)\n",
            "decode_pfor (0.122 ms)\n",
            "decode_pfor (0.172 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "daat (356.642 ms)\n",
            "decode_pfor (0.229 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.050 ms)\n",
            "daat (178.452 ms)\n",
            "decode_pfor (0.045 ms)\n",
            "decode_pfor (0.090 ms)\n",
            "daat (254.146 ms)\n",
            "decode_pfor (0.244 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "daat (148.869 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "daat (65.902 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.122 ms)\n",
            "daat (23.235 ms)\n",
            "decode_pfor (0.048 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "daat (193.322 ms)\n",
            "decode_pfor (0.142 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (139.347 ms)\n",
            "decode_pfor (0.067 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "daat (93.847 ms)\n",
            "decode_pfor (0.128 ms)\n",
            "decode_pfor (0.266 ms)\n",
            "decode_pfor (0.112 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "daat (715.341 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.629 ms)\n",
            "daat (1022.844 ms)\n",
            "decode_pfor (0.082 ms)\n",
            "decode_pfor (0.015 ms)\n",
            "decode_pfor (0.151 ms)\n",
            "daat (578.434 ms)\n",
            "decode_pfor (0.261 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.053 ms)\n",
            "daat (440.340 ms)\n",
            "decode_pfor (0.039 ms)\n",
            "decode_pfor (0.175 ms)\n",
            "decode_pfor (0.063 ms)\n",
            "daat (178.936 ms)\n",
            "decode_pfor (0.092 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.224 ms)\n",
            "daat (719.579 ms)\n",
            "decode_pfor (0.211 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.061 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (225.330 ms)\n",
            "decode_pfor (0.246 ms)\n",
            "decode_pfor (0.203 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "daat (486.534 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.174 ms)\n",
            "daat (18.226 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.159 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "daat (556.286 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "decode_pfor (0.047 ms)\n",
            "daat (85.553 ms)\n",
            "decode_pfor (0.055 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "daat (80.250 ms)\n",
            "decode_pfor (0.089 ms)\n",
            "decode_pfor (0.176 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "daat (597.553 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.056 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (229.207 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "daat (0.323 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (10.459 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "daat (17.984 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "daat (46.162 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "daat (0.015 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.005 ms)\n",
            "daat (19.449 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (20.936 ms)\n",
            "decode_pfor (0.052 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (91.264 ms)\n",
            "decode_pfor (0.117 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "daat (24.483 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "daat (0.039 ms)\n",
            "decode_pfor (0.051 ms)\n",
            "decode_pfor (0.020 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "daat (143.358 ms)\n",
            "decode_pfor (0.025 ms)\n",
            "daat (0.021 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "decode_pfor (0.074 ms)\n",
            "daat (244.009 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "decode_pfor (0.031 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "daat (169.117 ms)\n",
            "decode_pfor (0.689 ms)\n",
            "decode_pfor (0.064 ms)\n",
            "decode_pfor (0.026 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "daat (1769.196 ms)\n",
            "decode_pfor (0.080 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "daat (135.370 ms)\n",
            "decode_pfor (0.110 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.009 ms)\n",
            "daat (349.095 ms)\n",
            "decode_pfor (0.028 ms)\n",
            "decode_pfor (0.150 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "daat (383.817 ms)\n",
            "decode_pfor (0.087 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "decode_pfor (0.100 ms)\n",
            "daat (354.447 ms)\n",
            "decode_pfor (0.068 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "daat (124.833 ms)\n",
            "decode_pfor (0.102 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (144.669 ms)\n",
            "decode_pfor (0.032 ms)\n",
            "decode_pfor (0.049 ms)\n",
            "decode_pfor (0.180 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "daat (560.357 ms)\n",
            "decode_pfor (0.087 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.010 ms)\n",
            "daat (170.975 ms)\n",
            "decode_pfor (0.072 ms)\n",
            "decode_pfor (0.172 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "decode_pfor (0.085 ms)\n",
            "daat (716.056 ms)\n",
            "decode_pfor (0.121 ms)\n",
            "decode_pfor (0.033 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "daat (482.352 ms)\n",
            "decode_pfor (0.206 ms)\n",
            "decode_pfor (0.141 ms)\n",
            "decode_pfor (0.044 ms)\n",
            "decode_pfor (0.029 ms)\n",
            "daat (578.562 ms)\n",
            "decode_pfor (0.240 ms)\n",
            "decode_pfor (0.021 ms)\n",
            "daat (270.095 ms)\n",
            "decode_pfor (0.034 ms)\n",
            "decode_pfor (0.155 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.004 ms)\n",
            "daat (922.607 ms)\n",
            "decode_pfor (0.200 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "decode_pfor (0.177 ms)\n",
            "daat (458.695 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.014 ms)\n",
            "decode_pfor (0.119 ms)\n",
            "daat (280.919 ms)\n",
            "decode_pfor (0.046 ms)\n",
            "decode_pfor (0.017 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "decode_pfor (0.019 ms)\n",
            "decode_pfor (0.006 ms)\n",
            "daat (150.239 ms)\n",
            "decode_pfor (0.111 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.058 ms)\n",
            "daat (411.907 ms)\n",
            "decode_pfor (0.056 ms)\n",
            "decode_pfor (0.057 ms)\n",
            "decode_pfor (0.027 ms)\n",
            "decode_pfor (0.016 ms)\n",
            "daat (315.750 ms)\n",
            "decode_pfor (0.096 ms)\n",
            "decode_pfor (0.012 ms)\n",
            "decode_pfor (0.011 ms)\n",
            "daat (214.944 ms)\n",
            "decode_pfor (0.030 ms)\n",
            "decode_pfor (0.061 ms)\n",
            "daat (128.093 ms)\n",
            "decode_pfor (0.023 ms)\n",
            "daat (0.053 ms)\n",
            "decode_pfor (0.036 ms)\n",
            "decode_pfor (0.018 ms)\n",
            "decode_pfor (0.038 ms)\n",
            "decode_pfor (0.013 ms)\n",
            "daat (224.754 ms)\n",
            "decode_pfor (0.052 ms)\n",
            "decode_pfor (0.097 ms)\n",
            "decode_pfor (0.008 ms)\n",
            "daat (294.087 ms)\n",
            "decode_pfor (0.024 ms)\n",
            "daat (0.018 ms)\n",
            "decode_pfor (0.022 ms)\n",
            "decode_pfor (0.082 ms)\n",
            "decode_pfor (0.007 ms)\n",
            "daat (236.780 ms)\n",
            "Run file saved to: precomputed_pfor_bm25_run.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# File where the test queries are stored\n",
        "queries_file = \"msmarco-test2020-queries.tsv\"\n",
        "\n",
        "# Name of the run with the precomputed bm25 weights\n",
        "run_name = \"precomputed_pfor_bm25_run\"\n",
        "\n",
        "# Name of the file where the run will be stored\n",
        "run_file = run_name + \".txt\"\n",
        "\n",
        "# Scorer Leveraging PreComputed Weights\n",
        "scorer = PreComputedScorer()\n",
        "# TODO non bisogna ricomputarli prima? forse mi sbalio e non sono al posto delle frequenze, in caso contrario vanno riocmputati però\n",
        "\n",
        "# Extracting queries from test queries file\n",
        "queries = extract_queries(queries_file)\n",
        "\n",
        "\n",
        "# Initialize the inverted index with the current scoring function\n",
        "# This allows different retrieval models (e.g., TF, TF-IDF, BM25)\n",
        "inv_ind = InvertedIndex(\n",
        "    lexicon,       # term -> (termid, ...) mapping\n",
        "    inv_d,         # list of numpy arrays: doc IDs per term\n",
        "    inv_f,         # list of numpy arrays: term frequencies per term\n",
        "    doc_index,     # document statistics\n",
        "    stats,         # global statistics (e.g., total # of documents)\n",
        "    scorer=scorer  # scoring function to use for this run\n",
        ")\n",
        "\n",
        "# Generate and write a TREC-formatted run file for the current query set\n",
        "# The filename combines the run name and the run suffix\n",
        "write_run_file(\n",
        "    queries,              # queries to process\n",
        "    inv_ind,              # inverted index with current scoring function\n",
        "    run_file,             # output filename for this run\n",
        "    run_name              # run identifier (appears in run file)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMZ-mLXJPemm",
        "outputId": "dce0974e-3c03-422d-e121-95ba631eed00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 439.85722000000004\n",
            "Geometric Mean: 196.31518052253884\n",
            "Median: 284.131\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import gmean\n",
        "\n",
        "\n",
        "# Declaring path to the file containing execution times (one per line)\n",
        "# and the list that will hold execution times\n",
        "time_filename = \"opt_daat_pfor_bm25_time.txt\"\n",
        "times = []\n",
        "\n",
        "# Open the file, read all lines and convert them into a list\n",
        "with open(time_filename, \"r\") as f:\n",
        "    lines = f.readlines()                   # Reading Lines\n",
        "    times = [float(line) for line in lines] # Converting using list comprehension\n",
        "\n",
        "# Arithmetic mean\n",
        "mean = sum(times) / len(times)\n",
        "\n",
        "# Geometric mean is useful for averaging ratios or times when values\n",
        "# vary multiplicatively, it's computed with scipy package to avoid overflow\n",
        "geo_mean = gmean(times)\n",
        "\n",
        "# Sort the list of times to prepare for median calculation and extract\n",
        "# length as it will avoid lengthy expression\n",
        "sorted_times = sorted(times)\n",
        "l = len(sorted_times)\n",
        "\n",
        "# If the number of elements is odd, take the middle element\n",
        "if l % 2 == 1:\n",
        "    median = sorted_times[l // 2]\n",
        "# If even, take the average of the two middle elements\n",
        "else:\n",
        "    median = (sorted_times[l // 2] + sorted_times[(l // 2) - 1]) / 2\n",
        "\n",
        "# Print results\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Geometric Mean:\", geo_mean)\n",
        "print(\"Median:\", median)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwWiSJSWPkG7"
      },
      "source": [
        "| Statistic       | Value              |\n",
        "|-----------------|--------------------|\n",
        "| Mean            | 439.857 |\n",
        "| Geometric Mean  | 196.315 |\n",
        "| Median          | 284.131            |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knny2VKBr-j3"
      },
      "outputs": [],
      "source": [
        "# TODO: qui mancherebbe un t-test con i risultati precedenti per mostrare che non è peggio, no? in ogni caso non lo faremo hahah\n",
        "# magari si può mettere la tabella con i precomputed ma senza compressione in parte"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hCL6i9AeMAvu",
        "bQxd5IacME_Y",
        "NJLTkpTjMNwI",
        "TKScVf2ghNxt",
        "NJRhECAXhUnd",
        "X5yqiqC-AjpV",
        "TbqOrFOgfdz-",
        "5J6rluh0wSYz",
        "wRUyB_omy0uf",
        "GRrcF4bg2UeA",
        "hr8m3W2K3JRW",
        "IJVMNzy-3XXI",
        "f9ZunGmU3ebq",
        "ohoDLEzt3rhv",
        "L4t1sU16vwfR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00b857d19c3a4ba397c03c527dbb068b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "094df0987f104438803de6529bca321a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "202e636dbc8f43778af5fd48690606b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b657b95156345a784a9eb893a21ae88",
            "max": 104445177,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00b857d19c3a4ba397c03c527dbb068b",
            "value": 104445177
          }
        },
        "2b0d0362c0a6469c8b97cfeeaf216e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d9d29e9e85143a09d3bd513b9e0a1f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38052302c7454396a178f8511ff59446": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4143252a40b64f10ac9913e9f5f4f2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4795452a1560470b8ac87bda0672d5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38052302c7454396a178f8511ff59446",
            "placeholder": "​",
            "style": "IPY_MODEL_2b0d0362c0a6469c8b97cfeeaf216e62",
            "value": "https://repo1.maven.org/maven2/org/terrier/terrier-python-helper/0.0.8/terrier-python-helper-0.0.8.jar: 100%"
          }
        },
        "5319ca1f5b284bbca8dc32d266f48fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4143252a40b64f10ac9913e9f5f4f2bb",
            "placeholder": "​",
            "style": "IPY_MODEL_c16926e22a4e4effa62f541cd391d65c",
            "value": " 99.6M/99.6M [00:00&lt;00:00, 122MB/s]"
          }
        },
        "54f75f0613f0476d8d37924dd68b9291": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b657b95156345a784a9eb893a21ae88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61301684073d499fa8f103c57d91fe7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3dae090c20e4ccca0f2aa9ad071f8c0",
            "max": 37524,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9d6dae4300444a885d723d3378073eb",
            "value": 37524
          }
        },
        "669c29f40d3e42afb53e43f839674ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4adbdab2b44d8f93dbf85a410399f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b92dca187d04ae3b94456aff3e1b874",
            "placeholder": "​",
            "style": "IPY_MODEL_bbf0b39c2a874b6cb0709da3ea7f9734",
            "value": "https://repo1.maven.org/maven2/org/terrier/terrier-assemblies/5.11/terrier-assemblies-5.11-jar-with-dependencies.jar: 100%"
          }
        },
        "7b92dca187d04ae3b94456aff3e1b874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4e211a31994e3cac7e0e780de0e420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d9d29e9e85143a09d3bd513b9e0a1f4",
            "placeholder": "​",
            "style": "IPY_MODEL_094df0987f104438803de6529bca321a",
            "value": " 36.6k/36.6k [00:00&lt;00:00, 2.33MB/s]"
          }
        },
        "8d8e9e2cde9e48b4ae65a3f6ca0f3971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b4adbdab2b44d8f93dbf85a410399f9",
              "IPY_MODEL_202e636dbc8f43778af5fd48690606b4",
              "IPY_MODEL_5319ca1f5b284bbca8dc32d266f48fb4"
            ],
            "layout": "IPY_MODEL_669c29f40d3e42afb53e43f839674ea2"
          }
        },
        "b3dae090c20e4ccca0f2aa9ad071f8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb6f5131320946bf8df4f08680926d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4795452a1560470b8ac87bda0672d5cc",
              "IPY_MODEL_61301684073d499fa8f103c57d91fe7a",
              "IPY_MODEL_7d4e211a31994e3cac7e0e780de0e420"
            ],
            "layout": "IPY_MODEL_54f75f0613f0476d8d37924dd68b9291"
          }
        },
        "bbf0b39c2a874b6cb0709da3ea7f9734": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c16926e22a4e4effa62f541cd391d65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9d6dae4300444a885d723d3378073eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
